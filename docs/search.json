[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Introduction to Statistics and Data Science",
    "section": "",
    "text": "Welcome to the website for Middlebury College’s Fall 2024 STAT 201. On this website you will find the course syllabus, schedule, and assignments. The website is frequently updated during the semester, so please make a habit of refreshing the page. The icons at the top right will link to the supplemental textbook and Canvas."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Advanced Introduction to Statistics and Data Science",
    "section": "Course details",
    "text": "Course details\nInstructor: Prof. Becky Tang (she/her)\n\nOffice: WNS 214\nEmail: btang@middlebury.edu\n\nMeeting times and location:\n\nSection AZ: MW 8:15-9:30am in Warner 100, R 8:15-9:30am in Warner 104\nSection BY: MW 9:45-11:00am in Warner 100, R 9:45-11:00am in Warner 101\n\nOffice hours (both sections welcome):\n\nProf. Tang: Monday 2-4pm, Friday 9-10am\n\nTA hours in Quantitative Center in Armstrong Library:\n\nTA Claire Yang: Sunday 7-9, Thursday 7-9\nTA Justin Corke: Thursday 7-9\n\nThe syllabus (most recent update: 9/8/24) outlines our course policies and a rough schedule. Once classes begin, you should follow the schedule and due dates found on this website.\n\nNote the textbooks are optional in this class. However, several practice and homework problems are pulled from the OpenIntro textbook.\n\n\n\nggplot2 cheat sheet"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Jump to:\n\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nIn-class material\nCoding practice\nAssignments\n\n\n\n\n\n1\n\nM 09/09\n\nTopic: Welcome! (pdf here)\n\nDirections for printing at bottom\n\n\n\n\nBring your completed quiz to next class\nFill out this survey by next class.\n\n\n\n\nW 09/11\n\nTopic: Study design (pdf here)\n\nPractice problems\n\n\n\n\nWednesday problems on Problem Set 1\n\n\n\n\nR 09/12\n\nTopic: Software installation (no need to print slides!)\nR and .Rmd basics\n\nDownload the following .Rmd template and drag to your new STAT 201 folder:  Rmd template \nRecording here! Password: 3g^SS69r\n\n\n\nIntro to R and R Markdown\n Coding practice \n\n\nThursday problems on Problem Set 1\n\n\n\n\n\n\n\nIn-class material\nCoding practice\nAssignments\n\n\n2\nM 09/16\n\nTopic: Numerical data (part 1) (pdf here)\n\nLive code and associated template:  Rmd \nPractice problems\n\n\n\n\nMonday problems on Problem Set 2\nSunflower field\n\n\n\n\nW 09/18\n\nTopic: Numerical data (part 2) (pdf here)\n\nLive code\nPractice problems\n\n\n\nBasic plots and summary statistics in R\n Coding practice \n\n\nWednesday problems on Problem Set 2\n\n\n\n\nR 09/19\n\nTopic: ggplot for numerical variables (pdf here)\n\nLive code\n\n\n\nIntroduction to ggplot\n Coding practice \n\n\nThursday problems on Problem Set 2\nAssociated R problems\n Problem Set 2 \n\n\n\n\n\n\n\nIn-class material\nCoding practice\nAssignments\n\n\n3\nM 09/23\n\nTopic: categorical data (pdf here)\n\n\nVisualizing categorical data\n Coding practice \n\n\nMonday problems on Problem Set 3\n\n\n\n\nW 09/25\n\nTopic: Introduction to data wrangling (pdf here)\n\nLive code example\n\n\n\nPractice with wrangling\n Coding practice \n\nBegin working through this R lab:\n Problem Set 3 \n\n\n\nR 09/26\n\nTopic: Data wrangling (cont.)\n\nLive code example\n\nGroup exercise\n .Rmd \n\n\nContinue working on the above lab.\n\n\n\n\n\n\nIn-class material\nCoding practice\nAssignments\n\n\n4\nM 09/30\nTopic: Probability basics (pdf here)\n\nIntroduce Midterm 1\nPractice problems\n\n\n\nMonday problems on Problem Set 4\n\nNote: this week’s problem set is due Saturday 10/05 midnight!\n\n\n\nW 10/02\nTopic: Conditional probability (pdf here)\n\nPractice problems\n\n\n\nWednesday problems on Problem Set 4\n\nNote: this week’s problem set is due Saturday 10/05 midnight!\n\n\n\nR 10/03\nTopic: Simpson’s paradox (pdf here)\n\nPractice with wrangling: probabilities\n Coding practice \n\n\n\n\n\n\n\n\nIn-class material\nCoding practice\nAssignments\n\n\n5\nM 10/07\nTopic: Introduction to Bootstrap (pdf here)\n\nLive code\n\n\nNo problem set this week. Study for midterm!\n\n\n\nW 10/09\nTopic: Bootstrap confidence intervals (pdf here)\n\nPlease complete this mid-semester survey\n\n\nBootstrap CIs (due Monday midnight)\n Coding practice \n\n\n\n\n\nR 10/10\nMidterm 1!\n\n\n\n\n\n\n\n\nIn-class material\nCoding practice\nAssignments\n\n\n6\nM 10/14\n\nTopic: Introduction to Hypothesis Testing (HT) with simulation (pdf here)\n\nLive code\nPractice problems\n\n\n\nBootstrap CIs from last Thursday due tonight\n\n\nMonday problems in Problem Set 5\n\n\n\n\nW 10/16\n\nTopic: HTs with randomization\n\n\n\n\n\n\nR 10/18\n\nTopic: HTs with randomization (cont.)\n\n\n\n\n\n\n\n\n\nIn-class material\nCoding practice\nAssignments\n\n\n\nTo print PDF of the slides with multiple slides on a page:\n\nDownload the PDF and open the document\nPrint the document\n\nIn the Print options, go to Layout then choose your preferred number of Pages per Sheet\nHit Print"
  },
  {
    "objectID": "slides/slides-01-study-design.html#population-and-samples",
    "href": "slides/slides-01-study-design.html#population-and-samples",
    "title": "Study design",
    "section": "Population and samples",
    "text": "Population and samples\n\nData do not come from thin air! Data have to be collected in some way.\nThis usually takes the form of sampling a subset of individuals from a target group of interest\n\nThe target group of interest is called the population\nThe subset of individuals from whom we actually collect data is the sample\n\nA case is a fancy term for saying one observational unit\n\nWhat are the target populations in the following research questions? What would an individual case/unit be?\n\nWhat is the average height of trees on Middlebury College campus?\nWhat proportion of current Middlebury professors attended a liberal arts college?\nOver the last five years, what is the average time to complete a degree for Middlebury College students?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#example",
    "href": "slides/slides-01-study-design.html#example",
    "title": "Study design",
    "section": "Example",
    "text": "Example\nThe U.S. Census Bureau is responsible for producing data about the American people and economy.\n\nDecennial census\nAmerican community survey"
  },
  {
    "objectID": "slides/slides-01-study-design.html#parameters-and-statistics",
    "href": "slides/slides-01-study-design.html#parameters-and-statistics",
    "title": "Study design",
    "section": "Parameters and statistics",
    "text": "Parameters and statistics\n\nOften times, answering the research question simplifies to understanding a numerical summary.\n\nA numerical summary calculated from (or considered for calculation from) the entire population is called a (population) parameter\nIn contrast, a numerical summary calculated from the sample is called a (sample) statistic\n\nWhy do we differentiate? It’s always good to remember that we are trying to answer questions about the population!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#population-and-samples-cont.",
    "href": "slides/slides-01-study-design.html#population-and-samples-cont.",
    "title": "Study design",
    "section": "Population and samples (cont.)",
    "text": "Population and samples (cont.)\n\nTypically, the size of the sample is way smaller than the population. Why?\n\nIn the lucky event that we are able to collect data for every individual in the population, the sample is referred to as a census\n\nExample: the U.S. Census Bureau is responsible for producing data about the American people and economy. They collect data with different schemes and frequency:\n\nDecennial census\nAmerican community survey"
  },
  {
    "objectID": "slides/slides-01-study-design.html#a-good-sample",
    "href": "slides/slides-01-study-design.html#a-good-sample",
    "title": "Study design",
    "section": "A “good” sample",
    "text": "A “good” sample\n\nThe way we sample data from a population can directly influence the quality of that sample.\n\nWhat are desirable characteristics of a sample?\n\n\nRepresentative: the sample roughly “looks like” the population, i.e. the individuals in the sample offer a good representation of the population at large\nGeneralizable: any results based on the sample can generalize to the population, i.e. we can make “good guesses” about a population parameter using a sample statistic\nUnbiased: every individual in the sample had an equal chance of being sampled"
  },
  {
    "objectID": "slides/slides-01-study-design.html#bias-in-a-sample",
    "href": "slides/slides-01-study-design.html#bias-in-a-sample",
    "title": "Study design",
    "section": "Bias in a sample",
    "text": "Bias in a sample\nBias in a sample can arise due to many causes. Here are a few:\n\nSelection bias\n\nOften arises when convenience sample is taken\n\nExclusion/undercoverage bias\nNon-response bias\nResponse bias\n\n\n\nSelection bias: systematic tendency in procedure that causes some members of population to be more likely to be included than others\nUndercoverage bias: part of population is excluded from sample -> not representative\nNon-response bias: bias introduced when people who don’t respond differ for some reason that affects the target quantity of interest\nResponse bias: systematic favoring of certain outcomes that occurs when people don’t answer truthfully (lying or not being truthful)"
  },
  {
    "objectID": "slides/slides-01-study-design.html#simple-random-sampling",
    "href": "slides/slides-01-study-design.html#simple-random-sampling",
    "title": "Study design",
    "section": "Simple random sampling",
    "text": "Simple random sampling\n\nThe most intuitive and basic form of random sampling!\nEach individual is chosen entirely by chance from the population, each member of the population has an equal chance of being sampled.\n\nKnowing that an individual was sampled does not provide useful information about which other cases are included\nAny given fixed-size subset of the population is equally likely to be chosen.\n\n\nConsider again the research question: What proportion of current Middlebury professors attended a liberal arts college?\nHow might I obtain a sample random sample of 25 professors?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#stratified-sampling",
    "href": "slides/slides-01-study-design.html#stratified-sampling",
    "title": "Study design",
    "section": "Stratified sampling",
    "text": "Stratified sampling\n\nDepending on the population, we might need to use different random sampling methods to ensure the sample is representative.\nAssume that the population is/can be broken up into several different, distinct sub-populations or strata\n\nThe division should “make sense”\n\nRather than randomly sampling from the population as whole, we take a random sample from each stratum\n\nHow many from each stratum? Typically use a sampling fraction that is proportional to entire population!\nE.g. if population of trees on Middlebury campus are 80% deciduous and 20% coniferous and we want to sample \\(n = 10\\) trees total, we should randomly sample ___ deciduous and ___ coniferous trees\n\nWhat are some pros/cons?\n\n\n\nMay be useful to ensure we have samples from rare groups, and helps to improve precision of the sample\nMost useful when stratifying variables are simple to work with, easy to observe, closely related to topic of survey\nCan be expensive to travel –> motivates the next type"
  },
  {
    "objectID": "slides/slides-01-study-design.html#cluster-sampling",
    "href": "slides/slides-01-study-design.html#cluster-sampling",
    "title": "Study design",
    "section": "Cluster sampling",
    "text": "Cluster sampling\n\nDivide total population into \\(M\\) distinct groups or clusters of roughly equal size\nPerform a simple random sample on the \\(M\\) clusters, than sample all individuals within each of the randomly selected clusters\n\nDiscuss the following:\n\nWould you prefer the individuals within a cluster to be homogeneous (similar) or heterogeneous (varied)? Why?\nWould you prefer that cluster A and cluster B be relatively similar or different in terms of their sub-populations?\nWhat is the difference between stratified and cluster sampling?\n\n\n\n\n\nCreates pockets of sampled units –> reducing costs. Also useful when we cannot obtain a list of ALL units in the population, but can easily obtain a list of all units within a cluster\nLess efficient that SRS –> better to survey large number of small clusters than vice versa\n\nNeighboring units tend to be more similar –> sampling one being cluster would not represent a whole spectrum of variation present in the entire population\n\nDifficult to control final sample size. If you want a particular size n (e.g. 100), the other two methods are easier"
  },
  {
    "objectID": "slides/slides-01-study-design.html#multistage-sampling",
    "href": "slides/slides-01-study-design.html#multistage-sampling",
    "title": "Study design",
    "section": "Multistage sampling",
    "text": "Multistage sampling\n\nBuilds on the cluster sampling method, but rather than sampling all individuals within the selected clusters, only collect a random sample within each selected cluster\nThough seemingly more complicated, why might we prefer multistage sampling over cluster sampling?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#experimental-design",
    "href": "slides/slides-01-study-design.html#experimental-design",
    "title": "Study design",
    "section": "Experimental design",
    "text": "Experimental design\n\nExperiments are studies where the researcher assigns treatments to cases\n\nNote: experiments are often conducted in medical settings, hence the word “treatment”\n\nAre treatments considered explanatory or response variables?\n\n\nWhen the researcher randomly assigns the treatments, we have a randomized experiment\n\nRandomized experiments are critical when trying to assess the causal effect of the explanatory variable on the response variable\nNote: random assignment \\(\\ne\\) random sampling\n\n\n\nRunning example: quizzes and final exam. Want to know if having quizzes throughout semester boosts performance on final exam. Randomly assign half of class to do quizzes, and the other half to not. Then compare their final exam scores."
  },
  {
    "objectID": "slides/slides-01-study-design.html#confounding-variables",
    "href": "slides/slides-01-study-design.html#confounding-variables",
    "title": "Study design",
    "section": "Confounding variables",
    "text": "Confounding variables\n\nUnderstanding a causal relationship is made difficult by confounding variables: variables that are associated with both the explanatory and response variable of interest\n\n\nConfounders are bad!! Why?\n\n\nExample: consider a study that seeks to examine the effect of coffee consumption on heart disease.\n\nFrom each person, we only collect information on the average amount of coffee they consume per day and whether or not they have heart disease.\nWe find a positive association: more coffee \\(\\rightarrow\\) higher risk of heart disease\nPossible confounder: smoker status. Smokers tend to drink more coffee and tend to have higher rates of heart disease than non-smokers.\nSo the increase in heart disease may be due to smoker status rather than caffeine intake\n\n\n\nConfounders prevent us from attributing the cause to the (desired) explanatory variable!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#principles-of-experimental-design",
    "href": "slides/slides-01-study-design.html#principles-of-experimental-design",
    "title": "Study design",
    "section": "Principles of experimental design",
    "text": "Principles of experimental design\n\nRandomization: randomly assign patients to treatments\n\nHelps account for variables that cannot be controlled and possible confounding variables\n\nControlling for differences in the treatment: ensure that everyone follows the same protocol exactly\nReplication: the more cases we observe, the more confidence we have in the effect of the explanatory on the response\n\nAchieved by collecting a sufficiently large sample in a single study, or repeating the entire study more than once\n\n\n\nThese first three principles are crucial! The following is principle is desirable, but more complicated."
  },
  {
    "objectID": "slides/slides-01-study-design.html#principles-of-experimental-design-cont.",
    "href": "slides/slides-01-study-design.html#principles-of-experimental-design-cont.",
    "title": "Study design",
    "section": "Principles of experimental design (cont.)",
    "text": "Principles of experimental design (cont.)\n\nBlocking: suppose we know ahead of time that there is/are variable(s) that could influence the response besides just the explanatory. We assign patients to their respective blocks, and than randomly assign treatments within blocks.\n\nHelps to decrease unexplained variability by accounting for nuisance variables: variables that affect the response variable but are not of interest for answering the scientific question\nCan lead to greater interpretation of results"
  },
  {
    "objectID": "slides/slides-01-study-design.html#reducing-bias-in-human-experiments",
    "href": "slides/slides-01-study-design.html#reducing-bias-in-human-experiments",
    "title": "Study design",
    "section": "Reducing bias in human experiments",
    "text": "Reducing bias in human experiments\n\nWe should make the experiment a blind experiment by not allowing participants to know which group they’ve been assigned to\n\nGive a fake treatment known as a placebo to those in the control group (e.g. a sugar pill that looks exactly like the actual treatment pill)\nOftentimes, a placebo results in a slight but real improvement in patients. This is known as the placebo effect\n\nDoctors and researchers involved in the study should also be blinded so they do not give preferential treatment or care to patients in certain groups.\n\nDouble-blind experiments: both the patients and the doctors/researchers who interact with patients are unaware of who is or is not receiving the treatment\n\nQuestion of ethics"
  },
  {
    "objectID": "slides/slides-01-study-design.html#treatment-vs.-control",
    "href": "slides/slides-01-study-design.html#treatment-vs.-control",
    "title": "Study design",
    "section": "Treatment vs. control",
    "text": "Treatment vs. control\n\nRandomized experiments are the gold standard for data collection, but biases can still occur!\nWhen we want to learn if the explanatory variable causes some effect in the response variable.\n\nWe have a control group which establishes a baseline, and typically receives “zero amount” of the explanatory variable.\nWe also have a treatment group which receives some “non-zero amount” of the explanatory variable\n\nExample: suppose we want to test the effect of a drug that is developed to help people fall asleep.\n\nTreatment group: receives 50mg of the drug in pill form\nControl group: does not receive the drug at all\n\nWhat is a potential issue?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#observational-studies-1",
    "href": "slides/slides-01-study-design.html#observational-studies-1",
    "title": "Study design",
    "section": "Observational studies",
    "text": "Observational studies\n\nStudies where no treatment is explictly applied\nNothing is manipulated; researchers simply record/observe without intervening\nTypically cannot obtain causal conclusions using data from observational studies\n\nThere are too many confounding variables at play in observational studies\n\nBut we can use these studies to identify associations or form hypotheses for future experiments!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#observational-studies",
    "href": "slides/slides-01-study-design.html#observational-studies",
    "title": "Study design",
    "section": "Observational studies",
    "text": "Observational studies\n\nStudies where no treatment is explicitly applied\nNothing is manipulated; researchers simply record/observe without intervening\nTypically cannot obtain causal conclusions using data from observational studies\n\nThere are too many confounding variables at play in observational studies\n\nBut we can use these studies to identify associations or form hypotheses for future experiments!\n\n\nQuiz/exam example could be an observational study if we gave students the choice to do an optional quiz."
  },
  {
    "objectID": "practice/practice-01-study-design.html",
    "href": "practice/practice-01-study-design.html",
    "title": "Study design",
    "section": "",
    "text": "Please work on the practice problems in your group. At least one of the following problems will be assigned to the weekly problem set. Unless otherwise stated, problems come from the IMS textbook.\n\nTime to implement the sampling methods we learned! Keep track of your work on this problem; we will return to it in the next few classes.\nWe have a farmer who grows sunflowers for making sunflower oil. Her field is arranged in a grid pattern, with 12 rows and 12 columns as shown below. Water is important for crops, so irrigation ditches have been installed along the top and bottom of the field. It is expected that plants closer to a water source will perform better than those further away from water.\nThe farmer would like to estimate the number of healthy plants in the field, along with a few other characteristics about the sunflowers. It would be unfeasible to conduct a census, so we should choose to sample a subset of the grid cells. Suppose we’d like to sample \\(n = 12\\) grid cells total.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using simple random sampling. I should be able to read your work and know what to do without any questions! Think about how you will perform the random sampling.\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using stratified sampling where the strata are rows. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using stratified sampling where the strata are columns. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using cluster sampling where we have 24 clusters total. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using multistage sampling. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\n\nWe discussed several methods of sampling today. Now consider a new sampling scheme that is commonly used in the social sciences when sampling from a “hidden” population. A scenario might be that we want to conduct a poll among homeless people, but the research team may only have contact details for a few homeless people.\nDenote the initial contacts as Group 1. The sampling proceeds in the following stages:\n\nStage 1: ask the people in Group 1 to take the survey, and then provide contact details for other people from the population who might want to participate. Denote these new contacts as Group 2.\nStage 2: ask the people in Group 2 to take the survey, and then provide contact details for other people from the population who might want to participate. Denote these new contacts as Group 3.\nProceed in a similar manner until the researchers have sufficient data.\n\n\n\nWhat are some advantages to this method of sampling?\nWhat are some disadvantages? Think about statistically and also ethically.\n\n(2.5.20) To assess the effectiveness of taking large doses of vitamin C in reducing the duration of the common cold, researchers recruited 400 healthy volunteers from staff and students at a university. A quarter of the patients were assigned a placebo, and the rest were evenly divided between 1g Vitamin C, 3g Vitamin C, or 3g Vitamin C plus additives to be taken at onset of a cold for the following two days. All tablets had identical appearance and packaging. The nurses who handed the prescribed pills to the patients knew which patient received which treatment, but the researchers assessing the patients when they were sick did not. No statistically discernible differences were observed in any measure of cold duration or severity between the four groups, and the placebo group had the shortest duration of symptoms.\n\nWas this an experiment or an observational study? Why?\nWhat are the explanatory and response variables in this study?\nWere the patients blinded to their treatment?\nWas this study double-blind?\nParticipants are ultimately able to choose whether to use the pills prescribed to them. We might expect that not all of them will adhere and take their pills. Does this introduce a confounding variable to the study? Explain your reasoning."
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#data",
    "href": "slides/slides-03-numerical-vis.html#data",
    "title": "Numerical data",
    "section": "Data",
    "text": "Data\nWhich of the following variables are numerical?"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#scatterplots",
    "href": "slides/slides-03-numerical-vis.html#scatterplots",
    "title": "Numerical data",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots are bivariate visualizations that prove a case-by-case view of the data for two numerical variables\n\nEach point represents the observed pair of values of variables 1 and 2 for each case in the dataset"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#scatterplots-cont.",
    "href": "slides/slides-03-numerical-vis.html#scatterplots-cont.",
    "title": "Numerical data",
    "section": "Scatterplots (cont.)",
    "text": "Scatterplots (cont.)\n\nHow do we determine which variable to put on each axis?\nWhat do scatterplots reveal about the data, and how are they useful?\nHow might we improve on this visualization?"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#dot-plots",
    "href": "slides/slides-03-numerical-vis.html#dot-plots",
    "title": "Numerical data",
    "section": "Dot plots",
    "text": "Dot plots\n\nDot plots are a basic visualization that show the distribution of a single variable. They are univariate (one-variable) scatterplots.\nIn the following, we have a dot plot of BMI rounded to the nearest integer."
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#binning",
    "href": "slides/slides-03-numerical-vis.html#binning",
    "title": "Numerical data",
    "section": "Binning",
    "text": "Binning\n\nDot plot display the exact value for each observation. Become hard to read when the variable of interest has a wide set of values\nWe will sacrifice a bit of precision for convenience by binning: we will consider segmenting the variable into equal-sized bins and visualize the value of each observation using its corresponding bin\nFor example, the bmi variable has observed values of \\(15.96\\) through \\(49.6\\). Consider the following bins of size 5:\n\n[14, 18), [18, 22), [22, 26), …, [48, 52)\n\nWe tabulate/count up the number of observations that fall into each bin.\n\n\n\n\n# A tibble: 8 × 2\n  bmi_bin  count\n  <chr>    <int>\n1 [15, 19)     5\n2 [19, 23)    12\n3 [23, 27)    35\n4 [27, 31)    58\n5 [31, 35)    41\n6 [35, 39)    35\n7 [39, 43)    13\n8 [49, 52)     1"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#histograms",
    "href": "slides/slides-03-numerical-vis.html#histograms",
    "title": "Numerical data",
    "section": "Histograms",
    "text": "Histograms\nHistograms are visualizations that display the binned counts as bars for each bin."
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#histograms-cont.",
    "href": "slides/slides-03-numerical-vis.html#histograms-cont.",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHistograms provide a view of the density of the data; the values the data take on as well as how often\nVery helpful for understanding the shape of the data distribution\n\nDistributions are either symmetric or skewed in a one direction\nDistributions with long tails to the left are called left-skewed, whereas distributions with long tails to the right are right-skewed\n\nAlso helpful for identifying modes which are prominent peaks in the distribution\n\nDistribution may be unimodal (one peak), bimodal (two peaks), or multimodal (more than two peaks)\nPeaks need not be same height in histogram"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#histograms-cont.-1",
    "href": "slides/slides-03-numerical-vis.html#histograms-cont.-1",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHow would you describe the shape and modality in the following two histograms?"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#mean",
    "href": "slides/slides-03-numerical-vis.html#mean",
    "title": "Numerical data",
    "section": "Mean",
    "text": "Mean\n\nBy far the most common way to measure the center of the distribution of numerical data is using the mean, also called the average\nWe use the term sample mean when referring to the mean of observed/sampled data, which is typically denoted as \\(\\bar{x}\\)\n\n\\(x\\) is a placeholder for the variable of interest (e.g. BMI, charges)\nThe bar communicates that we are looking at the average\n\nThe (sample) mean is the sum over all the values of the variable, divided by total number of observations \\(n\\):\n\n\n\\[\\bar{x} = \\frac{x_{1} + x_{2} + \\ldots x_{n}}{n} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\]"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#mean-cont.",
    "href": "slides/slides-03-numerical-vis.html#mean-cont.",
    "title": "Numerical data",
    "section": "Mean (cont.)",
    "text": "Mean (cont.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe sample mean \\(\\bar{x}\\) is an example of a sample statistic\nThe mean over the entire population is an example of a population parameter. The population mean is often denoted \\(\\mu\\) (Greek letter mu)\nThe sample mean \\(\\bar{x}\\) is often used as an estimate for \\(\\mu\\)"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#live-code",
    "href": "slides/slides-03-numerical-vis.html#live-code",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\n\nBase R\nggplot"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#example",
    "href": "slides/slides-03-numerical-vis.html#example",
    "title": "Numerical data",
    "section": "Example",
    "text": "Example\nSuppose we have obtained the following data on diastolic blood pressure from patients at Porter Hospital:\n\\[\n\\boldsymbol{x} =76, 64, 62, 81, 70, 72, 81, 63, 67, 77\n\\]\n\nWrite out how you would calculate \\(\\bar{x}\\)\nThen we will use R to calculate the sample mean diastolic blood pressure!"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#means-depend-on-proportions",
    "href": "slides/slides-03-numerical-vis.html#means-depend-on-proportions",
    "title": "Numerical data",
    "section": "Means depend on proportions",
    "text": "Means depend on proportions\n\n\nWhat is the average of the following values: \\(1, 4, 4\\)?\n\n\n\\(\\bar{x} = \\frac{1+4+4}{3} = 1\\left(\\frac{1}{3} \\right) + 4\\left( \\frac{2}{3}\\right) = \\frac{9}{3} = 3\\)\n\n\nIf instead there were 10 1’s and 20 4’s, would the average be the same?\n\n\nYes! \\(\\bar{x} = 1\\left(\\frac{10}{30}\\right) + 4 \\left(\\frac{20}{30} \\right) = \\frac{90}{30} = 3\\)"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#variability",
    "href": "slides/slides-03-numerical-vis.html#variability",
    "title": "Numerical data",
    "section": "Variability",
    "text": "Variability\n\nWe learned that the mean is a way to describe the center or “average value” of a numerical variable\nHowever, at the heart of statistics is also the variability or spread of the distribution of the variable\nWe will work with variance and standard deviation, which describe how spread out data are from their mean"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#deviation",
    "href": "slides/slides-03-numerical-vis.html#deviation",
    "title": "Numerical data",
    "section": "Deviation",
    "text": "Deviation\nWe return to the blood pressure data:\n\\[\n\\boldsymbol{x} = 76, 64, 62, 81, 70, 72, 81, 63, 67, 77 \\qquad \\qquad \\qquad \\bar{x} = 71.3\n\\]\n\nWe start with deviation, which is the distance of or difference between an observation from the (sample) mean\n\nHow might we write this using statistical notation?\n\n\n\n\n\n    x deviation\n1  76       4.7\n2  64      -7.3\n3  62      -9.3\n4  81       9.7\n5  70      -1.3\n6  72       0.7\n7  81       9.7\n8  63      -8.3\n9  67      -4.3\n10 77       5.7"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation",
    "href": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation",
    "title": "Numerical data",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\n\nThe sample variance \\(s^2\\) squares the deviations and takes an average:\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n} (x_{i} - \\bar{x})^2}{n-1}\n\\]\n\nLet’s talk about this notation and intuition behind this formula. In particular, there are at least two things to note\n\nThe sample standard deviation \\(s\\) is simply the square root of the sample variance (\\(s = \\sqrt{s^2}\\))\nCalculate the sample variance and standard deviation for the blood pressure data\n\nBy hand\nUsing R"
  },
  {
    "objectID": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation-cont.",
    "href": "slides/slides-03-numerical-vis.html#variance-and-standard-deviation-cont.",
    "title": "Numerical data",
    "section": "Variance and standard deviation (cont.)",
    "text": "Variance and standard deviation (cont.)\n\nLike the mean, the population values for variance and standard deviation are denoted with Greek letters:\n\n\\(\\sigma\\) for population standard deviation (sigma)\n\\(\\sigma^2\\) for population variance\n\n\nIf the calculation of standard deviation is a more complicated quantity than the variance, why do we bother with standard deviation?"
  },
  {
    "objectID": "practice_probs/practice-03-numerical-data-pt1.html",
    "href": "practice_probs/practice-03-numerical-data-pt1.html",
    "title": "Numerical data (part 1)",
    "section": "",
    "text": "Please work on the practice problems in your group. At least one of the following problems will be assigned to the weekly problem set.\n\nIndicate which of the plots show (a) a positive association, (b) negative association, or (c) no association. Also determine if the positive and negative associations are linear or nonlinear. Each part may refer to more than on plot.\n\nCalculate the average/sample mean in each of the following scenarios:\n\nSuppose that we have some data where 20% of the data are 1’s, 50% are 2’s, and 30% are 3’s. What is the sample mean?\nA school has two classes, one with 10 students and one with 100 students. What is the average class size?\nA school as two classes, one with 10 students and one with 100 students. What is the average size of the class that a student is enrolled in?\n\nA list has 10 entries, and each entry is either a 1, 2, or 3. What must the list be if the average is 3? Can the average be 4?\n21 people in a room have an average of 5 feet 6 inches. A 22nd person enters the room. How tall would this person have to be to raise the average height by 1 inch?\nConsider the following lists:\n\\[(i) \\ 1, \\ 3,\\ 4, \\ 5,\\  7 \\qquad \\qquad (ii) \\ 6,\\ 8,\\ 9,\\ 10,\\ 12\\]\n\nFor each list, find the average and the standard deviation.\nHow is list (ii) related to list (i)? How does this relationship carry over to the average and to the standard deviation?\n\nWorkers at a particular mining site receive an average of 35 days paid vacation, which is lower than the national average. The manager of this plant is under pressure from a local union to increase the amount of paid time off. However, he does not want to give more days off to the workers because that would be costly. Instead he decides he should fire 10 employees in such a way as to raise the average number of days off that are reported by his employees. In order to achieve this goal, should he fire employees who have the most number of days off, least number of days off, or those who have about the average number of days off?\nLet’s return to the sunflowers! Recall that we used five different sampling schemes to obtain a sample of \\(n= 12\\) grid cells. You have now collected data on the number of healthy sunflowers in each of the 12 grid cells for each sampling scheme.\nFor each sampling scheme, calculate i) the average number of healthy sunflowers in a grid cell, as well as ii) the standard deviation of the number of healthy plants in a grid cell.\n\nTo show your work for this problem: it is sufficient to write-out the calculations by hand (using “…” notation is fine!) for just one of the sampling schemes. But be sure to report the statistics for all schemes.\nI highly encourage you to use R to help perform the actual calculations. If you do use R, write-out an example of the code you execute for just one of the sampling schemes."
  },
  {
    "objectID": "practice_probs/practice-01-study-design.html",
    "href": "practice_probs/practice-01-study-design.html",
    "title": "Study design",
    "section": "",
    "text": "Please work on the practice problems in your group. At least one of the following problems will be assigned to the weekly problem set.\n\nIn Spring 2024, Prof. Tang asked her STAT 311 students to fill out a mid-semester survey. She was particularly interested in the the amount of hours her STAT 311 students were spending per week on the course. The average time spent on the course was found to be 10.2 hours per week.\n\nBased on this information, identify each of the following: observation, variable, parameter, and statistic.\nWas this survey a census or (just) a sample? Why?\n\nTime to implement the sampling methods we learned! Keep track of your work on this problem; we will return to it in the next few classes.\nWe have a farmer who grows sunflowers for making sunflower oil. Her field is arranged in a grid pattern, with 12 rows and 12 columns as shown below. Water is important for crops, so irrigation ditches have been installed along the top and bottom of the field. It is expected that plants closer to a water source will perform better than those further away from water.\nThe farmer would like to estimate the number of healthy plants in the field, along with a few other characteristics about the sunflowers. It would be unfeasible to conduct a census, so we should choose to sample a subset of the grid cells. Suppose we’d like to sample \\(n = 12\\) grid cells total.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using simple random sampling. I should be able to read your work and know what to do without any questions! Think about how you will perform the random sampling.\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using stratified sampling where the strata are rows. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using stratified sampling where the strata are columns. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using cluster sampling where we have 24 clusters total. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\nUsing words (sentences or bulleted list are fine) and perhaps labeling the figure below, describe exactly how you would obtain a sample of 12 grid cells using multistage sampling. I should be able to read your work and know what to do without any questions!\nThen implement the method that you’ve written down, and either using the figure below or drawing your own 12x12 field, shade in the squares that correspond to your sample.\n\n\nSuppose we want to estimate household size, where a “household” is defined as people living together in the same dwelling, and sharing living accommodations. If we select students at random at an elementary school and ask them what their family size is, will this be a good measure of household size? Or will our average be biased? If so, will it overestimate or underestimate the true value?\nTo assess the effectiveness of taking large doses of vitamin C in reducing the duration of the common cold, researchers recruited 400 healthy volunteers from staff and students at a university. A quarter of the patients were assigned a placebo, and the rest were evenly divided between 1g Vitamin C, 3g Vitamin C, or 3g Vitamin C plus additives to be taken at onset of a cold for the following two days. All tablets had identical appearance and packaging. The nurses who handed the prescribed pills to the patients knew which patient received which treatment, but the researchers assessing the patients when they were sick did not. No statistically discernible differences were observed in any measure of cold duration or severity between the four groups, and the placebo group had the shortest duration of symptoms.\n\nWas this an experiment or an observational study? Why?\nWhat are the explanatory and response variables in this study?\nWere the patients blinded to their treatment?\nWas this study double-blind?\nParticipants are ultimately able to choose whether to use the pills prescribed to them. We might expect that not all of them will adhere and take their pills. Does this introduce a confounding variable to the study? Explain your reasoning.\n\n\n\n\n    a.  What are some advantages to this method of sampling?\n    b.  What are some disadvantages? Think about statistically and also ethically.\n-->"
  },
  {
    "objectID": "coding_practice/coding-practice-03-numerical-pt1.html",
    "href": "coding_practice/coding-practice-03-numerical-pt1.html",
    "title": "Numerical data coding practice",
    "section": "",
    "text": "Change your name in the YAML. Be sure to keep the quotation marks!\nIn the following code chunk, load in the openintro package. Then run the code in the code chunk. We will once again work with the cherry data set.\n\n\n\n\n\nIn the code chunk below, write code to find the mean and median of the diameter of trees in the cherry data frame.\n\n\n\n\n\nMake a box plot of the height of cherry trees. Can you make an informative axis label for your plot? Try changing the color of your boxplot by specifying col = \"color name\" in the function. Note that the name of the color must be in quotes! If you’re confused, look at the examples in the bottom of the Help file of the appropriate function,\n\n\n\n\n\nMake a scatter plot of the diameter and volume of cherry trees. Put volume on the y-axis.\n\n\n\n\nOnce you’re finished, be sure to knit and submit the output file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#recap",
    "href": "slides/slides-04-numerical-pt2.html#recap",
    "title": "Numerical data",
    "section": "Recap",
    "text": "Recap\nWe learned about the sample mean \\(\\bar{x}\\), the sample variance \\(s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\\), and the sample standard deviation \\(s = \\sqrt{s^2}\\)\n\nWhy care about standard deviation (SD)? Describes how far data are distributed from their mean\nUsually (but not always!!) about 70% of the data will be within one SD of the mean, and 95% will be within two SDs\n\nThese percentages are not precise, but are useful for intuition\nWe will come back to this later in semester"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#boxplot",
    "href": "slides/slides-04-numerical-pt2.html#boxplot",
    "title": "Numerical data",
    "section": "Boxplot",
    "text": "Boxplot\nAnother commonly used visualization to display the distribution of a numerical variable is the boxplot. Boxplots are created using five statistics and identify unusual observations.\n\n\nDoes the orientation (vertical or horizontal) matter?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#median",
    "href": "slides/slides-04-numerical-pt2.html#median",
    "title": "Numerical data",
    "section": "Median",
    "text": "Median\n\nThe (sample) median \\(m\\) is another common measure of center of a distribution. It is the value of the data distribution where 50% of the data are less than \\(m\\) and 50% of the data are greater than \\(m\\).\n\nIf we order the data from smallest to largest, the median is the value in the middle.\nIf the number of observations \\(n\\) is even, then there will be two values in the middle, and the median is taken as their average\n\n\nConsider the following data: \\(\\boldsymbol{x} =116, 114, 112, 121, 108, 113, 129, 118, 119, 115\\). What is the median?\n\nThe median is also known the 50th percentile because 50% of the data fall below \\(m\\)"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#mean-vs.-median",
    "href": "slides/slides-04-numerical-pt2.html#mean-vs.-median",
    "title": "Numerical data",
    "section": "Mean vs. Median",
    "text": "Mean vs. Median\n\nWhich is better measure of center? The mean or the median?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#interquartile-range",
    "href": "slides/slides-04-numerical-pt2.html#interquartile-range",
    "title": "Numerical data",
    "section": "Interquartile range",
    "text": "Interquartile range\nThe interquartile range (IQR) is another measure of variability/spread in the data.\n\\[\nIQR = Q_{3} - Q_{1}\n\\]\n\nIf the data are more spread out data, should the IQR increase or decrease?\nWhat is the IQR of the data \\(\\boldsymbol{x}\\)?\n\n\nIQR are not the values themselves, but rather, the spread of the middle 50% of the data. Interpretation once again depends on the scale of the data.\nQ3 = 119 and Q1 = 113 -> IQR = 6"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#creating-the-boxplot",
    "href": "slides/slides-04-numerical-pt2.html#creating-the-boxplot",
    "title": "Numerical data",
    "section": "Creating the boxplot",
    "text": "Creating the boxplot\n\nThe “box” part of the boxplot is created using \\(Q_{1}\\), \\(m\\), and \\(Q_{3}\\)\nThen we draw out whiskers from the box that attempt to capture data outside the IQR\n\nHow long should the whiskers be? There isn’t a fixed rule, but \\(1.5 \\times IQR\\) below \\(Q_1\\) and above \\(Q_{3}\\) is common\nWe should “cut off” the whiskers to be true to the data\n\nLastly, we add dots for any cases that lie beyond the whiskers\n\nThese points are unusually high/low compared to the rest of the data and are worth identifying as potential outliers\nAn outlier is an observation that appears extreme relative to the rest of the data\n\nLet’s draw a boxplot for the data \\(\\boldsymbol{x}\\)!"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#a-note-on-outliers",
    "href": "slides/slides-04-numerical-pt2.html#a-note-on-outliers",
    "title": "Numerical data",
    "section": "A note on outliers",
    "text": "A note on outliers\n\n\nWhy are we interested in identifying outliers?\n\n\nIdentifying strong skew\nIdentifying possible data collection/data entry errors\nProviding insight into interesting properties of the data\n\nAre outliers necessarily indicative of a problem in the data?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#histograms-vs-boxplots",
    "href": "slides/slides-04-numerical-pt2.html#histograms-vs-boxplots",
    "title": "Numerical data",
    "section": "Histograms vs boxplots",
    "text": "Histograms vs boxplots\n\nWhat characteristics of the distribution are apparent in the histogram and not in the box plot? What characteristics are apparent in the box plot but not in the histogram?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#robust-statistics",
    "href": "slides/slides-04-numerical-pt2.html#robust-statistics",
    "title": "Numerical data",
    "section": "Robust statistics",
    "text": "Robust statistics\n\n\n\n\nIn the data \\(\\boldsymbol{x} = 116, 114, 112, 121, 108, 113, 129, 118, 119, 115\\) that we have been working with, we have the following sample statistics:\n\n\n\\(\\qquad \\bar{x} =\\) 116.5, \\(s =\\) 5.8, \\(m =\\) 115.5 , \\(IQR =\\) 6\n\n\n\nSuppose we actually observed an additional data point with a value of \\(170\\). What are the sample statistics with this additional data point? How do they compare to the values above?\n\\(\\bar{x}' =\\) 121.4, \\(s' =\\) 17.03, \\(m' =\\) _____, \\(IQR' =\\) _____\n\nRobust statistics are statistics that are minimally affected by extreme values\n\nWhich of the statistics above would be considered robust?\n\n\nWhen should the mean be similar to the median (and the standard deviation similar to the IQR)?\n\n\n\nm’ = 116\nQ1’ = 113, Q3’ = 121, IQR’ = 8"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#mean-vs.-median-1",
    "href": "slides/slides-04-numerical-pt2.html#mean-vs.-median-1",
    "title": "Numerical data",
    "section": "Mean vs. Median",
    "text": "Mean vs. Median\nLet’s return to the insurance data. In the plot below, the orange line denotes the sample mean charges, and the blue line denotes the sample median:\n\nWhich is better? The mean or the median?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#boxplots-vs-histograms",
    "href": "slides/slides-04-numerical-pt2.html#boxplots-vs-histograms",
    "title": "Numerical data",
    "section": "Boxplots vs histograms",
    "text": "Boxplots vs histograms\nWhich plot do you prefer?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#transforming-data",
    "href": "slides/slides-04-numerical-pt2.html#transforming-data",
    "title": "Numerical data",
    "section": "Transforming data",
    "text": "Transforming data\n\nWhen data are strongly skewed or take on an “inconvenient” range of values, we might transform them so they are easier to work with\nA transformation rescales the data using a function\n\ne.g. \\(f(x) = e^x\\), \\(f(x) = \\log_{10}(x)\\), \\(f(x) = \\ln(x)\\), \\(f(x) = \\sqrt{x}\\)\nThe exact transformation you choose depends heavily on the data!!"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#exploratory-data-analysis",
    "href": "slides/slides-05-data-vis.html#exploratory-data-analysis",
    "title": "Visualizations with ggplot",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nExploratory data analysis (EDA) is an approach to analyzing data sets to summarize the main characteristics.\n\nOften visual through plots\n\nBecause of its name “exploratory”, we typically perform EDA at the beginning of a project\nCan also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#tidy-data",
    "href": "slides/slides-05-data-vis.html#tidy-data",
    "title": "Visualizations with ggplot",
    "section": "Tidy data",
    "text": "Tidy data\n\nThe first step of any data/statistical analysis is to understand the data you are working with. This often involves getting the data into R\nThen, it is a good idea to take a macro-level look at the data to ensure it is in tidy format, which means:\n\nEach row in the data set represent an observation/case\nEach columns represents a variable\n\nAnscombe data: four datasets with two variables each\n\n\n\n\nNon-tidy version:\n\n\n  x1 x2 x3 x4   y1   y2    y3   y4\n1 10 10 10  8 8.04 9.14  7.46 6.58\n2  8  8  8  8 6.95 8.14  6.77 5.76\n3 13 13 13  8 7.58 8.74 12.74 7.71\n4  9  9  9  8 8.81 8.77  7.11 8.84\n5 11 11 11  8 8.33 9.26  7.81 8.47\n6 14 14 14  8 9.96 8.10  8.84 7.04\n\n\n\nTidy version:\n\n\n   set  x     y\n1    I 10  8.04\n2    I  8  6.95\n3    I 13  7.58\n4    I  9  8.81\n5    I 11  8.33\n6    I 14  9.96\n7    I  6  7.24\n8    I  4  4.26\n9    I 12 10.84\n10   I  7  4.82\n11   I  5  5.68\n12  II 10  9.14\n13  II  8  8.14\n14  II 13  8.74\n15  II  9  8.77"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#country-footprint-datahttpswww.kaggle.comfootprintnetworkecological-footprint",
    "href": "slides/slides-05-data-vis.html#country-footprint-datahttpswww.kaggle.comfootprintnetworkecological-footprint",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data^[https://www.kaggle.com/footprintnetwork/ecological-footprint]",
    "text": "Country footprint data^[https://www.kaggle.com/footprintnetwork/ecological-footprint]\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 188 × 14\n   Country   Region Population   HDI    GDP Cropland Grazing Forest Carbon  Fish\n   <chr>     <chr>       <dbl> <dbl>  <dbl>    <dbl>   <dbl>  <dbl>  <dbl> <dbl>\n 1 Afghanis… Middl…      29.8   0.46   615.     0.3     0.2    0.08   0.18  0   \n 2 Albania   North…       3.16  0.73  4534.     0.78    0.22   0.25   0.87  0.02\n 3 Algeria   Africa      38.5   0.73  5431.     0.6     0.16   0.17   1.14  0.01\n 4 Angola    Africa      20.8   0.52  4666.     0.33    0.15   0.12   0.2   0.09\n 5 Antigua … Latin…       0.09  0.78 13205.    NA      NA     NA     NA    NA   \n 6 Argentina Latin…      41.1   0.83 13540      0.78    0.79   0.29   1.08  0.1 \n 7 Armenia   Middl…       2.97  0.73  3426.     0.74    0.18   0.34   0.89  0.01\n 8 Aruba     Latin…       0.1  NA       NA     NA      NA     NA     NA    NA   \n 9 Australia Asia-…      23.0   0.93 66604.     2.68    0.63   0.89   4.85  0.11\n10 Austria   Europ…       8.46  0.88 51274.     0.82    0.27   0.63   4.14  0.06\n# ℹ 178 more rows\n# ℹ 4 more variables: Total <dbl>, EarthsRequired <dbl>,\n#   CountriesRequired <dbl>, DataQuality <chr>"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#country-footprint-data-httpswww.kaggle.comfootprintnetworkecological-footprint",
    "href": "slides/slides-05-data-vis.html#country-footprint-data-httpswww.kaggle.comfootprintnetworkecological-footprint",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data ^[https://www.kaggle.com/footprintnetwork/ecological-footprint]",
    "text": "Country footprint data ^[https://www.kaggle.com/footprintnetwork/ecological-footprint]\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 188 × 14\n   Country   Region Population   HDI    GDP Cropland Grazing Forest Carbon  Fish\n   <chr>     <chr>       <dbl> <dbl>  <dbl>    <dbl>   <dbl>  <dbl>  <dbl> <dbl>\n 1 Afghanis… Middl…      29.8   0.46   615.     0.3     0.2    0.08   0.18  0   \n 2 Albania   North…       3.16  0.73  4534.     0.78    0.22   0.25   0.87  0.02\n 3 Algeria   Africa      38.5   0.73  5431.     0.6     0.16   0.17   1.14  0.01\n 4 Angola    Africa      20.8   0.52  4666.     0.33    0.15   0.12   0.2   0.09\n 5 Antigua … Latin…       0.09  0.78 13205.    NA      NA     NA     NA    NA   \n 6 Argentina Latin…      41.1   0.83 13540      0.78    0.79   0.29   1.08  0.1 \n 7 Armenia   Middl…       2.97  0.73  3426.     0.74    0.18   0.34   0.89  0.01\n 8 Aruba     Latin…       0.1  NA       NA     NA      NA     NA     NA    NA   \n 9 Australia Asia-…      23.0   0.93 66604.     2.68    0.63   0.89   4.85  0.11\n10 Austria   Europ…       8.46  0.88 51274.     0.82    0.27   0.63   4.14  0.06\n# ℹ 178 more rows\n# ℹ 4 more variables: Total <dbl>, EarthsRequired <dbl>,\n#   CountriesRequired <dbl>, DataQuality <chr>"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#country-footprint-data",
    "href": "slides/slides-05-data-vis.html#country-footprint-data",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data",
    "text": "Country footprint data\nData on the ecological footprint by country in 2023\n\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 182 × 15\n   Country       Region  SDGi Life_Exectancy   HDI   GDP Income_Group Population\n   <chr>         <chr>  <dbl>          <dbl> <dbl> <dbl> <chr>             <dbl>\n 1 Afghanistan   Middl…  52.5             62  0.48    NA LI                 40.8\n 2 Albania       Other…  71.6             76  0.8  14889 UM                  2.9\n 3 Algeria       Africa  71.5             76  0.75 11137 UM                 45.4\n 4 Angola        Africa  50.9             62  0.59  6304 LM                 35  \n 5 Antigua and … Centr…  NA               78  0.79 18749 HI                  0.1\n 6 Argentina     South…  72.8             75  0.84 22117 UM                 46  \n 7 Armenia       Middl…  71.1             72  0.76 13548 LM                  3  \n 8 Australia     Asia-…  75.6             83  0.95 53053 HI                 26.1\n 9 Austria       EU-27   82.3             81  0.92 55460 HI                  9.1\n10 Azerbaijan    Middl…  73.5             69  0.75 14692 UM                 10.3\n# ℹ 172 more rows\n# ℹ 7 more variables: Cropland <dbl>, Grazing <dbl>, Forest_Product <dbl>,\n#   Carbon <dbl>, Fish <dbl>, Built_up_land <dbl>, Total <dbl>\n\n\n\nData obtained from https://www.kaggle.com/datasets/jainaru/global-ecological-footprint-2023"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#why-do-we-visualize",
    "href": "slides/slides-05-data-vis.html#why-do-we-visualize",
    "title": "Visualizations with ggplot",
    "section": "Why do we visualize?",
    "text": "Why do we visualize?\n\nSummary statistics from each of the four datasets in Anscombe:\n\n\n\n\n# A tibble: 4 × 5\n  set   mean_x mean_y  sd_x  sd_y\n  <fct>  <dbl>  <dbl> <dbl> <dbl>\n1 I          9   7.50  3.32  2.03\n2 II         9   7.50  3.32  2.03\n3 III        9   7.5   3.32  2.03\n4 IV         9   7.50  3.32  2.03\n\n\n\n\nLet’s visualize the four data sets. What would be an appropriate type of plot to examine the relationship between the two variables?"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#common-plots-numerical",
    "href": "slides/slides-05-data-vis.html#common-plots-numerical",
    "title": "Visualizations with ggplot",
    "section": "Common plots (numerical)",
    "text": "Common plots (numerical)"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#aesthetics",
    "href": "slides/slides-05-data-vis.html#aesthetics",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics",
    "text": "Aesthetics\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age,\n                                       shape = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, alpha = age,\n                                       shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#faceting",
    "href": "slides/slides-05-data-vis.html#faceting",
    "title": "Visualizations with ggplot",
    "section": "Faceting",
    "text": "Faceting"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#modifications",
    "href": "slides/slides-05-data-vis.html#modifications",
    "title": "Visualizations with ggplot",
    "section": "Modifications",
    "text": "Modifications\n\nAdding title\nChanging axis title"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#common-plots-numerical-in-ggplot",
    "href": "slides/slides-05-data-vis.html#common-plots-numerical-in-ggplot",
    "title": "Visualizations with ggplot",
    "section": "Common plots (numerical) in ggplot",
    "text": "Common plots (numerical) in ggplot\n\nWe have learned about histograms, density plots, boxplots, and scatterplots\nNow learn how to create these plots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\nThis is what the code will generally look like. Values in < > denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, \n       mapping = aes(x = <x-var>, y = <y-var>)) +\n  geom_xxx() +\n  <other options>\n\n\n\n\nNew lines and spacing don’t impact the execution of code, but are important for good coding style!"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#additional-variables",
    "href": "slides/slides-05-data-vis.html#additional-variables",
    "title": "Visualizations with ggplot",
    "section": "Additional variables",
    "text": "Additional variables\n\nDepending on the plot and data, we can map additional variables by using aesthetics (color, size, shape, alpha (transparency) or faceting"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#live-code",
    "href": "slides/slides-05-data-vis.html#live-code",
    "title": "Visualizations with ggplot",
    "section": "Live code",
    "text": "Live code\nNote: most of the code I will show will be presented at the end of these slides. However, we will most likely go off-script based on questions from the class!"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_histogram",
    "href": "slides/slides-05-data-vis.html#geom_histogram",
    "title": "Visualizations with ggplot",
    "section": "geom_histogram()",
    "text": "geom_histogram()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram()\n\n\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram(binwidth = 5000)\n\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram(bins = 20)"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_density",
    "href": "slides/slides-05-data-vis.html#geom_density",
    "title": "Visualizations with ggplot",
    "section": "geom_density()",
    "text": "geom_density()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_density()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_boxplot",
    "href": "slides/slides-05-data-vis.html#geom_boxplot",
    "title": "Visualizations with ggplot",
    "section": "geom_boxplot()",
    "text": "geom_boxplot()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#side-by-side-boxplots",
    "href": "slides/slides-05-data-vis.html#side-by-side-boxplots",
    "title": "Visualizations with ggplot",
    "section": "Side-by-side boxplots",
    "text": "Side-by-side boxplots\n\nggplot(data = insurance, mapping = aes(x = sex, y = charges)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#geom_point",
    "href": "slides/slides-05-data-vis.html#geom_point",
    "title": "Visualizations with ggplot",
    "section": "geom_point()",
    "text": "geom_point()\n\nggplot(data = insurance, mapping = aes(x = age, y = charges)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#when-to-map-to-variable",
    "href": "slides/slides-05-data-vis.html#when-to-map-to-variable",
    "title": "Visualizations with ggplot",
    "section": "When to map to variable",
    "text": "When to map to variable\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point(col = \"purple\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = \"purple\")) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#facet_wrap",
    "href": "slides/slides-05-data-vis.html#facet_wrap",
    "title": "Visualizations with ggplot",
    "section": "facet_wrap()",
    "text": "facet_wrap()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker)\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker, scales = \"free_y\")"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#facet_grid",
    "href": "slides/slides-05-data-vis.html#facet_grid",
    "title": "Visualizations with ggplot",
    "section": "facet_grid()",
    "text": "facet_grid()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_grid(sex ~ smoker)"
  },
  {
    "objectID": "slides/slides-05-data-vis.html#adding-titles",
    "href": "slides/slides-05-data-vis.html#adding-titles",
    "title": "Visualizations with ggplot",
    "section": "Adding titles",
    "text": "Adding titles\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\") +\n  xlab(\"Charges ($)\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  labs(title = \"Histogram of charges\",\n       x = \"Charges ($)\", y = \"Count\")"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#looking-at-your-data",
    "href": "slides/slides-06-categorical-data.html#looking-at-your-data",
    "title": "Categorical data",
    "section": "Looking at your data",
    "text": "Looking at your data\nIs your data tidy, or do you have a table of counts (i.e. a frequency table)?\n\n\n\n\n\n\n\n# A tibble: 5 × 1\n  fruit \n  <chr> \n1 apple \n2 apple \n3 orange\n4 apple \n5 orange\n\n\n\n\n\n# A tibble: 2 × 2\n  fruit  number\n  <chr>   <dbl>\n1 apple       3\n2 orange      2"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#univariate-visualizations",
    "href": "slides/slides-06-categorical-data.html#univariate-visualizations",
    "title": "Categorical data",
    "section": "Univariate visualizations",
    "text": "Univariate visualizations\nIf we are interested in visualizing the distribution of a single categorical variable, it is common to use a barplot, where the different levels are displayed on ones axis and the counts of each level are portrayed on the the other axis.\n\n\n# A tibble: 2 × 2\n  smoker     n\n  <chr>  <int>\n1 no       155\n2 yes       45"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#contingency-tables",
    "href": "slides/slides-06-categorical-data.html#contingency-tables",
    "title": "Categorical data",
    "section": "Contingency tables",
    "text": "Contingency tables\n\nPerhaps we are interested in examining the distribution of two categorical variables at the same time\nWe can summarize the distribution using a two-way table of counts known as a contingency table, where each value in the table count the number of times a particular combination of variable 1 and variable 2 outcomes/levels occurred\n\n\n\n\nContingency table\n\n\nsmoker\nfemale\nmale\n\n\n\n\nno\n87\n68\n\n\nyes\n17\n28\n\n\n\n\n\n\n\nNote: can easily obtain the distribution of just one of the variables by looking row-wise or column-wise\n\nWe essentially convert the contingency table to a visualization to visualize the distribution of two categorical variables"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#dodged-bar-plot",
    "href": "slides/slides-06-categorical-data.html#dodged-bar-plot",
    "title": "Categorical data",
    "section": "Dodged bar plot",
    "text": "Dodged bar plot\nThe dodged bar plot directly converts the contingency table to a visualization.\n\n\n\n\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#stacked-bar-plot",
    "href": "slides/slides-06-categorical-data.html#stacked-bar-plot",
    "title": "Categorical data",
    "section": "Stacked bar plot",
    "text": "Stacked bar plot\n\n\nThe stacked bar plot looks at the counts either row-wise or column-wise.\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#proportions",
    "href": "slides/slides-06-categorical-data.html#proportions",
    "title": "Categorical data",
    "section": "Proportions",
    "text": "Proportions\nCan convert the contingency table to proportions row-wise or column-wise to obtain the fractional breakdown of one variable in another.\n\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\n\n\n\nRow-wise proportions\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    0.561 \n    0.439 \n  \n  \n    yes \n    0.378 \n    0.622 \n  \n\n\n\n\n\n\n\n\n\n\n\nWhat does the quantity 0.378 represent?\nIf we take the proportions row-wise, does each row need to sum to 1?\nIf we take the proportions row-wise, does each column need to sum to 1?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#proportions-cont.",
    "href": "slides/slides-06-categorical-data.html#proportions-cont.",
    "title": "Categorical data",
    "section": "Proportions (cont.)",
    "text": "Proportions (cont.)\n\nSet up how to find the column-wise proportions using our contingency table\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#standardized-bar-plot",
    "href": "slides/slides-06-categorical-data.html#standardized-bar-plot",
    "title": "Categorical data",
    "section": "Standardized bar plot",
    "text": "Standardized bar plot\nThe standardized bar plot visualizes these row-wise or column-wise proportions."
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#choosing-a-bar-plot",
    "href": "slides/slides-06-categorical-data.html#choosing-a-bar-plot",
    "title": "Categorical data",
    "section": "Choosing a bar plot",
    "text": "Choosing a bar plot\n\n\n\nUsing any of the plots, do you believe the smoker status and sex are associated?\nWhen might you prefer to use the stacked, dodged, or standardized bar plot?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#live-code",
    "href": "slides/slides-06-categorical-data.html#live-code",
    "title": "Categorical data",
    "section": "Live code",
    "text": "Live code\n\nBar plots\nAesthetics: fill, shape\nFaceting"
  },
  {
    "objectID": "live_code/dplyr.html",
    "href": "live_code/dplyr.html",
    "title": "Data wrangling with dplyr",
    "section": "",
    "text": "library(tidyverse)\n\n## modify this line accordingly!\ndatascience <- read_csv(\"data/datascience_survey_subset.csv\")\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "live_code/dplyr.html#selecting-a-single-column",
    "href": "live_code/dplyr.html#selecting-a-single-column",
    "title": "Untitled",
    "section": "Selecting a single column",
    "text": "Selecting a single column\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,618 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    21\n 7    22\n 8    29\n 9    35\n10    37\n# ℹ 2,608 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,618 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    21\n 7    22\n 8    29\n 9    35\n10    37\n# ℹ 2,608 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe the data frame using |> the select() function and specify that we want the variable Age\nThe result is a data frame with 2618 rows and 1 column\n\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "practice_probs/practice-04-numerical-data-pt2.html",
    "href": "practice_probs/practice-04-numerical-data-pt2.html",
    "title": "Numerical data (part 2)",
    "section": "",
    "text": "Please work on the practice problems in your group. Problems with an asterisk \\(^*\\) will be assigned to the weekly problem set.\n\nThe infant mortality rate is defined as the number of infant deaths per 1,000 live births. This rate is often used as an indicator of the level of health in a country. The histogram below shows the distribution of estimated infant death rates for 224 countries for which such data were available in 2014. In particular, this is a relative frequency histogram, which shows proportions instead of raw counts on the y-axis:\n\n\nEstimate \\(Q_{1}\\), the median \\(m\\), and \\(Q_{3}\\) from the histogram.\nWould you expect the mean of this dataset to be smaller or larger than the median? Explain your reasoning.\n\nSuppose that an exam has a total of 100 possible points, and the average score was an 85 with standard deviation of 15. Is the distribution of the scores on this exam symmetric? If not, what shape would you expect this distribution to have? Explain your reasoning.\nFor registered students at universities in the United States, do you expect the average age or the median age to be larger? Why?\n(\\(^*\\)) The statistic \\(\\frac{\\bar{x}}{m}\\) can be used as a measure of skewness. Suppose we have a distribution where all observations are greater than 0 (i.e. \\(x_{i} > 0\\) for all observations \\(i = 1,\\ldots, n\\)). What is the expected shape of the distribution under the following conditions? Explain your reasoning.\n\n\\(\\frac{\\bar{x}}{m} = 1\\)\n\\(\\frac{\\bar{x}}{m} > 1\\)\n\\(\\frac{\\bar{x}}{m} > 1\\)"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#data",
    "href": "slides/slides-03-numerical-pt1.html#data",
    "title": "Numerical data",
    "section": "Data",
    "text": "Data\nWhich of the following variables are numerical?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#scatterplots",
    "href": "slides/slides-03-numerical-pt1.html#scatterplots",
    "title": "Numerical data",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots are bivariate (two-variable) visualizations that provide a case-by-case view of the data for two numerical variables\n\nEach point represents the observed pair of values of variables 1 and 2 for a case in the dataset"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#live-code",
    "href": "slides/slides-03-numerical-pt1.html#live-code",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\nIf you’d like to follow along, please download the .Rmd template associated with today’s class! Otherwise, feel free to just watch and try coding on your own later on.\nWe will cover:\n\nScatterplots and histograms in base R"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#scatterplots-cont.",
    "href": "slides/slides-03-numerical-pt1.html#scatterplots-cont.",
    "title": "Numerical data",
    "section": "Scatterplots (cont.)",
    "text": "Scatterplots (cont.)\n\nHow do we determine which variable to put on each axis?\nWhat do scatterplots reveal about the data, and how are they useful?\n\n\nAssociations/patterns (linear, exponential, etc) between two variables. They might not tell the complete story, however!\nPositive vs negative associations"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#dot-plots",
    "href": "slides/slides-03-numerical-pt1.html#dot-plots",
    "title": "Numerical data",
    "section": "Dot plots",
    "text": "Dot plots\n\nDot plots are a basic visualization that show the distribution of a single variable (univariate)\nIn the following, we have a dot plot of BMI rounded to the nearest integer.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTypically, one dot for each case in our data. What is a disadvantage of dot plots?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#binning",
    "href": "slides/slides-03-numerical-pt1.html#binning",
    "title": "Numerical data",
    "section": "Binning",
    "text": "Binning\n\nWe will sacrifice a bit more of precision for convenience by binning:\n\nSegment the variable into equal-sized bins\nVisualize the value of each observation using its corresponding bin\n\nFor example, the bmi variable has observed values of \\(15.96\\) through \\(49.6\\). Consider the following bins of size 5: [15, 19), [19, 23), [23, 27), …, [49, 53)\n\nConvention of left or right inclusive?\n\nWe tabulate/count up the number of observations that fall into each bin."
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#histograms",
    "href": "slides/slides-03-numerical-pt1.html#histograms",
    "title": "Numerical data",
    "section": "Histograms",
    "text": "Histograms\nHistograms are visualizations that display the binned counts as bars for each bin.\n\nHistograms provide a view of the density of the data (the values the data take on as well as how often)\n\n\n\n\n\n\n\n\n\nbmi_bin\ncount\n\n\n\n\n[15, 19)\n5\n\n\n[19, 23)\n12\n\n\n[23, 27)\n35\n\n\n[27, 31)\n58\n\n\n[31, 35)\n41\n\n\n[35, 39)\n35\n\n\n[39, 43)\n13\n\n\n[49, 52)\n1"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#histograms-cont.",
    "href": "slides/slides-03-numerical-pt1.html#histograms-cont.",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHow would you describe the shape of the distributions in the following two histograms?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#histograms-cont.-1",
    "href": "slides/slides-03-numerical-pt1.html#histograms-cont.-1",
    "title": "Numerical data",
    "section": "Histograms (cont.)",
    "text": "Histograms (cont.)\n\nHow would you describe the shape and modality in the following two histograms?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#mean",
    "href": "slides/slides-03-numerical-pt1.html#mean",
    "title": "Numerical data",
    "section": "Mean",
    "text": "Mean\n\nBy far the most common way to measure the center of the distribution of a numerical variable is using the mean (also called the average)\nWe use the term sample mean when calculating a mean using sampled data. The sample mean is typically denoted as \\(\\bar{x}\\)\n\n\\(x\\) is a placeholder for the variable of interest (e.g. BMI, charges)\nThe bar communicates that we are looking at the average\n\nThe sample mean is the sum over all the observed values of the variable, divided by total number of observations \\(n\\):\n\n\n\\[\\bar{x} = \\frac{x_{1} + x_{2} + \\ldots x_{n}}{n} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\]"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#mean-cont.",
    "href": "slides/slides-03-numerical-pt1.html#mean-cont.",
    "title": "Numerical data",
    "section": "Mean (cont.)",
    "text": "Mean (cont.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe sample mean \\(\\bar{x}\\) is an example of a sample statistic\nThe mean over the entire population is an example of a population parameter. The population mean is often denoted \\(\\mu\\) (Greek letter mu)\nThe sample mean \\(\\bar{x}\\) is often used as an estimate for \\(\\mu\\) (more on this in STAT 311!)"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#example",
    "href": "slides/slides-03-numerical-pt1.html#example",
    "title": "Numerical data",
    "section": "Example",
    "text": "Example\nWe will be looking at some medical insurance data throughout these slides.\n\nWhich of the following variables are numerical? Which are discrete vs. continuous?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#means-depend-on-proportions",
    "href": "slides/slides-03-numerical-pt1.html#means-depend-on-proportions",
    "title": "Numerical data",
    "section": "Means depend on proportions",
    "text": "Means depend on proportions\n\n\nWhat is the average of the following values? \\(\\qquad 1, 4, 4\\)\nIf instead there were ten 1’s and twenty 4’s, would the average be the same?\n\n\n\n\\(\\bar{x} = \\frac{1+4+4}{3} = 1\\left(\\frac{1}{3} \\right) + 4\\left( \\frac{2}{3}\\right) = \\frac{9}{3} = 3\\)\n\\(\\bar{x} = 1\\left(\\frac{10}{30}\\right) + 4 \\left(\\frac{20}{30} \\right) = \\frac{90}{30} = 3\\)"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variability",
    "href": "slides/slides-03-numerical-pt1.html#variability",
    "title": "Numerical data",
    "section": "Variability",
    "text": "Variability\n\nHowever, at the heart of statistics is also the variability or spread of the distribution of the variable\nWe will work with variance and standard deviation, which are ways to describe how spread out data are from their mean"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#deviation",
    "href": "slides/slides-03-numerical-pt1.html#deviation",
    "title": "Numerical data",
    "section": "Deviation",
    "text": "Deviation\nWe begin with deviation, which is the distance or difference between an observation from the (sample) mean\n\nHow might we write this using statistical notation?\nLet’s write out the deviations of our estimated weights"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation",
    "href": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation",
    "title": "Numerical data",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\n\nThe sample variance \\(s^2\\) squares the deviations and takes an average:\n\\[\ns^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\n\\]\n\nLet’s talk about this notation and intuition behind this formula. In particular, there are at least two things to note\n\n\nSet-up the calculation of the sample variance for our data\n\n\nI will calculate this in R\n\nThe sample standard deviation \\(s\\) is the simply the square root of the sample variance (\\(s = \\sqrt{s^2}\\))"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation-cont.",
    "href": "slides/slides-03-numerical-pt1.html#variance-and-standard-deviation-cont.",
    "title": "Numerical data",
    "section": "Variance and standard deviation (cont.)",
    "text": "Variance and standard deviation (cont.)\n\nLike the mean, the population values for variance and standard deviation are denoted with Greek letters:\n\n\\(\\sigma\\) for population standard deviation (sigma)\n\\(\\sigma^2\\) for population variance\n\n\nIf the calculation of standard deviation is a more complicated quantity than the variance, why do we bother with standard deviation?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#comparing-numerical-data-across-groups",
    "href": "slides/slides-04-numerical-pt2.html#comparing-numerical-data-across-groups",
    "title": "Numerical data",
    "section": "Comparing numerical data across groups",
    "text": "Comparing numerical data across groups\n\nWhile we haven’t yet discussed categorical data, it is common to want to visualize the distribution of a numerical variable across different groups/levels of a categorical variable"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#live-code",
    "href": "slides/slides-04-numerical-pt2.html#live-code",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\n\nmedian()\nBoxplots in base R"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html",
    "href": "slides/slides-06-categorical-data.html",
    "title": "Categorical data",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#factoring",
    "href": "slides/slides-06-categorical-data.html#factoring",
    "title": "Categorical data",
    "section": "Factoring",
    "text": "Factoring"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html",
    "href": "slides/slides-05-numerical-data-viz.html",
    "title": "Visualizations with ggplot",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 1338 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#exploratory-data-analysis",
    "href": "slides/slides-05-numerical-data-viz.html#exploratory-data-analysis",
    "title": "Visualizations with ggplot",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nExploratory data analysis (EDA) is an approach to analyzing data sets to summarize the main characteristics.\n\nOften visual through plots\n\nBecause of its name “exploratory”, we typically perform EDA at the beginning of a project\nCan also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#tidy-data",
    "href": "slides/slides-05-numerical-data-viz.html#tidy-data",
    "title": "Visualizations with ggplot",
    "section": "Tidy data",
    "text": "Tidy data\n\nWhen working with data in R, always look at the data to ensure it is in tidy format:\n\nEach row represents an observation, each column represents a variable describing the observations\n\nanscombe data frame: four datasets each with 11 observations each and the same two variables\n\n\n\n\nNon-tidy version:\n\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\n\nTidy version (first 15 rows):\n\n\n   set  x     y\n1    I 10  8.04\n2    I  8  6.95\n3    I 13  7.58\n4    I  9  8.81\n5    I 11  8.33\n6    I 14  9.96\n7    I  6  7.24\n8    I  4  4.26\n9    I 12 10.84\n10   I  7  4.82\n11   I  5  5.68\n12  II 10  9.14\n13  II  8  8.14\n14  II 13  8.74\n15  II  9  8.77"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#why-do-we-visualize",
    "href": "slides/slides-05-numerical-data-viz.html#why-do-we-visualize",
    "title": "Visualizations with ggplot",
    "section": "Why do we visualize?",
    "text": "Why do we visualize?\n\nSummary statistics from each of the four datasets in anscombe:\n\n\n\n\n# A tibble: 4 × 5\n  set   mean_x mean_y  sd_x  sd_y\n  <fct>  <dbl>  <dbl> <dbl> <dbl>\n1 I          9   7.50  3.32  2.03\n2 II         9   7.50  3.32  2.03\n3 III        9   7.5   3.32  2.03\n4 IV         9   7.50  3.32  2.03\n\n\n\n\nLet’s visualize the four data sets. What would be an appropriate type of plot to examine the relationship between the two variables x and y?"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#common-plots-numerical-in-ggplot",
    "href": "slides/slides-05-numerical-data-viz.html#common-plots-numerical-in-ggplot",
    "title": "Visualizations with ggplot",
    "section": "Common plots (numerical) in ggplot",
    "text": "Common plots (numerical) in ggplot\n\nWe have learned about histograms, density plots, boxplots, and scatterplots, and how to code them in base R\nNow learn how to create these plots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\n\nHow does this differ from what we’ve seen in the past?\n\nThis is what the code will generally look like. Values in < > denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, \n       mapping = aes(x = <x-var>, y = <y-var>)) +\n  geom_xxx() +\n  <other options>\n\n\n\n\nNew lines and spacing don’t impact the execution of code, but are important for good coding style!"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#country-footprint-data",
    "href": "slides/slides-05-numerical-data-viz.html#country-footprint-data",
    "title": "Visualizations with ggplot",
    "section": "Country footprint data",
    "text": "Country footprint data\nData on the ecological footprint by country in 2023\n\n\nfootprint_data <- read_csv(\"data/countries_footprint.csv\")\nfootprint_data\n\n# A tibble: 182 × 15\n   Country       Region  SDGi Life_Exectancy   HDI   GDP Income_Group Population\n   <chr>         <chr>  <dbl>          <dbl> <dbl> <dbl> <chr>             <dbl>\n 1 Afghanistan   Middl…  52.5             62  0.48    NA LI                 40.8\n 2 Albania       Other…  71.6             76  0.8  14889 UM                  2.9\n 3 Algeria       Africa  71.5             76  0.75 11137 UM                 45.4\n 4 Angola        Africa  50.9             62  0.59  6304 LM                 35  \n 5 Antigua and … Centr…  NA               78  0.79 18749 HI                  0.1\n 6 Argentina     South…  72.8             75  0.84 22117 UM                 46  \n 7 Armenia       Middl…  71.1             72  0.76 13548 LM                  3  \n 8 Australia     Asia-…  75.6             83  0.95 53053 HI                 26.1\n 9 Austria       EU-27   82.3             81  0.92 55460 HI                  9.1\n10 Azerbaijan    Middl…  73.5             69  0.75 14692 UM                 10.3\n# ℹ 172 more rows\n# ℹ 7 more variables: Cropland <dbl>, Grazing <dbl>, Forest_Product <dbl>,\n#   Carbon <dbl>, Fish <dbl>, Built_up_land <dbl>, Total <dbl>\n\n\n\nData obtained from https://www.kaggle.com/datasets/jainaru/global-ecological-footprint-2023"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#additional-variables",
    "href": "slides/slides-05-numerical-data-viz.html#additional-variables",
    "title": "Visualizations with ggplot",
    "section": "Additional variables",
    "text": "Additional variables\n\nDepending on the plot and data, we can map additional variables by using aesthetics (color, size, shape, alpha (transparency) or faceting"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#modifications",
    "href": "slides/slides-05-numerical-data-viz.html#modifications",
    "title": "Visualizations with ggplot",
    "section": "Modifications",
    "text": "Modifications\n\nAdding title\nChanging axis title"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#live-code",
    "href": "slides/slides-05-numerical-data-viz.html#live-code",
    "title": "Visualizations with ggplot",
    "section": "Live code",
    "text": "Live code\nNote: most of the code I will show is included in the remaining slides. However, we will most likely go off-script based on questions from the class!"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_histogram",
    "href": "slides/slides-05-numerical-data-viz.html#geom_histogram",
    "title": "Visualizations with ggplot",
    "section": "geom_histogram()",
    "text": "geom_histogram()\n\nggplot(data = insurance,  mapping = aes(x = charges)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\nNote the message provided when you execute this code!"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_density",
    "href": "slides/slides-05-numerical-data-viz.html#geom_density",
    "title": "Visualizations with ggplot",
    "section": "geom_density()",
    "text": "geom_density()\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_density()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_boxplot",
    "href": "slides/slides-05-numerical-data-viz.html#geom_boxplot",
    "title": "Visualizations with ggplot",
    "section": "geom_boxplot()",
    "text": "geom_boxplot()\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(y = charges)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#side-by-side-boxplots",
    "href": "slides/slides-05-numerical-data-viz.html#side-by-side-boxplots",
    "title": "Visualizations with ggplot",
    "section": "Side-by-side boxplots",
    "text": "Side-by-side boxplots\n\nggplot(data = insurance, mapping = aes(x = sex, y = charges)) +\n  geom_boxplot()\n\n\n\n\n\n\nBivariate plot for a numerical and a categorical variable."
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_point",
    "href": "slides/slides-05-numerical-data-viz.html#geom_point",
    "title": "Visualizations with ggplot",
    "section": "geom_point()",
    "text": "geom_point()\n\nggplot(data = insurance, mapping = aes(x = age, y = charges)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetics",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetics",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics",
    "text": "Aesthetics\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, \n                                       col = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age,\n                                       shape = smoker)) +\n  geom_point()\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, alpha = age,\n                                       shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#when-to-map-to-variable",
    "href": "slides/slides-05-numerical-data-viz.html#when-to-map-to-variable",
    "title": "Visualizations with ggplot",
    "section": "When to map to variable",
    "text": "When to map to variable\nWhat’s going on here?\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges)) +\n  geom_point(col = \"purple\")\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges)) +\n  geom_point(aes(col = \"purple\"))\n\n\n\n\n\n\n\n\n\n\nKey takeaway: aesthetics should correspond/map to a variable in the data frame\n\n\n“Fixed” visual cues are set outside of aes()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#facet_wrap",
    "href": "slides/slides-05-numerical-data-viz.html#facet_wrap",
    "title": "Visualizations with ggplot",
    "section": "facet_wrap()",
    "text": "facet_wrap()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker)\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_wrap(~ smoker, scales = \"free_y\")"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#facet_grid",
    "href": "slides/slides-05-numerical-data-viz.html#facet_grid",
    "title": "Visualizations with ggplot",
    "section": "facet_grid()",
    "text": "facet_grid()\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges)) +\n  geom_point() +\n  facet_grid(sex ~ smoker)"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#adding-titles",
    "href": "slides/slides-05-numerical-data-viz.html#adding-titles",
    "title": "Visualizations with ggplot",
    "section": "Adding titles",
    "text": "Adding titles\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\") +\n  xlab(\"Charges ($)\")\n\n\n\n\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  labs(title = \"Histogram of charges\",\n       x = \"Charges ($)\", y = \"Count\")"
  },
  {
    "objectID": "live_code/dplyr.html#selecting-columns",
    "href": "live_code/dplyr.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 2288 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    31 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:EmploymentStatus)\n\n# A tibble: 2,288 × 3\n   Gender   Age EmploymentStatus                                    \n   <chr>  <dbl> <chr>                                               \n 1 Male      56 Independent contractor, freelancer, or self-employed\n 2 Male      33 Employed full-time                                  \n 3 Male      26 Employed full-time                                  \n 4 Male      25 Employed part-time                                  \n 5 Male      33 Employed full-time                                  \n 6 Male      22 Employed full-time                                  \n 7 Male      29 Employed full-time                                  \n 8 Male      35 Employed full-time                                  \n 9 Male      37 Employed full-time                                  \n10 Male      31 Employed part-time                                  \n# ℹ 2,278 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 2,288 × 16\n   Gender   Age EmploymentStatus          EmployerIndustry FormalEducation Major\n   <chr>  <dbl> <chr>                     <chr>            <chr>           <chr>\n 1 Male      56 Independent contractor, … Mix of fields    Master's degree Math…\n 2 Male      33 Employed full-time        Internet-based   Bachelor's deg… Other\n 3 Male      26 Employed full-time        Financial        Master's degree Comp…\n 4 Male      25 Employed part-time        Academic         Bachelor's deg… Phys…\n 5 Male      33 Employed full-time        Telecommunicati… Doctoral degree Elec…\n 6 Male      22 Employed full-time        Mix of fields    Bachelor's deg… Info…\n 7 Male      29 Employed full-time        Pharmaceutical   Master's degree Comp…\n 8 Male      35 Employed full-time        Technology       Doctoral degree Phys…\n 9 Male      37 Employed full-time        Technology       Master's degree Elec…\n10 Male      31 Employed part-time        Technology       Doctoral degree Comp…\n# ℹ 2,278 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>"
  },
  {
    "objectID": "live_code/dplyr.html#arranging-rows",
    "href": "live_code/dplyr.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1     0 Mathematics or statistics                                   \n 2     1 Other                                                       \n 3    19 Computer Science                                            \n 4    19 Biology                                                     \n 5    20 Information technology, networking, or system administration\n 6    20 Mathematics or statistics                                   \n 7    20 Computer Science                                            \n 8    20 Mathematics or statistics                                   \n 9    21 Other                                                       \n10    21 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/dplyr.html#slicing-for-certain-row-numbers",
    "href": "live_code/dplyr.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row in index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 17\n  Country   Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n  <chr>     <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n1 United S… Male      56 Independent con… Mix of fields    Master's degree Math…\n2 Russia    Male      33 Employed full-t… Internet-based   Bachelor's deg… Other\n3 Taiwan    Male      26 Employed full-t… Financial        Master's degree Comp…\n4 United S… Male      25 Employed part-t… Academic         Bachelor's deg… Phys…\n5 United S… Male      33 Employed full-t… Telecommunicati… Doctoral degree Elec…\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/dplyr.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/dplyr.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we only retain the observations where the person’s Major was Computer Science:\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 681 × 17\n   Country  Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n   <chr>    <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n 1 Taiwan   Male      26 Employed full-t… Financial        Master's degree Comp…\n 2 Poland   Male      29 Employed full-t… Pharmaceutical   Master's degree Comp…\n 3 Iran     Male      31 Employed part-t… Technology       Doctoral degree Comp…\n 4 Brazil   Male      25 Employed full-t… Academic         Master's degree Comp…\n 5 Brazil   Male      32 Employed full-t… Academic         Master's degree Comp…\n 6 Russia   Male      31 Independent con… CRM/Marketing    Some college/u… Comp…\n 7 India    Male      23 Employed full-t… Technology       Master's degree Comp…\n 8 Canada   Male      52 Employed full-t… Academic         Bachelor's deg… Comp…\n 9 Russia   Male      26 Independent con… Military/Securi… Bachelor's deg… Comp…\n10 Czech R… Male      25 Independent con… Internet-based   Master's degree Comp…\n# ℹ 671 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”:\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Computer Science    30\n10 Computer Science    30\n# ℹ 26 more rows\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 765 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    31\n 4 Computer Science    25\n 5 Computer Science    32\n 6 Computer Science    31\n 7 A social science    30\n 8 Computer Science    23\n 9 Biology             30\n10 Computer Science    52\n# ℹ 755 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 44 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Other               30\n10 Computer Science    30\n# ℹ 34 more rows"
  },
  {
    "objectID": "live_code/dplyr.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/dplyr.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 5 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n5 I prefer not to answer                                           \n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 58 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree A social science                                           \n 5 Bachelor's degree Electrical Engineering                                     \n 6 Bachelor's degree Mathematics or statistics                                  \n 7 Bachelor's degree Computer Science                                           \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree A humanities discipline                                    \n10 Bachelor's degree Management information systems                             \n# ℹ 48 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/dplyr.html#mutate-to-add-a-new-variable",
    "href": "live_code/dplyr.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify the name of the new variable and how to calculate the value of that variable for each observation:\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 2,288 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              15000              15\n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/dplyr.html#counting-to-create-frequency-tables",
    "href": "live_code/dplyr.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(EmployerIndustry)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 CRM/Marketing                       70\n 3 Financial                          211\n 4 Government                         137\n 5 Hospitality/Entertainment/Sports    27\n 6 Insurance                           68\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 Military/Security                   35\n10 Mix of fields                      195\n11 Non-profit                          35\n12 Other                              198\n13 Pharmaceutical                      54\n14 Retail                              61\n15 Technology                         445\n16 Telecommunications                  65\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(EmployerIndustry, sort = T)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\ndatascience |>\n  count(EmployerIndustry) |>\n  arrange(desc(n))\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/dplyr.html#practice",
    "href": "live_code/dplyr.html#practice",
    "title": "Data wrangling with dplyr",
    "section": "Practice",
    "text": "Practice\nSuppose I want to report a data frame that reports each unique level of Major and the proportion of times each level was observed in the data set in order of most popular to least popular. How might we do that?\n\n\nCode\ndatascience |>\n  count(Major) |>\n  mutate(prop = n/sum(n)) |>\n  select(Major, prop) |>\n  arrange(desc(prop))"
  },
  {
    "objectID": "live_code/dplyr.html#summarising-for-summary-statistics",
    "href": "live_code/dplyr.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     34.4\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a single/multiple summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead?"
  },
  {
    "objectID": "live_code/dplyr.html#grouping-by-grouped-operations",
    "href": "live_code/dplyr.html#grouping-by-grouped-operations",
    "title": "Data wrangling with dplyr",
    "section": "Grouping by grouped operations",
    "text": "Grouping by grouped operations\nSometimes, we want to look at a given statistic or create a new variable focusing on each level of a specific categorical variable. The group_by() function tells R to treat each unique level as a separate data set.\n\ndatascience |>\n  group_by(EmploymentStatus) |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 3 × 2\n  EmploymentStatus                                     mean_age\n  <chr>                                                   <dbl>\n1 Employed full-time                                       34.3\n2 Employed part-time                                       29.5\n3 Independent contractor, freelancer, or self-employed     39.0"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#working-dataset",
    "href": "slides/slides-07-wrangling.html#working-dataset",
    "title": "Data wrangling with dplyr",
    "section": "Working dataset",
    "text": "Working dataset\nData from Kaggle: In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\n\nLet’s go ahead and pull to get the data locally\nThen open a new .Rmd to work in\nLet’s load in the data together and take a quick look at it before diving into data wrangling"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#grammar-of-data-wrangling",
    "href": "slides/slides-07-wrangling.html#grammar-of-data-wrangling",
    "title": "Data wrangling with dplyr",
    "section": "Grammar of data wrangling",
    "text": "Grammar of data wrangling\n\n\n\n\nRecall: data frames are objects in R that store tabular data in tidy form\nThe dplyr package uses the concept of functions as verbs that manipulate data frames\n\nselect(): pick columns by name\nslice(): pick rows using indices\nfilters(): pick rows matching criteria\ndistinct(): filter for unique rows\nmutate(): add new variables as columns\nsummarise(): reduce variables to quantitative values\ngroup_by(): for grouped operations based on a variable\nand many more!!!"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#rules-of-dplyr-functions",
    "href": "slides/slides-07-wrangling.html#rules-of-dplyr-functions",
    "title": "Data wrangling with dplyr",
    "section": "Rules of dplyr functions",
    "text": "Rules of dplyr functions\n\nThe first argument is always a data frame\nSubsequent argument(s) say what to do with that data frame\n\nWe connect lines to code using a pipe operator (see next slide)\n\nAlways return a data frame, unless specifically told otherwise"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#pipes",
    "href": "slides/slides-07-wrangling.html#pipes",
    "title": "Data wrangling with dplyr",
    "section": "Pipes",
    "text": "Pipes\n\nIn programming, a pipe is a technique for passing information from one process to another\nIn dplyr, the pipes are coded as |> (i.e. vertical bar and greater than sign)\n\nNot to be confused with +\n\nWe can think about pipes as following a sequence of actions which provide a more natural and easier to read structure\nFor example: suppose that in order to get to work, I need to find my car keys, start my car, drive to work, and then park my car\n\n\n\n\nExpressed as a set of nested R pseudocode, this may look like:\n\n\n\npark(drive(start_car(find(\"car_keys\")), \n           to = \"work\"))\n\n\n\n\nExpressed using pipes, this may look like:\n\n\n\nfind(\"car_keys\") |>\n  start_car() |>\n  drive(to = \"work\") |>\n  park()"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#logical-operators-in-r",
    "href": "slides/slides-07-wrangling.html#logical-operators-in-r",
    "title": "Data wrangling with dplyr",
    "section": "Logical operators in R",
    "text": "Logical operators in R\nIt is common to compare two quantities using logical operators. All of these operators will return a logical TRUE or FALSE. List of some common operators:\n\n<: less than\n<=: less than or equal to\n>: greater than\n>=: greater than or equal to\n==: (exactly) equal to\n!=: not equal to\n\n\n\n1 < 4\n\n[1] TRUE\n\n\n\n\n\n2==3\n\n[1] FALSE\n\n\n\n\n\n2!=3\n\n[1] TRUE"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#logical-operators-cont.",
    "href": "slides/slides-07-wrangling.html#logical-operators-cont.",
    "title": "Data wrangling with dplyr",
    "section": "Logical operators (cont.)",
    "text": "Logical operators (cont.)\nWe might also want to know if a certain quantity “behaves” a certain way. The following also return logical outputs:\n\nis.na(x): test if x is NA\nx %in% y: test if x is in y\n!x: not x\n\n\n\nis.na(NA)\n\n[1] TRUE\n\n\n\n\n\nis.na(\"apple\")\n\n[1] FALSE\n\n\n\n\n\n3 %in% 1:10\n\n[1] TRUE\n\n\n\n\n\n!TRUE\n\n[1] FALSE"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#commenting-code",
    "href": "slides/slides-07-wrangling.html#commenting-code",
    "title": "Data wrangling with dplyr",
    "section": "Commenting code",
    "text": "Commenting code\nRecall that in R, we can comment out lines of code using the # symbol. The line of code will still be displayed, but it will not execute:\n\n1 + 1\n\n[1] 2\n\n# 2 * 1\n3 %in% 1:10\n\n[1] TRUE"
  },
  {
    "objectID": "slides/slides-07-wrangling.html#live-code",
    "href": "slides/slides-07-wrangling.html#live-code",
    "title": "Data wrangling with dplyr",
    "section": "Live code",
    "text": "Live code\nData from Kaggle: In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\nCopy and paste the following code into a code chunk in your live code! We will load in the data together and take a quick look at it before diving into data wrangling\n\nlibrary(readr)\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/datascience_survey_subset.csv\""
  },
  {
    "objectID": "slides/slides-07-wrangling.html#piping-to-ggplot",
    "href": "slides/slides-07-wrangling.html#piping-to-ggplot",
    "title": "Data wrangling with dplyr",
    "section": "Piping to ggplot",
    "text": "Piping to ggplot\n\nRemember that when creating plots, the ggplot() function expect a data frame as its first argument\nWe may sometimes need to wrangle data prior to visualizing it. We have two options (both have pros and cons)\n\nWrangle the data, store the resulting data frame with a new variable name, and then refer to that data frame with ggplot(), or\n\n\ndf_new <- df |>\n  mutate(age_months = age*12)\nggplot(df_new, aes(x = age_months)) +\n  geom_histogram()\n\n\nWrangle the data, and then directly pipe the result into ggplot()\n\n\ndf |>\n  mutate(age_months = age*12) |>\n  ggplot(aes(x = age_months)) +\n  geom_histogram()\n\n\n\n\nWhen do we use |> and when do we use + to connect lines of code?"
  },
  {
    "objectID": "slides/slides-08-probability.html#key-terms",
    "href": "slides/slides-08-probability.html#key-terms",
    "title": "Probability basics",
    "section": "Key terms",
    "text": "Key terms\n\nRandom process: a situation in which a particular result, called an outcome, is random/not known ahead of time\n\nExamples: flipping a coin, rolling six-sided die, sports game, if a treatment is effective\n\nA sample space \\(S\\) is the set of all possible outcomes of the random process\n\n\nWhat are possible sample spaces for the above examples?\n\n\nAn event is a set of outcomes from a random process"
  },
  {
    "objectID": "slides/slides-08-probability.html#probability",
    "href": "slides/slides-08-probability.html#probability",
    "title": "Probability basics",
    "section": "Probability",
    "text": "Probability\n\nFor us, the probability of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times\n\nProbability is used to express the likelihood that some outcome or event will or will not occur\nThink of as a proportion\n\nLet \\(A\\) denote some outcome or event. We denote the probability of \\(A\\) occurring as \\(\\text{P}(A)\\) or \\(\\text{Pr}(A)\\).\nWhen the sample space \\(S\\) is discrete with a finite size, then \\(\\text{Pr}(A) = \\frac{\\text{ number of outcomes favorable to } A}{\\text{ number of total outcomes possible} }\\)"
  },
  {
    "objectID": "slides/slides-08-probability.html#example",
    "href": "slides/slides-08-probability.html#example",
    "title": "Probability basics",
    "section": "Example",
    "text": "Example\nLet the random process rolling a fair, six-sided die. Let \\(X\\) a random variable representing the value of the die.\n\nFor each of the following, determine the outcome(s) and event under consideration, along with the value of the probability itself:\n\n\\(\\text{Pr}(X = 1)\\)\n\\(\\text{Pr}(X = 1 \\text{ and } 2)\\)\n\\(\\text{Pr}(X \\text{ is even})\\)\n\n\n\nConvince ourselves that \\(X\\) is a RV. Recall: sample space is 1,..,6.\nPossible outcome is 1, and an event would be \\(X=1\\); the RV being 1.\nPossible event is 1 or 2."
  },
  {
    "objectID": "slides/slides-08-probability.html#operations-with-events",
    "href": "slides/slides-08-probability.html#operations-with-events",
    "title": "Probability basics",
    "section": "Operations with events",
    "text": "Operations with events\nLet \\(A\\) and \\(B\\) be two possible events.\n\nThe intersection of \\(A\\) and \\(B\\) is denoted as \\(A \\cap B\\), and is the set of outcomes that belong to both events \\(A\\) and \\(B\\)\nThe union of \\(A\\) and \\(B\\) is denoted as \\(A \\cup B\\), and is the set of outcomes that belong to \\(A\\) and/or \\(B\\)\n\n\nWhen we have only two or three events, Venn diagrams can be very useful for visualizing probabilities!"
  },
  {
    "objectID": "slides/slides-08-probability.html#addition-rule",
    "href": "slides/slides-08-probability.html#addition-rule",
    "title": "Probability basics",
    "section": "Addition rule",
    "text": "Addition rule\nLet \\(A\\) and \\(B\\) be two possible events. Then the addition rule states that the probability that at least one will occur is:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\nVenn diagram\nExample: in a standard deck of 52 cards, we have four suits (diamond, heart, club, spade) with 13 cards within each suit (1-10, Jack, Queen, King).\n\nSuppose we randomly draw one card from the shuffled deck.\nLet \\(A\\) be the event that the card is a spade.\nLet \\(B\\) be the event that the card is a face card (Jack, Queen or King).\nFind \\(P(A \\cup B)\\)."
  },
  {
    "objectID": "slides/slides-08-probability.html#disjoint-events",
    "href": "slides/slides-08-probability.html#disjoint-events",
    "title": "Probability basics",
    "section": "Disjoint events",
    "text": "Disjoint events\nTwo events are disjoint or mutually exclusive if they cannot simultaneously happen.\n\nThat is, if \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cap B) = ?\\)\n\nIf our random process is rolling a six-sided die one time, what are some examples of disjoint events?"
  },
  {
    "objectID": "slides/slides-08-probability.html#rules-of-probability",
    "href": "slides/slides-08-probability.html#rules-of-probability",
    "title": "Probability basics",
    "section": "Rules of probability",
    "text": "Rules of probability\nKolmogorov axioms\n\nThe probability of any event is non-negative real number\nThe probability of the entire sample space 1\nIf \\(A\\) and \\(B\\) are disjoint, then \\(\\text{Pr}(A \\cup B) = \\text{Pr}(A) + \\text{Pr}(B)\\)\n\n\nThese axioms imply that all probabilities are between 0 and 1 inclusive, and lead to some important rules!"
  },
  {
    "objectID": "slides/slides-08-probability.html#probability-distributions",
    "href": "slides/slides-08-probability.html#probability-distributions",
    "title": "Probability basics",
    "section": "Probability distributions",
    "text": "Probability distributions\nWhen a random variable is discrete, it can be useful to discuss its probability distribution, which is a table of all (disjoint) outcomes and their associated probabilities.\n\n\nLet \\(X\\) be the sum of two fair, six-sided dice. What is the sample space \\(S\\)?\nFill out the table below to display the probability distribution of \\(X\\):\n\n\n\n\n\n\n\\(X\\)\n2\n3\n4\n5\n6\n7\n\n\nProbability\n\n\n\n\n\n\n\n\n\\(X\\)\n8\n9\n10\n11\n12\n\n\n\nProbability\n\n\n\n\n\n\n\n\n\n\n\nWhy not include 1 or 13?"
  },
  {
    "objectID": "slides/slides-08-probability.html#probability-distributions-cont.",
    "href": "slides/slides-08-probability.html#probability-distributions-cont.",
    "title": "Probability basics",
    "section": "Probability distributions (cont.)",
    "text": "Probability distributions (cont.)\nThe probability distribution of a discrete random variable must satisfy the following three rules:\n\nThe outcomes listed must be disjoint\nEach probability must be between 0 and 1 (inclusive)\nThe probabilities must sum to 1\n\n\nLet’s confirm that the distribution we found on the previous slide satisfies these rules!"
  },
  {
    "objectID": "slides/slides-08-probability.html#complement",
    "href": "slides/slides-08-probability.html#complement",
    "title": "Probability basics",
    "section": "Complement",
    "text": "Complement\n\nThe complement of an event \\(A\\) is the set of all outcomes in \\(S\\) that are not in \\(A\\)\n\nDenoted as \\(A^c\\)\n\nContinuing the dice example, if \\(A\\) is the event that a 1 or 2 is rolled, what is \\(A^c\\)?\nComplement rule: \\(\\text{Pr}(A^c) = 1 - \\text{Pr}(A)\\)\n\nLet our random process be the sum of two dice. What is the probability that…\n\nthe sum of the dice is \\(not\\) 6?\nthe sum is at least 4?"
  },
  {
    "objectID": "slides/slides-08-probability.html#demorgans-laws",
    "href": "slides/slides-08-probability.html#demorgans-laws",
    "title": "Probability basics",
    "section": "DeMorgan’s Laws",
    "text": "DeMorgan’s Laws\nLet’s use Venn diagrams to try and determine formulas for the following:\n\nComplement of union: \\((A \\cup B)^c = \\ ?\\)\nComplement of intersection: \\((A \\cap B)^c = \\ ?\\)"
  },
  {
    "objectID": "slides/slides-08-probability.html#independence",
    "href": "slides/slides-08-probability.html#independence",
    "title": "Probability basics",
    "section": "Independence",
    "text": "Independence\n\nQualitatively, two processes are independent if knowing the outcome of one does not provide any information about the outcome of the other process\n\nExamples and non-examples? How to formalize this?\n\nIf \\(A\\) and \\(B\\) are independent events from two different and independent processes, then \\(\\text{Pr}(A \\cap B) = \\text{Pr}(A) \\times \\text{Pr}(B)\\)\nMore generally, if \\(\\text{Pr}(A \\cap B) = \\text{Pr}(A) \\times \\text{Pr}(B)\\) and \\(A\\) and \\(B\\) are events from the same process, then \\(A\\) and \\(B\\) are independent.\n\nThis is known as the multiplication rule for independent events"
  },
  {
    "objectID": "slides/slides-08-probability.html#practice",
    "href": "slides/slides-08-probability.html#practice",
    "title": "Probability basics",
    "section": "Practice",
    "text": "Practice\n\nA Pew Research survey asked 2,373 randomly sampled registered voters their political affiliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 35% of respondents identified as Independent, 23% identified as swing voters, and 11% identified as both.\n\nWhat percent of voters are Independent but not swing voters?\nWhat percent of voters are Independent or swing voters?\nWhat percent of voters are neither Independent nor swing voters?\nIs the event that someone is a swing voter independent of the event that someone is a political Independent?"
  },
  {
    "objectID": "slides/slides-08-probability.html#more-practice",
    "href": "slides/slides-08-probability.html#more-practice",
    "title": "Probability basics",
    "section": "More practice",
    "text": "More practice\n\nA Pew Research survey asked 2,373 randomly sampled registered voters their political afilliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 35% of respondents identified as Independent, 23% identified as swing voters, and 11% identified as both.\n\nWhat percent of voters are Independent but not swing voters?\nWhat percent of voters are Independent or swing voters?\nWhat percent of voters are neither Independent nor swing voters?\nIs the event that someone is a swing voter independent of the event that someone is a political Independent?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#probabilities-with-contingency-tables",
    "href": "slides/slides-09-conditional-probability.html#probabilities-with-contingency-tables",
    "title": "Conditional probability",
    "section": "Probabilities with contingency tables",
    "text": "Probabilities with contingency tables\n\nAs we saw in the previous class, sometimes the probabilities of events are quite clear to calculate (e.g. dice rolls or drawing cards)\nBut oftentimes we have to use data to try and estimate probabilities\n\nWhy? Some probabilities are not known, and we use proportions from data as a proxy\n\nWhen we have two (or more) variables, we often want to understand the relationships between them (e.g. \\(A \\cap B\\))"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#practice",
    "href": "slides/slides-09-conditional-probability.html#practice",
    "title": "Conditional probability",
    "section": "Practice",
    "text": "Practice\n\nSource: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5788283/\n\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\n\n\nDefine events \\(A\\) = died and \\(B\\) = non-coffee drinker. Calculate/set-up the calculations for the following for a randomly selected person in the cohort:\n\n\\(\\text{P}(A)\\)\n\\(\\text{P}(A \\cap B)\\)\n\\(\\text{P}(A \\cup B^c)\\)"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#marginal-and-joint-probabilities",
    "href": "slides/slides-09-conditional-probability.html#marginal-and-joint-probabilities",
    "title": "Conditional probability",
    "section": "Marginal and joint probabilities",
    "text": "Marginal and joint probabilities\n\n\\(\\text{P}(A)\\) is an example of a marginal probability, which is a probability involving a single event\n\nFrom the contingency table, we use row totals or column totals and the overall total to obtain marginal probabilities\n\n\\(\\text{P}(A \\cap B)\\) and \\(\\text{P}(A \\cup B^c)\\) are examples of a joint probability, which is a probability involving two or more events that have yet to occur\n\nFrom the contingency table, we use specific cells and the overall total to obtain joint probabilities"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#marginal-from-joint",
    "href": "slides/slides-09-conditional-probability.html#marginal-from-joint",
    "title": "Conditional probability",
    "section": "Marginal from joint",
    "text": "Marginal from joint\nUsing LoTP, we can obtain the marginal probabilities from joint probabilities (which some of you intuitively did)!\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\n\\[\\begin{align*}\n\\text{P}(B) &=\\text{P}(\\text{no coffee}) \\\\\n&\\overset{\\text{LoTP}}{=} \\text{P}(\\text{no coffee} \\ \\cap \\text{ did not die}) + \\text{P}(\\text{no coffee} \\ \\cap \\text{ died})  \\\\\n&= \\text{P}(B \\cap A) + \\text{P}(B \\cap A^c) \\\\\n&= \\frac{5438}{69164 } + \\frac{1039}{69164} \\\\\n&= 0.0936\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#conditional-probability",
    "href": "slides/slides-09-conditional-probability.html#conditional-probability",
    "title": "Conditional probability",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nConditional probability: a probability that an event will occur given that another event has already occurred\n\nE.g. Given that it rained yesterday, what is the probability that it will rain today?\nIt is called “conditional” because we calculate a probability under a specific condition\n\n\n\n\\(\\text{Pr}(A | B)\\) : probability of \\(A\\) given \\(B\\)\n\nNot to be confused with the coding | which is “or”\nAppears to involve two events, but we assume that the event that is conditioned on (in this case \\(B\\)) has already happened\n\nWe can easily obtain conditional probabilities from contingency tables!"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#conditional-probability-with-contingency-tables",
    "href": "slides/slides-09-conditional-probability.html#conditional-probability-with-contingency-tables",
    "title": "Conditional probability",
    "section": "Conditional probability with contingency tables",
    "text": "Conditional probability with contingency tables\n\n\n\n\nDid not die\nDied\nTotal\n\n\n\n\nDoes not drink coffee\n5438\n1039\n6477\n\n\nDrinks coffee occasionally\n29712\n4440\n34152\n\n\nDrinks coffee regularly\n24934\n3601\n28535\n\n\nTotal\n60084\n9080\n69164\n\n\n\n\nFrom contingency table, we use specific cells and row or column totals to obtain conditional probabilities\n\n\n\nRecall events \\(A\\) = died and \\(B\\) = non-coffee drinker. Write \\(\\text{P}()\\) notation for the conditional probability of dying given that someone does not drink coffee, and then obtain this probability."
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#conditional-probability-formula",
    "href": "slides/slides-09-conditional-probability.html#conditional-probability-formula",
    "title": "Conditional probability",
    "section": "Conditional probability formula",
    "text": "Conditional probability formula\nWe can re-arrange the general multiplication formula to obtain the following general formula for conditional probability. For any events \\(A\\) and \\(B\\):\n\n\\[\n\\text{P}(A| B) = \\frac{\\text{P}(A \\cap B)}{\\text{P}(B)}\n\\]\n\n\n\nCome up with a similar formula for \\(\\text{P}(B|A)\\)\n\n\nNote: complement rule holds for conditional probabilities if we condition on the same information: \\(\\text{P}(A|B) = 1 - \\text{P}(A^c | B)\\)"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#independence-and-conditional-probabilities",
    "href": "slides/slides-09-conditional-probability.html#independence-and-conditional-probabilities",
    "title": "Conditional probability",
    "section": "Independence and conditional probabilities",
    "text": "Independence and conditional probabilities\n\nRecall, events \\(A\\) and \\(B\\) are independent when what is true about their joint probability?\nUsing the general multiplication rule, what is another way to determine if events \\(A\\) and \\(B\\) are independent?\n\nWhy does this make sense “intuitively”?\n\n\nUsing this new test of independence, are dying and abstaining from coffee independent events?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#bayes-rule-1",
    "href": "slides/slides-09-conditional-probability.html#bayes-rule-1",
    "title": "Conditional probability",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\nAs we saw before, the two conditional probabilities \\(P(A|B)\\) and \\(P(B|A)\\) are not the same. But are they related in some way?\nBayes’ rule:\n\n\n\\[\n\\text{P}(A|B) =\n\\]\n\n\nWhy is this seemingly more complicated formula useful?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#bayes-theorem-more-general",
    "href": "slides/slides-09-conditional-probability.html#bayes-theorem-more-general",
    "title": "Conditional probability",
    "section": "Bayes’ Theorem (more general)",
    "text": "Bayes’ Theorem (more general)\n\nSuppose we have a random process and have a defined event \\(A\\)\nFurther suppose we can break up the sample space into \\(k\\) disjoint/mutually exclusive outcomes or events \\(B_{1}, B_{2}, \\ldots, B_{k}\\)\nWithout loss of generality, suppose we want \\(\\text{P}(B_{1} | A)\\)\nBayes’ Theorem states:\n\\[\\begin{align*}\n\\text{P}(B_{1} |  A ) &= \\frac{\\text{P}(A|B_{1}) \\text{P}(B_{1})}{\\text{P}(A)}\\qquad \\qquad\\qquad \\qquad \\text{(Bayes' Rule)} \\\\\n&= \\frac{\\text{P}(A|B_{1})\\text{P}(B_{1})}{\\text{P}(A\\cap B_{1}) + \\text{P}(A \\cap B_{2}) + \\ldots + \\text{P}(A \\cap B_{k})} \\qquad \\qquad \\text{(LoTP)} \\\\\n&=\\frac{\\text{P}(A|B_{1}) \\text{P}(B_{1})}{\\text{P}(A|B_{1}) \\text{P}(B_{1}) + \\text{P}(A | B_{2}) \\text{P}(B_{2}) + \\ldots + \\text{P}(A | B_{k} ) \\text{P}(B_{k})}\n\\end{align*}\\]\n\n\nHow would this change if we wanted \\(P(A_{2} | B)\\) instead?\nWhy is this important? We want P(B_i | A), but sometimes we only have probabilities in the other order of conditioning!"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#diagnostic-testing-example",
    "href": "slides/slides-09-conditional-probability.html#diagnostic-testing-example",
    "title": "Conditional probability",
    "section": "Diagnostic testing example",
    "text": "Diagnostic testing example\nSuppose we are interested in the performance of a medical diagnostic test. Let \\(D\\) be the event that a patient has the disease, and let \\(T\\) be the event that the test is positive for the disease.\n\nSome definitions (don’t worry about memorizing):\n\nPrevalence: \\(P(D)\\)\nSensitivity of test: \\(P(T|D)\\)\nSpecificity of test: \\(P(T^c | D^c)\\)\nPositive predictive value: \\(P(D | T)\\)\nNegative predictive value: \\(P(D^c | T^c)\\)\n\n\nWhat do these probabilities mean in plain English? Which ones do we hope are low? Which ones do we hope are high?\nWhich probability would you be most interested in knowing?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#example",
    "href": "slides/slides-09-conditional-probability.html#example",
    "title": "Conditional probability",
    "section": "Example",
    "text": "Example\n\nIn Canada, about 0.35% of women over 40 will develop breast cancer in any given year. A common screening test for cancer is the mammogram, but this test is not perfect.\nIn about 11% of patients with breast cancer, the test gives a false negative: it indicates a woman does not have breast cancer when she does have breast cancer.\nIn about 7% of patients who do not have breast cancer, the test gives a false positive: it indicates these patients have breast cancer when they actually do not.\nIf we tested a random Canadian woman over 40 for breast cancer using a mammogram and the test came back positive, what is the probability that the patient actually has breast cancer?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#study-design",
    "href": "slides/slides-10-simpsons.html#study-design",
    "title": "Simpson’s paradox",
    "section": "Study design",
    "text": "Study design\n\nWhat are the differences between observational studies and experimental studies?\nWhat is a confounding variable?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#probability",
    "href": "slides/slides-10-simpsons.html#probability",
    "title": "Simpson’s paradox",
    "section": "Probability",
    "text": "Probability\nObservational study on sex bias based on Fall 1973 admissions data to the graduate program at the University of California, Berkeley\n\nRows: applicant gender. Columns: application results.\n\n\n\nAdmit\nDeny\nTotal\n\n\n\n\nMen\n3738\n4704\n8442\n\n\nWomen\n1494\n2827\n4321\n\n\nTotal\n5232\n7531\n12763\n\n\n\n\n\nWhat is the probability of admission for a randomly selected applicant?\nWhat is the probability of admission among men? Among women?\nAre the probabilities you found marginal, joint, or conditional probabilities?\n\n\n\n\nSuppose we want to understand the relationship between gender and admission decision. What sort of visualization might be appropriate for representing this data?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#dive-into-data",
    "href": "slides/slides-10-simpsons.html#dive-into-data",
    "title": "Simpson’s paradox",
    "section": "Dive into data",
    "text": "Dive into data\nWe have more nuanced data about the graduate admissions: we know the department that each person was applied to.\nWe will consider the six largest departments: A, B, C, D, E, F\n\nThe first six observations in the data frame are as follows:\n\n\n\nhead(admissions)\n\n# A tibble: 6 × 3\n  Decision Gender Dept \n  <chr>    <chr>  <chr>\n1 Admit    Male   B    \n2 Reject   Female C    \n3 Admit    Male   C    \n4 Reject   Female C    \n5 Admit    Male   A    \n6 Reject   Male   F    \n\n\n\n\n\nWhat sort of EDA would be interesting/appropriate for these data?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#live-code",
    "href": "slides/slides-10-simpsons.html#live-code",
    "title": "Simpson’s paradox",
    "section": "Live code",
    "text": "Live code\n\n\nFemale applicants:\n\n\n\n\n\nDept\nDecision\nn\n\n\n\n\nA\nAdmit\n89\n\n\nA\nReject\n19\n\n\nB\nAdmit\n17\n\n\nB\nReject\n8\n\n\nC\nAdmit\n202\n\n\nC\nReject\n391\n\n\nD\nAdmit\n131\n\n\nD\nReject\n244\n\n\nE\nAdmit\n94\n\n\nE\nReject\n299\n\n\nF\nAdmit\n24\n\n\nF\nReject\n317\n\n\n\n\n\n\nMale applicants:\n\n\n\n\n\nDept\nDecision\nn\n\n\n\n\nA\nAdmit\n512\n\n\nA\nReject\n313\n\n\nB\nAdmit\n353\n\n\nB\nReject\n207\n\n\nC\nAdmit\n120\n\n\nC\nReject\n205\n\n\nD\nAdmit\n138\n\n\nD\nReject\n279\n\n\nE\nAdmit\n53\n\n\nE\nReject\n138\n\n\nF\nAdmit\n22\n\n\nF\nReject\n351"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#visualize",
    "href": "slides/slides-10-simpsons.html#visualize",
    "title": "Simpson’s paradox",
    "section": "Visualize",
    "text": "Visualize"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#closer-look",
    "href": "slides/slides-10-simpsons.html#closer-look",
    "title": "Simpson’s paradox",
    "section": "Closer look",
    "text": "Closer look\nProbability of admission conditioning on gender and department:\n\n\n\n\n\n\n \n  \n    Dept \n    Gender \n    cond_prob_admit \n  \n \n\n  \n    A \n    Female \n    0.82 \n  \n  \n    A \n    Male \n    0.62 \n  \n  \n    B \n    Female \n    0.68 \n  \n  \n    B \n    Male \n    0.63 \n  \n  \n    C \n    Female \n    0.34 \n  \n  \n    C \n    Male \n    0.37 \n  \n  \n    D \n    Female \n    0.35 \n  \n  \n    D \n    Male \n    0.33 \n  \n  \n    E \n    Female \n    0.24 \n  \n  \n    E \n    Male \n    0.28 \n  \n  \n    F \n    Female \n    0.07 \n  \n  \n    F \n    Male \n    0.06 \n  \n\n\n\n\n\n\n\n\nAre all departments uniform in admission rates?\nDo admissions still seem biased against female applicants?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#whats-going-on",
    "href": "slides/slides-10-simpsons.html#whats-going-on",
    "title": "Simpson’s paradox",
    "section": "What’s going on?",
    "text": "What’s going on?\n\n\n\nBut wait… didn’t we start by noting that men were way more likely to be admitted than women?\nThe first two departments (A and B) are easy to get into\nThe following table shows for each gender, the proportion of applicants each department received.\n\n\n\n\n\n\n\n \n  \n    Gender \n    Dept \n    cond_prop \n  \n \n\n  \n    Female \n    A \n    0.059 \n  \n  \n    Female \n    B \n    0.014 \n  \n  \n    Female \n    C \n    0.323 \n  \n  \n    Female \n    D \n    0.204 \n  \n  \n    Female \n    E \n    0.214 \n  \n  \n    Female \n    F \n    0.186 \n  \n  \n    Male \n    A \n    0.307 \n  \n  \n    Male \n    B \n    0.208 \n  \n  \n    Male \n    C \n    0.121 \n  \n  \n    Male \n    D \n    0.155 \n  \n  \n    Male \n    E \n    0.071 \n  \n  \n    Male \n    F \n    0.139 \n  \n\n\n\n\n\n\n\n\nWhat do you notice?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#simpsons-paradox",
    "href": "slides/slides-10-simpsons.html#simpsons-paradox",
    "title": "Simpson’s paradox",
    "section": "Simpson’s paradox",
    "text": "Simpson’s paradox\nThe UC Berkeley admissions observational study is an example of Simpson’s paradox: when omitting one explanatory variable causes the measure/degree of association between another explanatory variable and a response variable to reverse or disappear\n\nIn other words, the inclusion/exclusion of a third variable in the analysis can change the apparent relationship between the other two variables\nWhat was the confounding variable in UC Berkeley study?"
  },
  {
    "objectID": "practice_probs/practice-08-probability.html",
    "href": "practice_probs/practice-08-probability.html",
    "title": "Probability",
    "section": "",
    "text": "If events \\(A\\) and \\(B\\) are disjoint, what is a simple formula for \\(P(A \\cup B)\\)?\n(\\(^*\\)) The American Community Survey (ACS) is an ongoing survey that provides data every year to give communities the current information they need to plan investments and services. The 2010 ACS estimated that 14.6% of Americans live below the poverty line, 20.7% speak a language other than English (i.e. a foreign language) at home, and 4.2% fall into both categories.\n\nAre living below the poverty line and speaking a foreign language at home disjoint?\nDraw a Venn diagram summarizing the probabilities and their associated probabilities. Be sure to complete the diagram by including a ``bounding box”.\nWhat percent of Americans live below the poverty line and only speak English at home?\nWhat percent of Americans live below the poverty line or speak a foreign language at home?\nWhat percent of Americans live below the poverty line and only speak English at home?\nIs the event that someone lives below the poverty line independent of the event that the person speaks a foreign language at home?\n\nIn a multiple choice exam, there are 5 questions and 4 choices for each question. Nancy has not studied for the exam at all and decides to randomly guess the answers. What is the probability that:\n\nthe first question Nancy gets correct is the 5th question? State any assumptions that you make.\nNancy gets all of the questions right?\nNancy gets at least one question right?"
  },
  {
    "objectID": "practice_probs/practice-09-conditional-probability.html",
    "href": "practice_probs/practice-09-conditional-probability.html",
    "title": "Conditional probability",
    "section": "",
    "text": "Suppose we have an event \\(A\\) from one random process and an event \\(B\\) from a second random process such that \\(P(A) = 0.3\\), \\(P(B) = 0.7\\), and \\(P(A \\cap B) = 0.1\\).\n\nAre the random processes independent?\nWhat is \\(P(A|B)\\)?\n\nAssortative mating is a nonrandom mating pattern where individuals with similar genotypes and/or phenotypes mate with one another more frequently than what would be expected under a random mating pattern. Researchers studying this topic collected the following data on eye colors of 204 Scandinavian men and their female partners. For simplicity, we only include heterosexual relationships in this exercise.\n\n\nFind the probability that a randomly chosen male respondent or his partner has blue eyes.\nWhat is the probability that a randomly chosen male respondent with blue eyes has a partner with blue eyes?\nWhat is the probability that a randomly chosen male respondent with brown eyes has a partner with blue eyes? What about the probability of a randomly chosen male respondent with green eyes having a partner with blue eyes?\nDoes it appear that the eye colors of male respondents and their partners are independent? Explain your reasoning.\n\n\\(^*\\) To get to Middlebury College, a professor uses their car 30% of the time, walks 20% of the time, and bikes 50% of the time. They are late 5% when walking, 10% of the time when driving (because this is Vermont and people stop for all pedestrians), and 2% of the time when biking.\n\nWhat is the probability the professor drove to work if they were late?\nWhat is the probability the professor walked to work if they were on time?"
  },
  {
    "objectID": "live_code/data_wrangling_viz.html",
    "href": "live_code/data_wrangling_viz.html",
    "title": "Group data wrangling",
    "section": "",
    "text": "We will now work a larger subset of the Kaggle data science survey data!"
  },
  {
    "objectID": "live_code/data_wrangling_viz.html#warm-up-exercises",
    "href": "live_code/data_wrangling_viz.html#warm-up-exercises",
    "title": "More data wrangling",
    "section": "Warm-up exercises",
    "text": "Warm-up exercises\nHow many different programming languages were recommended in the survey?\n\n\n\nHow many of the respondents who work in academia in the United States are at most 25 years old at the time taking the survey?"
  },
  {
    "objectID": "live_code/data_wrangling_viz.html#group-analysis",
    "href": "live_code/data_wrangling_viz.html#group-analysis",
    "title": "Group data wrangling",
    "section": "Group analysis",
    "text": "Group analysis\nI want your group to generate your own investigation. Using your data-wrangling and plotting skills to do some EDA. After about a half hour, your group will share your process and results with the rest of the class!\nYour final results must include:\n\nA meaningful use of group_by()\nSummary statistics or frequency table\nVisualization with meaningful labels/titles\n\nYou can create more than one visualization and/or more than one table. Whatever speaks to you! The individual components (i.e. table/summary stats vs plot) do not need to use the same set of variables. Feel free to create as many code chunks as you’d like! There is a data dictionary at the bottom of this page that defines all the variables in the data set for you."
  },
  {
    "objectID": "live_code/data_wrangling_viz.html#data-dictionary",
    "href": "live_code/data_wrangling_viz.html#data-dictionary",
    "title": "Group data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the data dictionary for the subset of the Kaggle data data.\n\nCountry: home country of employee (character)\nGender: specified gender (character)\nAge: age at time of survey (numeric)\nEmploymentStatus: reported employed status (character)\nEmploymerIndustry: employer’s industry (character)\nMajor: college major (character)\nCompensationAmount: annual compensation (numeric)\nCompensationCurrency: three-letter currency code (character)\nCurrentJobTitle: job title (character)\nTitleFit: assessment of how well the job title fits (“Fine”, “Perfectly”, “Poorly”)\nLanguageRecommendation: recommended programming language (character)\nWorkDataVisualizations: proportion of job dedicated to creating data visualizations, broken into pre-determined categories (character)\nJobSatisfaction: rating of job satisfaction on scale of 1-10, where 1 is not satisfied and 10 is highly satisfied (character)\nJobSatisfaction2: numeric version of JobSatisfaction (numeric)\nConversionUSD: conversion factor from CompensationCurrency to USD (numeric)"
  },
  {
    "objectID": "live_code/data_wrangling.html",
    "href": "live_code/data_wrangling.html",
    "title": "Data wrangling with dplyr",
    "section": "",
    "text": "Recall that we are looking at data provided by Kaggle. In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "live_code/data_wrangling.html#selecting-columns",
    "href": "live_code/data_wrangling.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 2288 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    31 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:EmploymentStatus)\n\n# A tibble: 2,288 × 3\n   Gender   Age EmploymentStatus                                    \n   <chr>  <dbl> <chr>                                               \n 1 Male      56 Independent contractor, freelancer, or self-employed\n 2 Male      33 Employed full-time                                  \n 3 Male      26 Employed full-time                                  \n 4 Male      25 Employed part-time                                  \n 5 Male      33 Employed full-time                                  \n 6 Male      22 Employed full-time                                  \n 7 Male      29 Employed full-time                                  \n 8 Male      35 Employed full-time                                  \n 9 Male      37 Employed full-time                                  \n10 Male      31 Employed part-time                                  \n# ℹ 2,278 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 2,288 × 16\n   Gender   Age EmploymentStatus          EmployerIndustry FormalEducation Major\n   <chr>  <dbl> <chr>                     <chr>            <chr>           <chr>\n 1 Male      56 Independent contractor, … Mix of fields    Master's degree Math…\n 2 Male      33 Employed full-time        Internet-based   Bachelor's deg… Other\n 3 Male      26 Employed full-time        Financial        Master's degree Comp…\n 4 Male      25 Employed part-time        Academic         Bachelor's deg… Phys…\n 5 Male      33 Employed full-time        Telecommunicati… Doctoral degree Elec…\n 6 Male      22 Employed full-time        Mix of fields    Bachelor's deg… Info…\n 7 Male      29 Employed full-time        Pharmaceutical   Master's degree Comp…\n 8 Male      35 Employed full-time        Technology       Doctoral degree Phys…\n 9 Male      37 Employed full-time        Technology       Master's degree Elec…\n10 Male      31 Employed part-time        Technology       Doctoral degree Comp…\n# ℹ 2,278 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>"
  },
  {
    "objectID": "live_code/data_wrangling.html#arranging-rows",
    "href": "live_code/data_wrangling.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable. The arrange() function does this, and requires specifying at least one variable to arrange by:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1     0 Mathematics or statistics                                   \n 2     1 Other                                                       \n 3    19 Computer Science                                            \n 4    19 Biology                                                     \n 5    20 Information technology, networking, or system administration\n 6    20 Mathematics or statistics                                   \n 7    20 Computer Science                                            \n 8    20 Mathematics or statistics                                   \n 9    21 Other                                                       \n10    21 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/data_wrangling.html#slicing-for-certain-row-numbers",
    "href": "live_code/data_wrangling.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row is index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 17\n  Country   Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n  <chr>     <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n1 United S… Male      56 Independent con… Mix of fields    Master's degree Math…\n2 Russia    Male      33 Employed full-t… Internet-based   Bachelor's deg… Other\n3 Taiwan    Male      26 Employed full-t… Financial        Master's degree Comp…\n4 United S… Male      25 Employed part-t… Academic         Bachelor's deg… Phys…\n5 United S… Male      33 Employed full-t… Telecommunicati… Doctoral degree Elec…\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/data_wrangling.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/data_wrangling.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we use the filter() function to only retain the observations where the person’s Major was Computer Science. This function requires specifying a logical condition, and keeps observations in which the condition is met (i.e. TRUE).\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 681 × 17\n   Country  Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n   <chr>    <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n 1 Taiwan   Male      26 Employed full-t… Financial        Master's degree Comp…\n 2 Poland   Male      29 Employed full-t… Pharmaceutical   Master's degree Comp…\n 3 Iran     Male      31 Employed part-t… Technology       Doctoral degree Comp…\n 4 Brazil   Male      25 Employed full-t… Academic         Master's degree Comp…\n 5 Brazil   Male      32 Employed full-t… Academic         Master's degree Comp…\n 6 Russia   Male      31 Independent con… CRM/Marketing    Some college/u… Comp…\n 7 India    Male      23 Employed full-t… Technology       Master's degree Comp…\n 8 Canada   Male      52 Employed full-t… Academic         Bachelor's deg… Comp…\n 9 Russia   Male      26 Independent con… Military/Securi… Bachelor's deg… Comp…\n10 Czech R… Male      25 Independent con… Internet-based   Master's degree Comp…\n# ℹ 671 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”. In the following code, we retain cases where someone’s major was Computer Science and they were 30 years old at the time of filling out the survey.\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Computer Science    30\n10 Computer Science    30\n# ℹ 26 more rows\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 765 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    31\n 4 Computer Science    25\n 5 Computer Science    32\n 6 Computer Science    31\n 7 A social science    30\n 8 Computer Science    23\n 9 Biology             30\n10 Computer Science    52\n# ℹ 755 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 44 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Other               30\n10 Computer Science    30\n# ℹ 34 more rows"
  },
  {
    "objectID": "live_code/data_wrangling.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/data_wrangling.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\nThe distinct() function requires specifying variables in the data frame, and the function will keep only unique/distinct instances of the variable(s). Unless otherwise specified, it will drop all the other variables.\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 5 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n5 I prefer not to answer                                           \n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 58 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree A social science                                           \n 5 Bachelor's degree Electrical Engineering                                     \n 6 Bachelor's degree Mathematics or statistics                                  \n 7 Bachelor's degree Computer Science                                           \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree A humanities discipline                                    \n10 Bachelor's degree Management information systems                             \n# ℹ 48 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/data_wrangling.html#mutate-to-add-a-new-variable",
    "href": "live_code/data_wrangling.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify:\n\nThe name of the new variable and\nHow to calculate the value of that new variable for each observation. This will typically involve operations involving variables already present in the data frame.\n\nWe link the two with an equals sign.\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 2,288 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              15000              15\n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/data_wrangling.html#counting-to-create-frequency-tables",
    "href": "live_code/data_wrangling.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(EmployerIndustry)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 CRM/Marketing                       70\n 3 Financial                          211\n 4 Government                         137\n 5 Hospitality/Entertainment/Sports    27\n 6 Insurance                           68\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 Military/Security                   35\n10 Mix of fields                      195\n11 Non-profit                          35\n12 Other                              198\n13 Pharmaceutical                      54\n14 Retail                              61\n15 Technology                         445\n16 Telecommunications                  65\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(EmployerIndustry, sort = T)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\ndatascience |>\n  count(EmployerIndustry) |>\n  arrange(desc(n))\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/data_wrangling.html#practice",
    "href": "live_code/data_wrangling.html#practice",
    "title": "Data wrangling with dplyr",
    "section": "Practice",
    "text": "Practice\nSuppose I want to report a data frame that reports each unique level of Major and the proportion of times each level was observed in the data set in order of most popular to least popular. How might we do that?\n\n\nCode\ndatascience |>\n  count(Major) |>\n  mutate(prop = n/sum(n)) |>\n  select(Major, prop) |>\n  arrange(desc(prop))"
  },
  {
    "objectID": "live_code/data_wrangling.html#summarising-for-summary-statistics",
    "href": "live_code/data_wrangling.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     34.4\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead? You’ll note that the calculation becomes the column title."
  },
  {
    "objectID": "live_code/data_wrangling.html#grouping-by-grouped-operations",
    "href": "live_code/data_wrangling.html#grouping-by-grouped-operations",
    "title": "Data wrangling with dplyr",
    "section": "Grouping by grouped operations",
    "text": "Grouping by grouped operations\nSometimes, we want to look at a given statistic or create a new variable focusing on each level of a specific categorical variable. The group_by() function tells R to treat each unique level as a separate data set.\n\ndatascience |>\n  group_by(EmploymentStatus) |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 3 × 2\n  EmploymentStatus                                     mean_age\n  <chr>                                                   <dbl>\n1 Employed full-time                                       34.3\n2 Employed part-time                                       29.5\n3 Independent contractor, freelancer, or self-employed     39.0"
  },
  {
    "objectID": "coding_practice/coding-practice-07-wrangling.html",
    "href": "coding_practice/coding-practice-07-wrangling.html",
    "title": "Data wrangling coding practice",
    "section": "",
    "text": "Load in the tidyverse and openintro packages the in the code chunk below. We will once again work with the starbucks data from the openintro package. Remember that if you want to look at the data, you can type View(data frame name) in the Console.\n\n\n# load packages here\n\n\nWrangle the data to display the five items with the highest amount of calories. Only display the name of the items and their calorie content.\n\n\n\n\n\nWrangle the data to display all the sandwich items in the data set.\n\n\n\n\n\nThree macronutrients serve as sources of calories (i.e. energy) in food: carbohydrates, proteins, and fat. Carbohydrates contain 4 calories per gram, proteins contain 4 calories per gram, and fats contain 9 calories per gram.\n\nWrangle the data to add a new variable called theoretical_cals which represents the number of calories each item in the starbucks data theoretically should have based on its levels of carbohydrates, protein, and fat. Store the resulting data frame as a new data frame called starbucks_new.\n\n\n\n\nUsing your starbucks_new data frame from the previous step, display a summary table/data frame that shows the standard deviation of the differences between the reported calories and theoretical calories. Make sure to specify an informative/nicer name in your summary table.\n\n\n\n\nOnce you’re finished, be sure to knit and submit the outputted HTML file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "slides/slides-00-welcome.html#syllabus-and-website",
    "href": "slides/slides-00-welcome.html#syllabus-and-website",
    "title": "Welcome!",
    "section": "Syllabus and website",
    "text": "Syllabus and website\n\nCourse website: https://midd-stat201-fall2024.github.io/\n\nPlease bookmark this page and visit frequently!\nNote that both sections will use the same website"
  },
  {
    "objectID": "slides/slides-00-welcome.html#what-is-this-course-about",
    "href": "slides/slides-00-welcome.html#what-is-this-course-about",
    "title": "Welcome!",
    "section": "What is this course about?",
    "text": "What is this course about?\n\nWhat is statistics? What is data science?\nBy the end of this course, you will:\n\nProduce and interpret graphical displays and numerical summaries of data\nHave developed confidence and some proficiency in coding in R (and in particular, the tidyverse syntax)\nBetter understand the central role of randomness in designing studies and making conclusions\nHopefully want to pursue another Statistics or Mathematics course!\nAnd much more…"
  },
  {
    "objectID": "slides/slides-00-welcome.html#necessary-background",
    "href": "slides/slides-00-welcome.html#necessary-background",
    "title": "Welcome!",
    "section": "Necessary background",
    "text": "Necessary background\n\nWe assume ZERO background in statistics and data science\nThere is a large computing component, though not as much as in STAT 118\nMATH 121 (Calculus 1) pre-req"
  },
  {
    "objectID": "slides/slides-00-welcome.html#recommendations",
    "href": "slides/slides-00-welcome.html#recommendations",
    "title": "Welcome!",
    "section": "Recommendations",
    "text": "Recommendations\n\nTakes notes! Each day’s slides will be made available on the course website by 10pm the night before. I recommend either:\n\nPrinting out the PDF version of slides to write notes on during class\n\nI recommend 4 or 6 slides per page (demo)\n\nDownloading PDF of slides to iPad/tablet/laptop and write notes on then using device\nTaking supplemental notes on paper/device\n\nRe–visit notes within 24 hours of class"
  },
  {
    "objectID": "slides/slides-00-welcome.html#recommendations-cont.",
    "href": "slides/slides-00-welcome.html#recommendations-cont.",
    "title": "Welcome!",
    "section": "Recommendations (cont.)",
    "text": "Recommendations (cont.)\n\nWe will frequently make use of our laptops. Please bring one with enough charge to last the entire class each day we meet!\n\nPlease let me know as soon as possible if you do not have access to a laptop\n\nTry to resist the temptation to do other tasks (e.g. check email, online shop, watch shows) when your laptop is open\n\nThis can be distracting to those around you\n\nKeep an open mind and don’t be afraid to ask for assistance or tell me to slow down!\nResist the temptation of using ChatGPT or other generative AI tools"
  },
  {
    "objectID": "slides/slides-00-welcome.html#github-username",
    "href": "slides/slides-00-welcome.html#github-username",
    "title": "Welcome!",
    "section": "GitHub username",
    "text": "GitHub username\n\nIf you don’t already have a GitHub account, please make one by visiting https://github.com/ and creating an account.\n\nTips for creating a username: incorporate your actual name, shorter is better than longer, make it timeless\n\nOnce you have an account, please go to this GoogleForm and enter in your GitHub username."
  },
  {
    "objectID": "slides/slides-00-welcome.html#beyoncés-albums",
    "href": "slides/slides-00-welcome.html#beyoncés-albums",
    "title": "Welcome!",
    "section": "Beyoncé’s albums",
    "text": "Beyoncé’s albums\n\nBeyoncé is one of the most famous singers of the 21st century\nBy 2023, Beyoncé had produced eight solo studio albums:\n\nDangerously in Love (2003), B’Day (2006), I Am… Sasha Fierce (2008), 4 (2011), Beyoncé (2013), Lemonade (2016), Renaissance (2022)\nPopular opinion (i.e. Reddit) is that Lemonade is her best album\n\nIs there any difference between the first four albums and Lemonade?\nLet’s consider the average length of words in these albums\n\nWe will discuss “average” in more detail next week, but for today, we will treat “average” as a number that is calculated by summing a bunch of quantities together and dividing by the total number of quantities"
  },
  {
    "objectID": "slides/slides-00-welcome.html#average-word-length",
    "href": "slides/slides-00-welcome.html#average-word-length",
    "title": "Welcome!",
    "section": "Average word length",
    "text": "Average word length\n\n\n\nThe average length of a word in Beyoncé’s first four alums is 3.62. What is the average length of a word in Lemonade?\n\n\nHow might we go about answering this question?\n\nLet’s collect some data!"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#reproducibility",
    "href": "slides/slides-02-toolkit-installation.html#reproducibility",
    "title": "Installation Day",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nAllows your code execution or an experiment to be repeated by another person\nGoals:\n\nAre the tables and figures generated directly from the code?\nDoes the code actually do what you think it does?\nCan your code be used for other data/analyses?"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#toolkit",
    "href": "slides/slides-02-toolkit-installation.html#toolkit",
    "title": "Installation Day",
    "section": "Toolkit",
    "text": "Toolkit\n\n\nWe will use the programming language R to write code\nHow will interact with the R code? In the integrated development environment called RStudio. Helps us be more productive with R\n\nR is like a car engine, and RStudio is like a car’s dashboard\n\nWe will liberate our programming by keeping code, narrative, and output all in the same interface using R Markdown documents"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#r-markdown",
    "href": "slides/slides-02-toolkit-installation.html#r-markdown",
    "title": "Installation Day",
    "section": "R Markdown",
    "text": "R Markdown\n\nAllows us to create fully reproducible reports\nCan code in code chunks and type regular text/narrative outside of these chunks\nHow will we use R Markdown?\n\nYou coding practice problems and some weekly lab assignments will be assigned as an R Markdown document (.Rmd)\nYou will almost always be provided with a template .Rmd to start with (the exception being the end of the semester when you’ve mastered this material!)"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#version-control",
    "href": "slides/slides-02-toolkit-installation.html#version-control",
    "title": "Installation Day",
    "section": "Version control",
    "text": "Version control"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#git-and-github",
    "href": "slides/slides-02-toolkit-installation.html#git-and-github",
    "title": "Installation Day",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\nGit is a version control system (like “Track Changes” in Microsoft Word)\nGitHub is the home for your Git-based projects (like DropBox)\nWe will work with GitHub Desktop to make working on code on your personal machine and sending it to the cloud for “safe keeping” seamless\n\nAlso makes for great collaboration, because multiple people can be on the same GitHub project and will see all the change you make (kind of like a shared GoogleDoc)"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#installing-r",
    "href": "slides/slides-02-toolkit-installation.html#installing-r",
    "title": "Installation Day",
    "section": "Installing R",
    "text": "Installing R\nPlease be patient! This process may be time-consuming and stressful, but it is necessary for the rest of the course!\n\nWINDOWS/MAC: Go to the CRAN website and click on the appropriate link under “Download and Install R”. Then:\n\nIf you are Windows: click on the blue text that says “install R for the first time”.\nIf you are macOS: check your Mac OS system and if you have a chip (Apple icon -> About this Mac -> Overview)\n\nThen on the website, click the newest release that supports your current OS version. This will most likely be R-4.4.1-arm64.pkg or R-4.4.1-x86_64.pkg.\n\n\n\nLINUX: follow the instructions on for Steps 1 and 2 on this website."
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#install-r-cont.",
    "href": "slides/slides-02-toolkit-installation.html#install-r-cont.",
    "title": "Installation Day",
    "section": "Install R (cont.)",
    "text": "Install R (cont.)\n\nA file will download, most likely to your Downloads folder. Run the file by clicking on it. Allow the app to make changes to your device if prompted.\n\nFollow the installation instructions, until you click on “Finish” to exit the installation setup. At this point, R should be successfully installed!"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#installing-rstudio",
    "href": "slides/slides-02-toolkit-installation.html#installing-rstudio",
    "title": "Installation Day",
    "section": "Installing RStudio",
    "text": "Installing RStudio\n\nLINUX: go to step 3 of the same website\nWINDOWS/MACS: Go to the Posit website and scroll down a little until you see two steps. We already did Step 1!\n\nUnder Step 2, click the blue Download RStudio Desktop button recommended for your computer\n\nmacOS users: double check you have an OS that is recent enough! Otherwise, raise your hand!\n\nRun the downloaded RStudio Executable file until you hit the “Finish” button. It may be the case that you don’t have to click anything at all.\nAfter RStudio finishes downloading, a window like this might pop up. If so, go ahead and drag the RStudio icon into the Applications folder."
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#opening-rstudio",
    "href": "slides/slides-02-toolkit-installation.html#opening-rstudio",
    "title": "Installation Day",
    "section": "Opening RStudio",
    "text": "Opening RStudio\n\nIn the previous step, we put an RStudio shortcut into your Applications folder.\nYou may find it easier to put a shortcut somewhere else for easier access (e.g. your dock or home screen)\nTo open RStudio, simply double click on the RStudio icon (you do not need to click on the R icon)"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html#make-a-folder",
    "href": "slides/slides-02-toolkit-installation.html#make-a-folder",
    "title": "Installation Day",
    "section": "Make a folder",
    "text": "Make a folder\n\nMake a folder that is easy to access (e.g. on your Desktop). Call it STAT 201.\n\nAll of your files for this course should go into this folder!!!!"
  },
  {
    "objectID": "slides/slides-00-welcome.html",
    "href": "slides/slides-00-welcome.html",
    "title": "Welcome!",
    "section": "",
    "text": "Course website: https://midd-stat201-fall2024.github.io/\n\nPlease bookmark this page and visit frequently!\nNote that both sections will use the same website\n\n\n\n\n\n\nWhat is statistics? What is data science?\nBy the end of this course, you will:\n\nHopefully want to pursue another Statistics or Mathematics course!\n\n\n\n\n\n\nWe assume ZERO background in statistics and data science\nThere is a large computing component, though not as much as in STAT 118\nMATH 121 (Calculus 1) pre-req\n\n\n\n\n\nTakes notes! Each day’s slides will be made available on the course website by 10pm the night before. I recommend either:\n\nPrinting out the PDF version of slides to write notes on in during class\n\nI recommend 4 or 6 slides per page (demo)\n\nDownloading PDF of slides to iPad/tablet/laptop and write notes on then using device\nTaking supplemental notes on paper/device\n\nRe–visit notes within 24 hours of class\n\n\n\n\n\nWe will frequently make use of our laptops. Please bring one with enough charge to last the entire class each day we meet!\n\nPlease let me know as soon as possible if you do not have access to a laptop\n\nTry to resist the temptation to do other tasks (e.g. check email, online shop, watch shows) when your laptop is open\n\nThis can be distracting to those around you\n\nKeep an open mind and don’t be afraid to ask for assistance or tell me to slow down!\nResist the temptation of using ChatGPT or other generative AI tools\n\n\n\n\n\nIf you don’t already have a GitHub account, please make one by visiting https://github.com/ and creating an account.\n\nTips for creating a username: incorporate your actual name, shorter is better than longer, make it timeless\n\nOnce you have an account, please go to this GoogleForm and enter in your GitHub username."
  },
  {
    "objectID": "live_code/intro_R.html",
    "href": "live_code/intro_R.html",
    "title": "Intro to R and R Markdown",
    "section": "",
    "text": "In the Console, type the following code: 1 + 1. What happens?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNothing!\n\n\n\nTo execute/run code in the Console, we simply press Enter. Try it! What happens?\n\n\nNote that spacing doesn’t matter in R code.\nWe can add (+), subtract (-), multiply (*), divide (/), and perform more complicated calculations using R."
  },
  {
    "objectID": "live_code/intro_R.html#introduction-to-r-markdown",
    "href": "live_code/intro_R.html#introduction-to-r-markdown",
    "title": "Untitled",
    "section": "Introduction to R Markdown",
    "text": "Introduction to R Markdown\nThis document that we are working in is called an R markdown document. It allows us to seamlessly move between R code and regular text. How do we tell the document which parts correspond to code, and which parts correspond to text?\nIn the following, you see three back ticks followed by a left curly brace, the letter r, and right curly brace. A few lines down, you will see three more back ticks. The background in between these lines is gray, with some symbols on the right.\nThis defines ______. All of our R code should go into one.\n\n\n\n\n\n\n\nWhat happens if we delete a back tick?\n\n\n\nIn the code chunk above, let’s evaluate \\(\\sqrt{4}\\) (the square root of 4). To do this, type the following code: sqrt(4). Now evaluating the code in a code chunk is different from evaluating code in the Console. There are two ways to do so:\n1.\n2."
  },
  {
    "objectID": "live_code/intro_R.html#saving-progress",
    "href": "live_code/intro_R.html#saving-progress",
    "title": "Intro to R and R Markdown",
    "section": "Saving progress",
    "text": "Saving progress\nAt this point it is a good idea to save our progress. Like most document editors, we need to explicitly save our work. You know your work is not saved when _____.\nTo save our work in R Markdown document, we can do one of the following:\n\nClick on the floppy disk at the top of the panel\nGo to File -> Save\nHit Cmd+S\n____ the document\n\n\nKnitting\nKnitting the document will render your R markdown into its final output form. To knit, simply click on the ball of yarn at the top of the panel. Knitting can take anywhere from a few seconds to a few minutes depending on the amount of code and narrative you have.\nNow, outside of R Studio, go to the Folder where this R Markdown document is located. What do you notice? ______"
  },
  {
    "objectID": "live_code/intro_R.html#r-markdown-basics",
    "href": "live_code/intro_R.html#r-markdown-basics",
    "title": "Intro to R and R Markdown",
    "section": "R Markdown basics",
    "text": "R Markdown basics\nHow do we tell the document which parts correspond to code, and which parts correspond to text?\nIn the following, you see three back ticks followed by a left curly brace, the letter r, and right curly brace. A few lines down, you will see three more back ticks. The background in between these lines is gray, with some symbols on the right. These backs ticks must be aligned on the same tabulation.\nThis defines ______. All of our R code should go into one.\n\n\n\n\n\n\n\nWhat happens if we delete a back tick?\n\n\n\nIn the code chunk above, let’s evaluate \\(\\sqrt{4}\\) (the square root of 4). To do this, type the following code: sqrt(4). Now evaluating the code in a code chunk is different from evaluating code in the Console. There are two ways to do so:\n1.\n2.\n\nsqrt(4)\n\n[1] 2"
  },
  {
    "objectID": "live_code/intro_R.html#coding-in-r",
    "href": "live_code/intro_R.html#coding-in-r",
    "title": "Intro to R and R Markdown",
    "section": "Coding in R",
    "text": "Coding in R\nR is more than just a calculator! It provides lots of functionality for performing tasks related specifically to statistics.\n\nObject types\nEverything in R is an object. Here, we provide a non-exhaustive list of common objects (i.e. structures) you will encounter.\n\nA ____ object contains only a single number\n\n\n\n\n\nA ____ or ____ object is a set of characters within one pair of quotation marks\n\n\n\n\n\nA ____ object is an ordered collection of numbers or strings. We can create vectors using the command c():\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWhat happened here?\n\nc(1, \"no\")\n\n[1] \"1\"  \"no\"\n\n\n\n\n\n\nA ____ object is either TRUE or FALSE. It is also referred to as a boolean.\nData frames are representations of datasets in R where the rows correspond to observations and columns correspond to variables that describe the observations (more on this later).\n\n\n\nFunctions\nWhen we calculated \\(\\sqrt{4}\\), we used the code sqrt(). This is an example of a function. Functions allow us to automate common tasks in a general way. Functions (just like in math) take in one or more inputs. These inputs are known as _____ or _____. They will almost always return an output. We know a command in R is a function because it has _____.\nIt is possible for us to create our own customized functions (you definitely will if you take STAT 218). However, in STAT 201, we will work with pre-provided functions. All pre-provided functions in R are accompanied by a Help file. To access the Help file, simply type ? followed by the name of the function in the Console. Try opening the Help file for the sqrt() function.\nIf I want to obtain the square root of the values 1, 4, 9, and 16, what code can I type?\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsqrt(c(1,4,9, 16))\n\n[1] 1 2 3 4\n\n\n\n\n\n\n\nStoring objects as variables\nSuppose I want to calculate the volume of a cube, where each edge is of length 2. The volume is \\(\\text{edge length}^3\\) . We could calculate the area as follows:\n\n2*2*2\n\n[1] 8\n\n\nNow suppose someone tells you that the edge length was actually 2.1 instead of 2. So you modify as follows:\n\n2.1*2.1*2.1\n\n[1] 9.261\n\n\nThen you get told the edge length is actually 2.2. So frustrating! To save ourselves further troubles, we do the following to make our code reproducible:\n\nlength <- 2.2\nlength^3\n\n[1] 10.648\n\n\nWhat did we do in the above code? We _____ or ______ the value 2.2 into the ______ called length using the keys <-.\nNow make a new R code chunk here. In this new code chunk, make a new object called volume and assign to it an appropriate value. Now let’s knit the document.\n\n\n\nAs you should note: when we assign an object a value, its value is not automatically shown as output. In order to display the output, you must _____."
  },
  {
    "objectID": "live_code/intro_R.html#errors-warnings-and-messages",
    "href": "live_code/intro_R.html#errors-warnings-and-messages",
    "title": "Intro to R and R Markdown",
    "section": "Errors, warnings, and messages",
    "text": "Errors, warnings, and messages\nThese are always shown in red text in the Console. Whenever you see them, don’t panic! With practice, you will be able to decipher the messages and de-bug your code with ease.\n\nErrors: prevent code from executing and documents from knitting. It will be prefaced with “Error in…”. Trying typing in the following code in your Console: 1 + a. What happens?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n1+a\n\nError in eval(expr, envir, enclos): object 'a' not found\n\n\n\n\n\n\n\nA good reason to knit often is to ensure your code is error-free!\n\nWarnings: your code will run with some caveats. It will be prefaced with “Warning:”. We will see examples of this later on.\nMessages: messages in red that do not begin with “Error” or “Warning” are simply friendly messages that might provide you more information about the execution of your code."
  },
  {
    "objectID": "live_code/intro_R.html#packages",
    "href": "live_code/intro_R.html#packages",
    "title": "Intro to R and R Markdown",
    "section": "Packages",
    "text": "Packages\nPackages in R extend the functionality by providing additional functions and data. You can view them as analogous to apps you download from the App Store or Google Play on a cell phone. To use an app on a phone, you have to:\n\nDownload the app\nExplicitly open the app\n\nTo use a package, we need to:\n\n____ the package\n____ the package\n\nUnless you update R Studio, you will only need to install a package once. However, you will need to explicitly load in packages every time you work in a new R Markdown document.\nThere are thousands of available packages to work with. Two of the most common packages we will use are the openintro package and the tidyverse package (though, the tidyverse package is actually a giant package that is comprised of several other packages).\n\nPackage installation\nThere are two ways to install a package:\n\nOption 1:\n\nClick on the “Packages” tab in the Files pane of RStudio\nClick on “Install”\nType the name of the package under “Packages (separate multiple with space or comma):”.\nClick “Install”\n\nOption 2:\n\nType install.packages(\"package name\") into the Console. Note that the quotation marks are necessary.\nPress Return/Enter\n\n\nWe will install the openintro package together. Then, try installing the tidyverse package on your own!\n\n\nPackage loading\nTo use the package we have installed, we use the library() command:\n\nlibrary(openintro)\n\nLoading required package: airports\n\n\nLoading required package: cherryblossom\n\n\nLoading required package: usdata\n\n\n\n\nThis is an example of a function that does not return an output\n\n\n\n\n\n\nTip\n\n\n\nYou may have seen some red text in your Console when you loaded in the package above. Was this an error, warning, or regular message?"
  },
  {
    "objectID": "coding_practice/coding-practice-02-intro-r.html",
    "href": "coding_practice/coding-practice-02-intro-r.html",
    "title": "Intro to R coding practice",
    "section": "",
    "text": "Change your name in the YAML. Be sure to keep the quotation marks!\nExecute the following the code in the code chunk. Describe in words what the code is doing.\n\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nAnswer:\n\nWe will learn how to use the important function sample(), which allows us to obtain a random sample. Look at the help file by typing ?sample into your Console. After some experimenting, write code randomly sample two numbers from the set of numbers 1-5, without replacement. Note: it’s okay if you get something different from those around you! We are randomly sampling after all!\n\n\n\n\n\nIn the following code chunk, write code to load in the openintro package. Then run the code in the code chunk.\n\n\n\n\n\nIn the Console, type in ?cherry to open up the Help file for the cherry data frame. Type into the white space below the units for each of the variables.\n\nAnswer:\n\nRemember that rows in data frames represents observations. How many observations are there in the cherry data frame? Answer this by using the nrow() function and passing in the name of data frame of interest. You can confirm your answer by looking at the cherry Help file.\n\n\n\n\nOnce you’re finished, be sure to knit and submit the outputted file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#explanatory-vs.-response",
    "href": "slides/slides-01-study-design.html#explanatory-vs.-response",
    "title": "Study design",
    "section": "Explanatory vs. Response",
    "text": "Explanatory vs. Response\n\nLots of scientific questions revolve around asking how \\(x\\) relates to \\(y\\)\nIf \\(y\\) is the primary variable of interest, i.e. the variable whose behavior we want to understand, it is called the response variable\nIf we try to understand how changing \\(x\\) affects \\(y\\), then \\(x\\) is called the explanatory variable\n\nExplanatory variables can often be manipulated/controlled/observed by the researcher ahead of time"
  },
  {
    "objectID": "slides/slides-00-welcome.html#important-course-information",
    "href": "slides/slides-00-welcome.html#important-course-information",
    "title": "Welcome!",
    "section": "Important course information",
    "text": "Important course information\n\nProfessor Becky Tang\n\nOffice: Warner 214\nEmail: btang@middlebury.edu\n\nCourse website: https://midd-stat201-fall2024.github.io/\n\nPlease bookmark this page and visit frequently!\nNote that both sections will use the same website"
  },
  {
    "objectID": "slides/slides-00-welcome.html#example",
    "href": "slides/slides-00-welcome.html#example",
    "title": "Welcome!",
    "section": "Example",
    "text": "Example\nCounties of the U.S. within the bottom 10% of death rates for kidney cancer for white males, 1980-1989.\n\n\nWhat do you notice? What might be the explanation?"
  },
  {
    "objectID": "slides/slides-00-welcome.html#example-cont.",
    "href": "slides/slides-00-welcome.html#example-cont.",
    "title": "Welcome!",
    "section": "Example (cont.)",
    "text": "Example (cont.)\nCounties of the U.S. within the top 10% of death rates for kidney cancer for white males, 1980-1989."
  },
  {
    "objectID": "slides/slides-00-welcome.html#example-cont.-1",
    "href": "slides/slides-00-welcome.html#example-cont.-1",
    "title": "Welcome!",
    "section": "Example (cont.)",
    "text": "Example (cont.)\nWhat’s going on? Let’s do some digging…\n\nDeath rate for kidney cancer: https://seer.cancer.gov/statfacts/html/kidrp.html\nCounty sizes: https://en.wikipedia.org/wiki/County_statistics_of_the_United_States"
  },
  {
    "objectID": "slides/slides-01-study-design.html#example-literary-digest-poll",
    "href": "slides/slides-01-study-design.html#example-literary-digest-poll",
    "title": "Study design",
    "section": "Example: Literary Digest poll",
    "text": "Example: Literary Digest poll\n\n1936 was an election year in the United States. Franklin D. Roosevelt (a Democrat) was completing his first term in office as president.\nRepublican candidate Alfred Landon of Kansas was his competitor\nLiterary Digest magazine conducted a polling survey, which received 2.4 million respondents (largest number of people every replying to a poll at that time)\n\nPrediction: overwhelming victory for Landon (predicted FDR would only get 43% of popular vote)\n\nActual result: FDR won by a landslide! (62% to 38%)\nWhat happened? Selection and non-response bias\n\n\n\nSelection bias: Digest mailed questionnaires to 10 million people. Where did they get the address form? Telephone books and club membership lists –> screened out the poor (only about 25% of households had phones)\n\nThis wouldn’t necessarily be bias, EXCEPT for the fact that poor people overwhelmingly favored FDR and the rich favored Landon\n\nNon-response bias: lots of people didn’t respond to survey (~75%)\n\nOnce again, wouldn’t matter if there wasn’t a difference in the opinions of respondents vs non-respondents. But among the 20% who responded, over half favored Landon\nNon-respondents can be very different from respondents. When there is high non-response rate, look for non-response bias\n\nLesson: not all samples that were done poorly are necessarily biased, but we should always ask how the sample was conducted! Also, when a selection procedure is biased, a large sample does not help; this just replicates the mistake on a larger scale!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#simple-random-sampling-srs",
    "href": "slides/slides-01-study-design.html#simple-random-sampling-srs",
    "title": "Study design",
    "section": "Simple random sampling (SRS)",
    "text": "Simple random sampling (SRS)\n\nIn a simple random sample, each individual is chosen entirely by chance from the population, and each member of the population has an equal chance of being sampled\n\nTypically sampling without replacement\nKnowing that an individual was sampled does not provide useful information about which other cases are included\n\nAny given fixed-size subset of the population is equally likely to be chosen\n\n\n\nConsider again the research question: What proportion of current Middlebury professors attended a liberal arts college?\nHow might I obtain a sample random sample of 25 professors?\n\n\n\nRequires us to list all of the units in the target/survey population –> May be unrealistic!"
  },
  {
    "objectID": "slides/slides-01-study-design.html#multistage-cluster-sampling",
    "href": "slides/slides-01-study-design.html#multistage-cluster-sampling",
    "title": "Study design",
    "section": "Multistage cluster sampling",
    "text": "Multistage cluster sampling\n\nBuilds on the cluster sampling method, but rather than sampling all individuals within the selected clusters, only collect a simple random sample within each selected cluster\n\nCan make more stages/layers if appropriate!\n\nThough seemingly more complicated, why might we prefer multistage sampling over cluster sampling?\nHow might we devise a multistage cluster sample for Literary Digest?"
  },
  {
    "objectID": "slides/slides-01-study-design.html#probability-sampling",
    "href": "slides/slides-01-study-design.html#probability-sampling",
    "title": "Study design",
    "section": "Probability sampling",
    "text": "Probability sampling\n\nAny sampling method where the selection from the target population is based on random selection/chance\n\nAll subjects in the target population have equal chances of being selected as some point in the method\nNo one has discretion about who is included in the sample\n\nRandomly sampling from the population can help reduce bias in our sample\n\nIf we don’t randomly sample, results obtained from the sample will most likely not be representative and will not generalize to the target population\n\nExamples include: simple random, stratified, cluster, systematic"
  },
  {
    "objectID": "live_code/intro_R.html#yaml",
    "href": "live_code/intro_R.html#yaml",
    "title": "Intro to R and R Markdown",
    "section": "YAML",
    "text": "YAML\nAt the top of a markdown topic, you’ll see code between two sets of three dashed lines. This is known as a YAML header, and it contains the “informational” content of a document (e.g. title, author, date). Change these arguments accordingly for each assignment.\n\n\n\n\n\n\n\nNotice the quotation marks! These are extremely important!\nGo ahead and change your name in the author argument of the YAML."
  },
  {
    "objectID": "slides/slides-01-study-design.html",
    "href": "slides/slides-01-study-design.html",
    "title": "Study design",
    "section": "",
    "text": "Please bring your laptops tomorrow! We will be installing R and RStudio!"
  },
  {
    "objectID": "live_code/template_intro_R.html",
    "href": "live_code/template_intro_R.html",
    "title": "Introduction to R and R Markdown",
    "section": "",
    "text": "This document that we are working in is called an R markdown document. It allows us to seamlessly move between R code and regular text. The name of the file is easily found at the top this panel. All R markdown files end in ____.\n\n\nAt the top of a markdown topic, you’ll see code between two sets of three dashed lines. This is known as a YAML header, and it contains the “informational” content of a document (e.g. title, author, date). Change these accordingly for each assignment!\nGo ahead and change your name in the author argument of the YAML.\n\n\n\nHow do we tell the document which parts correspond to code, and which parts correspond to text?\nIn the following, you see three back ticks followed by a left curly brace, the letter r, and right curly brace. A few lines down, you will see three more back ticks. The background in between these lines is gray, with some symbols on the right. These backs ticks must be aligned on the same tabulation.\nThis defines ______. All of our R code should go into one.\n\n\n\nIn the code chunk above, let’s evaluate \\(\\sqrt{4}\\) (the square root of 4). To do this, type the following code: sqrt(4). Now evaluating the code in a code chunk is different from evaluating code in the Console. There are two ways to do so:\n\n\n\n\n\n\n\nAt this point it is a good idea to save our progress. Like most document editors, we need to explicitly save our work. You know your work is not saved when _____.\nTo save our work in R Markdown document, we can do one of the following:\n\nClick on the floppy disk at the top of the panel\nGo to File -> Save\nHit Cmd+S\n____ the document\n\n\n\nKnitting the document will render your R markdown into its final output form. To knit, simply click on the ball of yarn at the top of the panel. Knitting can take anywhere from a few seconds to a few minutes depending on the amount of code and narrative you have.\nNow, outside of R Studio, go to the Folder where this R Markdown document is located. What do you notice? ______\n\n\n\n\nR is more than just a calculator! It provides lots of functionality for performing tasks related specifically to statistics.\n\n\nEverything in R is an object. Here, we provide a non-exhaustive list of common objects (i.e. structures) you will encounter.\n\nA ____ object contains only a single number\n\n\n\n\n\nA ____ or ____ object is a set of characters within one pair of quotation marks\n\n\n\n\n\nA ____ object is an ordered collection of numbers or strings. We can create vectors using the command c():\n\n\n\n\n\nA ____ object is either TRUE or FALSE. It is also referred to as a boolean.\nData frames are representations of datasets in R where the rows correspond to observations and columns correspond to variables that describe the observations (more on this later).\n\n\n\n\nWhen we calculated \\(\\sqrt{4}\\), we used the code sqrt(). This is an example of a function. Functions allow us to automate common tasks in a general way. Functions (just like in math) take in one or more inputs. These inputs are known as _____ or _____. They will almost always return an output. We know a command in R is a function because it has _____.\nIt is possible for us to create our own customized functions (you definitely will if you take STAT 218). However, in STAT 201, we will work with pre-provided functions. All pre-provided functions in R are accompanied by a Help file. To access the Help file, simply type ? followed by the name of the function in the Console. Try opening the Help file for the sqrt() function.\n\n\n\nSuppose I want to calculate the volume of a cube, where each edge is of length 2. The volume is \\(\\text{edge length}^3\\) . We could calculate the area as follows:\n\n\n\nNow suppose someone tells you that the edge length was actually 2.1 instead of 2. So you modify as follows:\n\n\n\nThen you get told the edge length is actually 2.2. So frustrating! To save ourselves further troubles, we do the following to make our code reproducible:\n\n\n\nWhat did we do in the above code? We _____ or ______ the value 2.2 into the ______ called length using the keys <-.\nNow make a new R code chunk here. In this new code chunk, make a new object called volume and assign to it an appropriate value. Now let’s knit the document.\nAs you should note: when we assign an object a value, its value is not automatically shown as output. In order to display the output, you must _____.\n\n\n\n\nThese are always shown in red text in the Console. Whenever you see them, don’t panic! With practice, you will be able to decipher the messages and de-bug your code with ease.\n\nErrors: prevent code from executing and documents from knitting. It will be prefaced with “Error in…”. Trying typing in the following code in your Console: 1 + a. What happens?\nWarnings: your code will run with some caveats. It will be prefaced with “Warning:”. We will see examples of this later on.\nMessages: messages in red that do not begin with “Error” or “Warning” are simply friendly messages that might provide you more information about the execution of your code.\n\n\n\n\nPackages in R extend the functionality by providing additional functions and data. You can view them as analogous to apps you download from the App Store or Google Play on a cell phone. To use an app on a phone, you have to:\n\nDownload the app\nExplicitly open the app\n\nTo use a package, we need to:\n\n____ the package\n____ the package\n\nUnless you update R Studio, you will only need to install a package once. However, you will need to explicitly load in packages every time you work in a new R Markdown document.\nThere are thousands of available packages to work with. Two of the most common packages we will use are the openintro package and the tidyverse package (though, the tidyverse package is actually a giant package that is comprised of several other packages).\n\n\nThere are two ways to install a package:\n\nOption 1:\n\nClick on the “Packages” tab in the Files pane of RStudio\nClick on “Install”\nType the name of the package under “Packages (separate multiple with space or comma):”.\nClick “Install”\n\nOption 2:\n\nType install.packages(\"package name\") into the Console. Note that the quotation marks are necessary.\nPress Return/Enter\n\n\nWe will install the openintro package together. Now, try installing the tidyverse package on your own!\n\n\n\nTo use the package we have installed, we use the library() command:"
  },
  {
    "objectID": "slides/slides-02-toolkit-installation.html",
    "href": "slides/slides-02-toolkit-installation.html",
    "title": "Installation Day",
    "section": "",
    "text": "More homework problems released today. All due to Canvas on Monday, 9/16 by 11:59pm! Feel free to hand-write and then scan your work, or work in a text editor directly.\nOffice hours reminder!"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#variables-types",
    "href": "slides/slides-03-numerical-pt1.html#variables-types",
    "title": "Numerical data",
    "section": "Variables types",
    "text": "Variables types\n\nVariables can be broadly broken into two categories: numerical (quantitative) or categorical (qualitative)\nNumerical variables take a wide range of numerical values, and it is sensible to add/subtract/do mathematical operations with those values. Two types:\n\nDiscrete if it can only take on finitely many numerical values within a given interval\nContinuous if it can take on any infinitely many values within a given interval\n\nCategorical variables are essentially everything else (more on this next week!)\nExamples and non-examples?"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#example-1",
    "href": "slides/slides-03-numerical-pt1.html#example-1",
    "title": "Numerical data",
    "section": "Example",
    "text": "Example\nLet’s calculate the sample mean estimated weight from the data we collected today\n\n\nWrite out how you would calculate \\(\\bar{x}\\)\n\nThen I will use R to calculate the sample mean!"
  },
  {
    "objectID": "live_code/stat201_live_code.html",
    "href": "live_code/stat201_live_code.html",
    "title": "STAT 201 Live code",
    "section": "",
    "text": "# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "live_code/numerical_pt1_live.html",
    "href": "live_code/numerical_pt1_live.html",
    "title": "9/16/2024 Live code",
    "section": "",
    "text": "# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# first argument is x-axis\nplot(insurance$bmi, insurance$charges)\n\n\n\n# make axis labels more informative and add title \nplot(insurance$bmi, insurance$charges, xlab = \"BMI\", ylab = \"Charges ($)\", \n     main = \"Scatterplot of insurance charges by BMI\")"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#creating-visualizations",
    "href": "slides/slides-03-numerical-pt1.html#creating-visualizations",
    "title": "Numerical data",
    "section": "Creating visualizations",
    "text": "Creating visualizations\nWorking in your groups, create a dot plot and a histogram of the estimated weights from the data we collected today!"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#live-code-1",
    "href": "slides/slides-03-numerical-pt1.html#live-code-1",
    "title": "Numerical data",
    "section": "Live code",
    "text": "Live code\nFunctions to calculate sample mean, variance, and standard deviation in R:\n\nmean()\nvar()\nsd()"
  },
  {
    "objectID": "live_code/numerical_pt1_live.html#plots-in-base-r",
    "href": "live_code/numerical_pt1_live.html#plots-in-base-r",
    "title": "9/16/2024 Live code",
    "section": "Plots in base R",
    "text": "Plots in base R\n\n# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# scatter plot: first argument is x-axis\nplot(insurance$bmi, insurance$charges)\n\n\n\n# make axis labels more informative, add title, add color for fun\nplot(insurance$bmi, insurance$charges, xlab = \"BMI\", ylab = \"Charges ($)\", \n     main = \"Scatterplot of insurance charges by BMI\",\n     col = \"blue\")\n\n\n\n# make histogram\nhist(insurance$bmi)\n\n\n\n# change numbers of bins. Check Help file!\nhist(insurance$bmi, xlab = \"BMI\", ylab = \"Histogram of BMI\", breaks = 15)"
  },
  {
    "objectID": "live_code/numerical_pt1_live.html#summary-statistics",
    "href": "live_code/numerical_pt1_live.html#summary-statistics",
    "title": "9/16/2024 Live code",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nmean(insurance$bmi)\n\n[1] 30.63417\n\nvar(insurance$bmi)\n\n[1] 31.98109\n\nsd(insurance$bmi)\n\n[1] 5.655182\n\n# confirm\nsqrt(var(insurance$bmi))\n\n[1] 5.655182"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#another-boxplot",
    "href": "slides/slides-04-numerical-pt2.html#another-boxplot",
    "title": "Numerical data",
    "section": "Another boxplot",
    "text": "Another boxplot\nNow a boxplot of the estimated weights from the previous class!"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#quartiles",
    "href": "slides/slides-04-numerical-pt2.html#quartiles",
    "title": "Numerical data",
    "section": "Quartiles",
    "text": "Quartiles\n\nThe 25th percentile is the value of data with 25% of values below it. Special name: first quartile \\(Q_{1}\\)\nThe 75th percentile is the value of data with 75% of values below it. Special name: third quartile \\(Q_{3}\\)\n\nWhat percent of the data fall between \\(Q_{1}\\) and \\(Q_{3}\\)? What percent of the data fall between \\(Q_{1}\\) and the median?\n\nHow to calculate? Suppose we have \\(2q\\) (even) or \\(2q + 1\\) (odd) number of values\n\n\\(Q_{1}\\) is the median of the \\(q\\) smallest values\n\\(Q_{3}\\) is the median of the \\(q\\) largest values\n\n\nWhat are \\(Q_{1}\\) and \\(Q_{3}\\) of the data \\(\\boldsymbol{x}\\)?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#more-visualizations-and-statistics",
    "href": "slides/slides-04-numerical-pt2.html#more-visualizations-and-statistics",
    "title": "Numerical data",
    "section": "More visualizations and statistics",
    "text": "More visualizations and statistics\n\n\n\n\nWe know how to calculate some summary statistics and interpret them alongside the histogram. But wouldn’t it be great if we had a visualization that directly displays some summary statistics?"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot",
    "href": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot",
    "title": "Visualizations with ggplot",
    "section": "Introduction to ggplot",
    "text": "Introduction to ggplot\n\nWe will learn how to create histograms, box plots, and scatterplots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\n\nHow does this differ from what we’ve seen in the past?\n\nThis is what the code will generally look like. Values in < > and xxx denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, # specify data frame\n       mapping = aes(x = <x-var>)) + #  specify variables to be used in plot\n  geom_xxx() + # specify plot type\n  <other options>"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot-.incremental-t",
    "href": "slides/slides-05-numerical-data-viz.html#introduction-to-ggplot-.incremental-t",
    "title": "Visualizations with ggplot",
    "section": "Introduction to ggplot {.incremental = T}",
    "text": "Introduction to ggplot {.incremental = T}\n\nWe will learn how to create histograms, box plots, and scatterplots using the ggplot() function from the ggplot2 library\n\nPlots are constructed in layers\n\nAt a minimum, we need to specify 1) the dataset, 2) variable(s) from the dataset we’d like to plot, and 3) the type of plot\n\nHow does this differ from what we’ve seen in the past?\n\nThis is what the code will generally look like. Values in < > and xxx denote what you as the coder need to specify.\n\n\n\nggplot(data = <dataset>, # <1>\n       mapping = aes(x = <x-var>)) + # <2> \n  geom_xxx() + # <3>\n  <other options>\n\n\nSpecify data frame\nSpecify variables to be use in plot\nSpecify type of plot"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#test",
    "href": "slides/slides-05-numerical-data-viz.html#test",
    "title": "Visualizations with ggplot",
    "section": "Test",
    "text": "Test\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins |>                                      # <1>\n  mutate(                                        # <2>\n    bill_ratio = bill_depth_mm / bill_length_mm, # <2>\n    bill_area  = bill_depth_mm * bill_length_mm  # <2>\n  )                                              # <2>\n\nTake penguins, and then,\nadd new columns for the bill ratio and bill area."
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetics-color",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetics-color",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics: color",
    "text": "Aesthetics: color\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges, \n                     col = age)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi, y = charges)) +\n  geom_point(aes(col = age))"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetics-transparency",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetics-transparency",
    "title": "Visualizations with ggplot",
    "section": "Aesthetics: transparency",
    "text": "Aesthetics: transparency\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, \n                                       alpha = age)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetic-color",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetic-color",
    "title": "Visualizations with ggplot",
    "section": "Aesthetic: color",
    "text": "Aesthetic: color\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, \n                                       col = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#aesthetic-shape",
    "href": "slides/slides-05-numerical-data-viz.html#aesthetic-shape",
    "title": "Visualizations with ggplot",
    "section": "Aesthetic: shape",
    "text": "Aesthetic: shape\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age,\n                                       shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#specifying-multiple-aesthetics",
    "href": "slides/slides-05-numerical-data-viz.html#specifying-multiple-aesthetics",
    "title": "Visualizations with ggplot",
    "section": "Specifying multiple aesthetics",
    "text": "Specifying multiple aesthetics\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = age, alpha = age)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#adding-a-title",
    "href": "slides/slides-05-numerical-data-viz.html#adding-a-title",
    "title": "Visualizations with ggplot",
    "section": "Adding a title",
    "text": "Adding a title\n\nggplot(data = insurance, mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\",\n          subtitle = \"In USD\")"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#changing-axis-labels",
    "href": "slides/slides-05-numerical-data-viz.html#changing-axis-labels",
    "title": "Visualizations with ggplot",
    "section": "Changing axis labels",
    "text": "Changing axis labels\nBy default, axis titles are taken from variable name specified in aes(). To change:\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram() +\n  ggtitle(\"Histogram of charges\") +\n  xlab(\"Charges ($)\")\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram() +\n  labs(title = \"Histogram of charges\",\n       x = \"Charges ($)\", y = \"Count\")"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#geom_histogram-cont.",
    "href": "slides/slides-05-numerical-data-viz.html#geom_histogram-cont.",
    "title": "Visualizations with ggplot",
    "section": "geom_histogram() cont.",
    "text": "geom_histogram() cont.\nTo improve on histogram we change the bin width.\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram(binwidth = 5000)\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = charges)) +\n  geom_histogram(bins = 20)"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#additional-variables-modifications",
    "href": "slides/slides-05-numerical-data-viz.html#additional-variables-modifications",
    "title": "Visualizations with ggplot",
    "section": "Additional variables + modifications",
    "text": "Additional variables + modifications\n\nWe emphasize making informative and useful visualizations.\n\nInformative titles and labels\nPlot should tell a meaningful story\n\nDepending on the plot and data, we can map additional variables by:\n\nSpecifying visual cues via aesthetics: color, size, shape, alpha (transparency)\nFaceting (will see this next week)"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html",
    "href": "slides/slides-04-numerical-pt2.html",
    "title": "Numerical data",
    "section": "",
    "text": "We learned about the sample mean \\(\\bar{x}\\), the sample variance \\(s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\\), and the sample standard deviation \\(s = \\sqrt{s^2}\\)\n\nWhy care about standard deviation (SD)? Describes how far data are distributed from their mean\nUsually (but not always!!) about 70% of the data will be within one SD of the mean, and 95% will be within two SDs\n\nThese percentages are not precise, but are useful for intuition\nWe will come back to this later in semester"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#aesthetic-color",
    "href": "slides/slides-06-categorical-data.html#aesthetic-color",
    "title": "Categorical data",
    "section": "Aesthetic: color",
    "text": "Aesthetic: color\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = smoker)) +\n  geom_point() \n\n\n\nWhat do you notice about the legend for color?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#aesthetic-shape",
    "href": "slides/slides-06-categorical-data.html#aesthetic-shape",
    "title": "Categorical data",
    "section": "Aesthetic: shape",
    "text": "Aesthetic: shape\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, shape = smoker)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#facet_wrap",
    "href": "slides/slides-06-categorical-data.html#facet_wrap",
    "title": "Categorical data",
    "section": "facet_wrap()",
    "text": "facet_wrap()\nFaceting is used when we want to split a particular visualization by the values of another (categorical) variable\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_wrap(~ smoker) \n\n\n\n\n\n\n\n\n\nggplot(data = insurance, \n       mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_wrap(~ smoker, scales = \"free_y\")"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#facet_grid",
    "href": "slides/slides-06-categorical-data.html#facet_grid",
    "title": "Categorical data",
    "section": "facet_grid()",
    "text": "facet_grid()\n\nggplot(data = insurance, mapping = aes(x = bmi)) +\n  geom_histogram() +\n  facet_grid(sex ~ smoker)"
  },
  {
    "objectID": "slides/slides-03-numerical-pt1.html#describing-distributions",
    "href": "slides/slides-03-numerical-pt1.html#describing-distributions",
    "title": "Numerical data",
    "section": "Describing distributions",
    "text": "Describing distributions\nA convenient way to describe a variable’s behavior is through the shape of its distribution. Using histograms, we should identify:\n\nIf the distribution is symmetric or skewed\n\nDistributions with long tails to the left are called left-skewed\nDistributions with long tails to the right are right-skewed\nIf not skewed, then the distribution is symmetric\n\nModes which are prominent peaks in the distribution\n\nDistribution may be unimodal (one peak), bimodal (two peaks), or multimodal (more than two peaks)\nPeaks need not be same height"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#interpreting-sd",
    "href": "slides/slides-04-numerical-pt2.html#interpreting-sd",
    "title": "Numerical data",
    "section": "Interpreting SD",
    "text": "Interpreting SD\nWe learned about the sample mean \\(\\bar{x}\\), the sample variance \\(s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^2\\), and the sample standard deviation \\(s = \\sqrt{s^2}\\)\n\nWhy care about standard deviation (SD)? Describes how far data are distributed from their mean\nUsually (but not always!!) about 70% of the data will be within one SD of the mean, and 95% will be within two SDs\n\nThese percentages are not precise, but are useful for intuition\nWe will come back to this later in semester"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#visualizing-sd",
    "href": "slides/slides-04-numerical-pt2.html#visualizing-sd",
    "title": "Numerical data",
    "section": "Visualizing SD",
    "text": "Visualizing SD"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#visualizing-sd-cont.",
    "href": "slides/slides-04-numerical-pt2.html#visualizing-sd-cont.",
    "title": "Numerical data",
    "section": "Visualizing SD (cont.)",
    "text": "Visualizing SD (cont.)\n\n\nWe know how to calculate some summary statistics and interpret them alongside the histogram. But wouldn’t it be great if we had a visualization that directly displays some summary statistics?"
  },
  {
    "objectID": "slides/slides-04-numerical-pt2.html#summary",
    "href": "slides/slides-04-numerical-pt2.html#summary",
    "title": "Numerical data",
    "section": "Summary",
    "text": "Summary\n\nBoxplots are another univariate visualization for numerical data\nMedian and IQR are robust to outliers, whereas mean and standard deviation are sensitive to outliers\nWhen should we prefer median over mean (or vice versa)?\n\n\nMedian is more stable; not affected by one single data point. But mean is easier to compute than median since you do not have sort observations. Also, mean has nice theoretical properties (STAT 311). If possible, always good to calculate both!!\nMedian = what is typical, mean = what you expect. The typical charge amount is around $9000. But if you’re looking at insurance charges, you shouldn’t expect to pay that low amount."
  },
  {
    "objectID": "live_code/numerical_pt2_live.html#boxplot-and-median",
    "href": "live_code/numerical_pt2_live.html#boxplot-and-median",
    "title": "9/18/2024 Live code",
    "section": "Boxplot and median",
    "text": "Boxplot and median\n\n# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\n\n# if you don't have the readr package, please install it!\nlibrary(readr)\n\n# read data, and assign to variable called insurance\ninsurance <- read_csv(url_file)\n\nRows: 200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# boxplot: first argument is x-axis\nboxplot(insurance$bmi)\n\n\n\n# median\nmedian(insurance$bmi)\n\n[1] 30.2075\n\n# making and sorting vectors\nmy_vec <- c(1, 9, 8, -2, 4)\nsort(my_vec)\n\n[1] -2  1  4  8  9"
  },
  {
    "objectID": "slides/slides-05-numerical-data-viz.html#inheriting-arguments",
    "href": "slides/slides-05-numerical-data-viz.html#inheriting-arguments",
    "title": "Visualizations with ggplot",
    "section": "Inheriting arguments",
    "text": "Inheriting arguments\n\nMany functions related to plotting in ggplot take the form geom_xxx()\nThe Help file for these functions show that the first two arguments are mapping and data. These are automatically inherited from the mapping and data arguments in the first layer ggplot() function\n\ni.e. you don’t need to re-specify them, unless you are trying to add a new data frame’s data to your visualization"
  },
  {
    "objectID": "coding_practice/coding-practice-04-numerical-pt2.html",
    "href": "coding_practice/coding-practice-04-numerical-pt2.html",
    "title": "Numerical data coding practice",
    "section": "",
    "text": "Change your name in the YAML. Be sure to keep the quotation marks!\nIn the following code chunk, load in the openintro package. We will once again work with the cherry data set.\n\n\n\n\n\nIn the code chunk below, write code to find the mean and median of the diameter of trees in the cherry data frame.\n\n\n\n\n\nMake a box plot of the height of cherry trees. Can you make an informative axis label for your plot? Try changing the color of your boxplot by specifying col = \"color name\" in the function. Note that the name of the color must be in quotes! If you’re confused, look at the examples in the bottom of the Help file of the appropriate function.\n\n\n\n\n\nMake a scatter plot of the diameter and volume of cherry trees. Put volume on the y-axis. Add some nicer labels!\n\n\n\n\nOnce you’re finished, be sure to knit and submit the output file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "coding_practice/coding-practice-06-ggplot.html",
    "href": "coding_practice/coding-practice-06-ggplot.html",
    "title": "ggplot coding practice",
    "section": "",
    "text": "Load the tidyverse and openintro packages in the code chunk below. We will work with the mammals data from the openintro package. Load the data by typing data(mammals) right underneath where you loaded the packages. Then run the code chunk, and take a quick look at the data by clicking twice on the variable mammals in your Environment.\n\n\n# packages\n\n# data\n\n\nUsing ggplot, make a scatterplot of the gestation time and life span. (Gestation time is how long a baby is in the uterus.) You should notice that a Warning message appears. Describe in common language what the warning is trying to tell you.\n\n\n\n\nAnswer:\n\nNow, let’s make your plot from above more presentable. Using the labs() function, change the axes on your plots to have better titles that include the units. Also add a title. You may copy and paste your from above to get started. Start practicing good coding style by having line breaks between layers of the code!\n\n\n\n\n\nLet’s add color to your plot! Modify your code above to map the color of the points to the total amount of sleep each mammal gets. You might notice that some points are colored gray, instead of blue. Why do you think that is?\n\nAnswer:\nOnce you’re finished, be sure to knit and submit the outputted file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "homework/hw2_r.html",
    "href": "homework/hw2_r.html",
    "title": "Problem Set 2: R",
    "section": "",
    "text": "Throughout this assignment, try to pay attention to practicing good coding style by having each layer of ggplot code be on its own line.\n\nChange your name in the YAML. Then load in the tidyverse and openintro packages in the code chunk below. We will work with the starbucks data from the openintro package.\n\n\n# load packages here\n\n\nNotice in the code chunk above, the code chunk header reads {r message = FALSE} instead of the usual {r}. Knit this file, and briefly study the output. Then delete the message = FALSE and knit again. What is this argument is doing? Once you’ve answered this, put the message = FALSE back!\n\nAnswer:\n\nWrite code that creates a variable for the average number of calories in a Starbucks food item.\n\n\n\n\n\nIn the following code chunk, use ggplot code to create a boxplot of the amount of calories in Starbucks food items. You should note that that one of the axes has tick marks/break points that are meaningless. Add to your plot the appropriate choice of the following two functions scale_x_continuous or scale_y_continuous(), then set the breaks argument to get rid of the breaks (maybe looks at its Help file).\n\n\n\n\n\nUsing ggplot, create a histogram of the calories in Starbucks food items. Change the binwidth to make a more “pleasing” plot. Add an informative title.\n\n\n\n\n\nTo your code above, add the function layer geom_vline() to add a vertical line that displays the mean number of calories (you may want to refer to the Help file). You should use the variable you created in number 3. Make this line a color of your choice. Then, add a caption that provides a brief description of what the line represents.\nUsing the plots you created, along with some summary statistics, describe the distribution of calories in Starbucks food items. Make sure you discuss shape, center, spread, and potential outliers.\n\nAnswer:\n\nNow create a scatterplot in ggplot with calories on the y-axis. For the x-axis variable, choose a variable that displays a strong association with calories. You may have to play around a bit! Add an informative title and change the x-axis variable to include the units (grams).\n\n\n\n\n\nIn the code above, color the points by another numerical variable in the data set. Then, add a layer of code using the function scale_color_viridis_c(). When you run this code, you’ll notice that this function changes the color palette to something called the Viridis color palette. Play around with different palettes by looking to the Help file for this function and looking at the option parameter. Choose one of the eight options!\nBriefly interpret this last plot you created. This may include discussing associations/trends/patterns (or lack thereof)!\n\nAnswer:\nOnce you’re done, knit this file one more time, and submit the outputted HTML file to Canvas alongside the other homework problems."
  },
  {
    "objectID": "coding_practice/coding-practice-05-ggplot.html",
    "href": "coding_practice/coding-practice-05-ggplot.html",
    "title": "ggplot coding practice",
    "section": "",
    "text": "Load the tidyverse and openintro packages in the code chunk below. We will work with the mammals data from the openintro package.\n\nIf you want to see the data frame, type View(mammals) in the Console. That will open up a new tab with the data frame in this Source pane.\n\n# packages\n\n\nUsing ggplot, make a scatterplot of the gestation time and life span. (Gestation time is how long a baby is in the uterus.) You should notice that a Warning message appears. Describe in common language what the warning is trying to tell you.\n\n\n\n\nAnswer:\n\nNow, let’s make your plot from above more presentable. Using the labs() function, change the axes on your plots to have better titles that include the units. Also add a title. You may copy and paste your from above to get started. Start practicing good coding style by having line breaks between layers of the code!\n\n\n\n\n\nLet’s add color to your plot! Modify your code above to map the color of the points to the total amount of sleep each mammal gets. You might notice that some points are colored gray, instead of blue. Why do you think that is?\n\nAnswer:\nOnce you’re finished, be sure to knit and submit the outputted file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#categorical-data",
    "href": "slides/slides-06-categorical-data.html#categorical-data",
    "title": "Categorical data",
    "section": "Categorical data",
    "text": "Categorical data\n\nRecall that a variable is either numerical or categorical\nCategorical variables are variables that can take one of a limited (usually fixed) number of possible values, known as levels\n\nRepresent data that can be divided into groups\n\nTwo types:\n\nOrdinal: the levels have a special ordering\nNominal: the levels don’t have an ordering\n\nWe will almost exclusively treat our categorical variables as nominal in this class\n\n\nExamples and non-examples?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#insurance-data",
    "href": "slides/slides-06-categorical-data.html#insurance-data",
    "title": "Categorical data",
    "section": "Insurance data",
    "text": "Insurance data"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#univariate",
    "href": "slides/slides-06-categorical-data.html#univariate",
    "title": "Categorical data",
    "section": "Univariate",
    "text": "Univariate\nIf we are interested in understanding the distribution of a single categorical variable, it is common to:\n\n\n\n\nDisplay a frequency table, which is a table of counts of each level\n\n\n\n# A tibble: 2 × 2\n  smoker     n\n  <chr>  <int>\n1 no       155\n2 yes       45\n\n\n\n\n\n\nVisualize the data through a bar plot, where different levels are displayed on one axis and the counts are portrayed on the other"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#univariate-eda",
    "href": "slides/slides-06-categorical-data.html#univariate-eda",
    "title": "Categorical data",
    "section": "Univariate EDA",
    "text": "Univariate EDA\nIf we are interested in understanding the distribution of a single categorical variable, it is common to:\n\n\n\nDisplay a frequency table, which is a table of counts of each level\n\n\n# A tibble: 2 × 2\n  smoker     n\n  <chr>  <int>\n1 no       155\n2 yes       45\n\n\n\n\n\nCreate a bar plot, where different levels are displayed on one axis and the counts are portrayed on the other\n\n\n\n\n\n\n\n\n\nHow do bar plots differ from histograms?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bivariate-eda",
    "href": "slides/slides-06-categorical-data.html#bivariate-eda",
    "title": "Categorical data",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA\n\nPerhaps we are interested in examining the distribution of two categorical variables at the same time\nSummarize the distribution using a two-way table known as a contingency table:\n\nEach value in the table counts the number of times a particular combination of variable 1 and variable 2 levels occurred in data\n\n\n\n\n\nContingency table\n \n  \n    smoker \n    female \n    male \n  \n \n\n  \n    no \n    87 \n    68 \n  \n  \n    yes \n    17 \n    28 \n  \n\n\n\n\n\n\n\n\nHow can we use contingency table to obtain the distribution of just one of the variables?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#visualizing-numerical-and-categorical",
    "href": "slides/slides-06-categorical-data.html#visualizing-numerical-and-categorical",
    "title": "Categorical data",
    "section": "Visualizing numerical and categorical",
    "text": "Visualizing numerical and categorical\n\nggplot(data = insurance, mapping = aes(x = bmi, y = charges, col = smoker)) +\n  geom_point() \n\n\n\nWhat do you notice about the legend for color?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bar-plot-univariate",
    "href": "slides/slides-06-categorical-data.html#bar-plot-univariate",
    "title": "Categorical data",
    "section": "Bar plot (univariate)",
    "text": "Bar plot (univariate)\n\nggplot(data = insurance, mapping = aes(x = smoker)) +\n  geom_bar()\n\n\n\nNote: if your data are already in the form of frequency table, we should use geom_col() instead!"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bivariate-bar-plots",
    "href": "slides/slides-06-categorical-data.html#bivariate-bar-plots",
    "title": "Categorical data",
    "section": "Bivariate bar plots",
    "text": "Bivariate bar plots\n\n\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"dodge\")  \n\n\n\n\n\n\n\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"stack\") # this is default"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#bivariate-bar-plots-cont.",
    "href": "slides/slides-06-categorical-data.html#bivariate-bar-plots-cont.",
    "title": "Categorical data",
    "section": "Bivariate bar plots (cont.)",
    "text": "Bivariate bar plots (cont.)\n\nggplot(insurance, aes(x = smoker, fill = sex)) +\n  geom_bar(position = \"fill\")\n\n\nHow might we make the bars horizontal instead of vertical?"
  },
  {
    "objectID": "slides/slides-06-categorical-data.html#side-by-side-box-plots",
    "href": "slides/slides-06-categorical-data.html#side-by-side-box-plots",
    "title": "Categorical data",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\nggplot(data = insurance, \n       mapping = aes(x = smoker, y = bmi)) +\n  geom_boxplot()\n\n\nLike faceting, but only for box plots."
  },
  {
    "objectID": "coding_practice/coding-practice-06-categorical.html",
    "href": "coding_practice/coding-practice-06-categorical.html",
    "title": "Categorical data coding practice",
    "section": "",
    "text": "# load additional packages here\nlibrary(readr)\n\n\nIn the code chunk above, add a line of code to load in the package necessary for working with ggplot. Also change your name in the YAML.\nWe will be working with data you gave me from the start-of-semester study survey! In the following code, I would like you to delete the underscores and replace them with a variable name of your choice. The variable name should be meaningful to you, but also not too long.\n\nThen run the code chunk and take a look at the data! Then delete the argument eval = FALSE in the code chunk header!! That argument tells RStudio to not evaluate that particular code chunk when knitting, but we definitely want to evaluate this as this is how where our data gets loaded in!\n\n# url to read data from\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/stat201_f24_data.csv\"\n\n____ <- read_csv(url_file)\n\n\nDo students take the 9:45 section because they want to get more sleep? Create boxplots of the average number of hours of sleep students get per night, split by the different sections. Note there are two ways to do this!\n\nThen interpret your visualization in the context of my “research question”.\n\n\n\nAnswer:\n\nPick two categorical variables of your choice. Using an appropriate type of bar plot, compare the distribution of one variable across the distribution of the second variable. That is, do the frequencies of occurrences of the levels of one variable depend on/change with the levels of the second variable?\n\n\n\n\nAnswer:\n\nWe will change the colors in our bar plot! Look at the Help file for the function scale_fill_brewer(). You should see many options of different palettes. Add this function to your code above (use good coding style!), and set the palette argument to one of the palette names. Play around until you’ve settled on one!\nYou used the function scale_fill_brewer() above, but there is a similar function called scale_color_brewer(). Why do you think we used the first function and not the second? (You can explore this by changing your code above to scale_color_brewer and seeing what happens. Be sure to revert back to scale_fill_brewer before submitting!)\n\nAnswer:\nOnce you’re finished, be sure to knit and submit the outputted file to the corresponding Canvas assignment!"
  },
  {
    "objectID": "homework/hw3_r.html",
    "href": "homework/hw3_r.html",
    "title": "STAT 201: Problem Set 3 (R)",
    "section": "",
    "text": "In January 2017, Buzzfeed published an article titled “These Nobel Prize Winners Show Why Immigration Is So Important For American Science”. In the article they explore where many Nobel laureates in the sciences were born and where they lived when they won their prize.\nIn this homework we will work with the data about Nobel laureates to recreate/update some of their visualizations with new data as well as explore new questions.\n\nlibrary(readr)\n# add more packages here as necessary\n\n\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/nobel.csv\"\nnobel <- read_csv(url_file)\n\n\nChange your name in the YAML and add the package(s) necessary for creating ggplots and wrangling data in the code chunk above. Then run the code chunk to load in the data.\n\nA description of the variables in the nobel data are as follows:\n\nid: ID number\nfirstname: first name (and possible middle initial) of laureate\nsurname: last name/surname\nyear: the year the prize was awarded\ncategory: category of prize (Chemistry, Economics, Literature, Peace, Physics, or Medicine)\nborn_year: year laureate was born\ndied_year: year laureate died\naffiliation: affiliation of laureate at time of winning\ncity: city of laureate in prize year\ncountry: country where laureate was based in prize year\ngender: gender or laureate (male, female, or org, where org represents an organization)\nborn_city: city where laureate was born\nborn_country: country where laureate was born\nborn_country_code: two-letter country code of born_country\ndied_city: city were laureate died\ndied_country: country where laureate died\ndied_country_code: two-letter country code of died_country\nshare: reciprocal of the portion of prize awarded to the laureate\nmotivation: motivation for recognition\n\nThere are a few other variables ending in _original which correspond to locations whose names changed after the prize was given. The values in these columns are the original names of the locations at the time of the award. We won’t need to work with these variables.\n\nDisplay a summary table of the sample average and standard deviation of the ages of Nobel laureates at the time of receiving the prize. Do this in a single pipeline by:\n\n\nCreating a new variable that represents the age of the laureate when they one their prize, calculated as the year they received the award minus the year they were born\nFiltering to only retain observations for which your newly calculated age variable is available\nWriting code to actually create the summary statistics\n\nBe sure to explicitly set/define the column titles of your summary table. Then interpret these statistics (particularly the standard deviation) in context.\n\n\n\nAnswer:\n\nCreate a new data frame called nobel_living that filters for the following criteria:\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations\nlaureates who are still alive\n\n\n\n\nUse code to confirm that you have 247 laureates in your new data frame:\n\n\n\n\nBuzzfeed’s Claim #1: “Most living Nobel laureates were based in the US when they won their prizes”. Let’s see if that’s true.\n\nModify (i.e. store/assign over) your nobel_living data frame by creating a new variable called country_us. The variable should equal:\n\n“USA” if the laureate’s country value is indeed the “USA”\n“Other” is the laureate’s country value is not “USA”\n\nYou will have to use the if_else() function. Take a look at its Help file (and in particular, its examples).\n\n\n\nNow would be a good time to knit your work to save the progress and make sure everything is working!\n\nCreate a new data frame called nobel_living_science that only retains observations with laureates from the Physics, Chemistry, Medicine, and Economics categories from the nobel_living data frame.\n\n\n\n\n\nUsing the data frame nobel_living_science, create a faceted bar plot with horizontal bars that visualizes the relationship between 1) the category of prize and 2) whether the laureate was in the US when they won the Nobel prize. Note: Your visualization should be faceted by category. For each facet you should have two bars, one for winners in the US and one for Other.\n\nInterpret your visualization, and say a few words about whether the Buzzfeed Claim #1 is supported by the data.\n\n\n\nAnswer:\nNow would be a good time to knit your work to save the progress and make sure everything is working!\n\nBuzzfeed’s Claim #2: “But of those US-based Nobel laureates, many were born in other countries.” Let’s investigate this second claim!\n\nCreate a new variable called born_country_us that has the value “USA” if the laureate is born in the US, and “Other” if not. Be sure to save the variable to the data frame by storing the output back into nobel_living_science.\n\n\n\n\nLet’s improve on our previous visualization here. Visualize the relationship between where the laureate was based when they won the Nobel Prize and where they were born, split by category. Your final visualization should:\n\n\ncontain a facet for each category\nwithin each facet, have a bar for whether the laureate won the award in the US or not\nwithin each bar, display whether the laureate was born in the US or not\n\nBased on your visualization, do the data appear to support Buzzfeed’s Claim #2? Explain your reasoning in a few sentences.\n\n\n\nAnswer:\n\nWe will explore where the non-US laureates were born. In a single pipeline starting with nobel_living_science, filter for laureates who were living in the US when they won their prize but where born outside of the US. Then create a frequency table for their birth country, only displaying the top eight countries.\n\n\n\n\n\nFinally, go to the Buzzfeed website linked at the top (copy and paste the URL into Chrome or Safari) and compare your frequency table from the previous exercise to their bar plot. The numbers and ordering might not be the same. Why do you think that is?\n\nAnswer:\nOnce you’re finished, knit once more. Be sure to submitted the outputted HTML file to Canvas."
  },
  {
    "objectID": "live_code/data_wrangling.html#remember-to-save-over-data-frames-for-future-use",
    "href": "live_code/data_wrangling.html#remember-to-save-over-data-frames-for-future-use",
    "title": "Data wrangling with dplyr",
    "section": "Remember to save over data frames for future use!",
    "text": "Remember to save over data frames for future use!\nOften, we wrangle a data frame because we want certain variables to exist for future analyses. When we have modify a data frame for several future analyses, we should save over/store back into the same data frame with our new operations. As an example, in the following code, I am creating a new variable called age_months that represents the age in months.\n\ndatascience |>\n  mutate(age_months = Age * 12)\n\nNow suppose I want to visualize this variable:\n\nggplot(data = datascience, mapping = aes(x = age_months))+\n  geom_histogram()\n\nError in `geom_histogram()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! object 'age_months' not found\n\n\nIt’s complaining because the data frame datascience does not have a variable called age_months! We need to store over the previous version to make sure we “save our work”:\n\ndatascience <- datascience |>\n  mutate(age_months = Age * 12)\nggplot(data = datascience, mapping = aes(x = age_months))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html",
    "href": "live_code/data_wrangling_pt1.html",
    "title": "Data wrangling with dplyr",
    "section": "",
    "text": "Don’t forget to load the tidyverse package, which includes dplyr!\nRecall that we are looking at data provided by Kaggle. In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data.\nBy default, all dplyr functions expect the first argument to be a data frame."
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#selecting-columns",
    "href": "live_code/data_wrangling_pt1.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 102 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    36\n# ℹ 92 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 102 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    36\n# ℹ 92 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 102 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 102 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    36 Information technology, networking, or system administration\n# ℹ 92 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:Major)\n\n# A tibble: 102 × 3\n   Gender   Age Major                                                       \n   <chr>  <dbl> <chr>                                                       \n 1 Male      56 Mathematics or statistics                                   \n 2 Male      33 Other                                                       \n 3 Male      26 Computer Science                                            \n 4 Male      25 Physics                                                     \n 5 Male      33 Electrical Engineering                                      \n 6 Male      22 Information technology, networking, or system administration\n 7 Male      29 Computer Science                                            \n 8 Male      35 Physics                                                     \n 9 Male      37 Electrical Engineering                                      \n10 Male      36 Information technology, networking, or system administration\n# ℹ 92 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 102 × 7\n   Gender   Age Major    FormalEducation CompensationAmount CompensationCurrency\n   <chr>  <dbl> <chr>    <chr>                        <dbl> <chr>               \n 1 Male      56 Mathema… Master's degree             250000 USD                 \n 2 Male      33 Other    Bachelor's deg…            1200000 RUB                 \n 3 Male      26 Compute… Master's degree            1100000 TWD                 \n 4 Male      25 Physics  Bachelor's deg…              20000 USD                 \n 5 Male      33 Electri… Doctoral degree             100000 USD                 \n 6 Male      22 Informa… Bachelor's deg…             624000 RUB                 \n 7 Male      29 Compute… Master's degree             126000 PLN                 \n 8 Male      35 Physics  Doctoral degree             133000 USD                 \n 9 Male      37 Electri… Master's degree              80000 USD                 \n10 Male      36 Informa… Master's degree              80000 AUD                 \n# ℹ 92 more rows\n# ℹ 1 more variable: LanguageRecommendation <chr>"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#arranging-rows",
    "href": "live_code/data_wrangling_pt1.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable. The arrange() function does this, and requires specifying at least one variable to arrange by:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 102 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    21 Computer Science                                            \n 2    21 Computer Science                                            \n 3    22 Information technology, networking, or system administration\n 4    22 Computer Science                                            \n 5    22 Computer Science                                            \n 6    22 Computer Science                                            \n 7    22 Computer Science                                            \n 8    22 Computer Science                                            \n 9    22 Computer Science                                            \n10    23 Biology                                                     \n# ℹ 92 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#slicing-for-certain-row-numbers",
    "href": "live_code/data_wrangling_pt1.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row is index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 8\n  Country       Gender   Age Major            FormalEducation CompensationAmount\n  <chr>         <chr>  <dbl> <chr>            <chr>                        <dbl>\n1 United States Male      56 Mathematics or … Master's degree             250000\n2 Russia        Male      33 Other            Bachelor's deg…            1200000\n3 Taiwan        Male      26 Computer Science Master's degree            1100000\n4 United States Male      25 Physics          Bachelor's deg…              20000\n5 United States Male      33 Electrical Engi… Doctoral degree             100000\n# ℹ 2 more variables: CompensationCurrency <chr>, LanguageRecommendation <chr>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/data_wrangling_pt1.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we use the filter() function to only retain the observations where the person’s Major was Computer Science. This function requires specifying a logical condition, and keeps observations in which the condition is met (i.e. TRUE).\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 35 × 8\n   Country                 Gender   Age Major FormalEducation CompensationAmount\n   <chr>                   <chr>  <dbl> <chr> <chr>                        <dbl>\n 1 Taiwan                  Male      26 Comp… Master's degree            1100000\n 2 Poland                  Male      29 Comp… Master's degree             126000\n 3 India                   Male      34 Comp… Master's degree            2300000\n 4 Russia                  Male      22 Comp… Bachelor's deg…             528000\n 5 People 's Republic of … Male      28 Comp… Master's degree              70000\n 6 Russia                  Male      34 Comp… Some college/u…            1500000\n 7 Russia                  Male      22 Comp… Master's degree              70000\n 8 Italy                   Male      22 Comp… Bachelor's deg…              10000\n 9 India                   Male      23 Comp… Bachelor's deg…             400000\n10 Other                   Male      32 Comp… Master's degree            1200000\n# ℹ 25 more rows\n# ℹ 2 more variables: CompensationCurrency <chr>, LanguageRecommendation <chr>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”. In the following code, we retain cases where someone’s major was Computer Science and they were 30 years old at the time of filling out the survey.\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 3 × 2\n  Major              Age\n  <chr>            <dbl>\n1 Computer Science    30\n2 Computer Science    30\n3 Computer Science    30\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    34\n 4 Computer Science    22\n 5 Computer Science    28\n 6 Computer Science    34\n 7 Computer Science    22\n 8 Computer Science    22\n 9 Computer Science    23\n10 Computer Science    32\n# ℹ 26 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 3 × 2\n  Major              Age\n  <chr>            <dbl>\n1 Computer Science    30\n2 Computer Science    30\n3 Computer Science    30"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/data_wrangling_pt1.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\nThe distinct() function requires specifying variables in the data frame, and the function will keep only unique/distinct instances of the variable(s). Unless otherwise specified, it will drop all the other variables.\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 4 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 29 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree Computer Science                                           \n 5 Bachelor's degree Biology                                                    \n 6 Bachelor's degree A humanities discipline                                    \n 7 Bachelor's degree Electrical Engineering                                     \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree Mathematics or statistics                                  \n10 Doctoral degree   Electrical Engineering                                     \n# ℹ 19 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#mutate-to-add-a-new-variable",
    "href": "live_code/data_wrangling_pt1.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify:\n\nThe name of the new variable and\nHow to calculate the value of that new variable for each observation. This will typically involve operations involving variables already present in the data frame.\n\nWe link the two with an equals sign.\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 102 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              80000              80\n# ℹ 92 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#counting-to-create-frequency-tables",
    "href": "live_code/data_wrangling_pt1.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(LanguageRecommendation)\n\n# A tibble: 8 × 2\n  LanguageRecommendation     n\n  <chr>                  <int>\n1 C/C++/C#                   3\n2 Haskell                    1\n3 Matlab                     3\n4 Other                      1\n5 Python                    66\n6 R                         19\n7 SQL                        6\n8 Scala                      3\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(LanguageRecommendation, sort = T)\n\n# A tibble: 8 × 2\n  LanguageRecommendation     n\n  <chr>                  <int>\n1 Python                    66\n2 R                         19\n3 SQL                        6\n4 C/C++/C#                   3\n5 Matlab                     3\n6 Scala                      3\n7 Haskell                    1\n8 Other                      1\n\n\n\ndatascience |>\n  count(LanguageRecommendation) |>\n  arrange(desc(n))\n\n# A tibble: 8 × 2\n  LanguageRecommendation     n\n  <chr>                  <int>\n1 Python                    66\n2 R                         19\n3 SQL                        6\n4 C/C++/C#                   3\n5 Matlab                     3\n6 Scala                      3\n7 Haskell                    1\n8 Other                      1\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#practice",
    "href": "live_code/data_wrangling_pt1.html#practice",
    "title": "Data wrangling with dplyr",
    "section": "Practice",
    "text": "Practice\nSuppose I want to report a data frame that reports each unique level of Major and the proportion of times each level was observed in the data set in order of most popular to least popular. How might we do that?\n\n\nCode\ndatascience |>\n  count(Major) |>\n  mutate(prop = n/sum(n)) |>\n  select(Major, prop) |>\n  arrange(desc(prop))"
  },
  {
    "objectID": "live_code/data_wrangling_pt1.html#summarising-for-summary-statistics",
    "href": "live_code/data_wrangling_pt1.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     32.8\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead? You’ll note that the calculation becomes the column title."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html",
    "href": "live_code/data_wrangling_pt2.html",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "",
    "text": "Don’t forget to load the tidyverse package!\nRecall that we are looking at data provided by Kaggle. In 2017, Kaggle conducted an industry-wide survey to establish a comprehensive view of the state of data science and machine learning. We will be looking at just a subset of the data."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#selecting-columns",
    "href": "live_code/data_wrangling_pt2.html#selecting-columns",
    "title": "Data wrangling with dplyr",
    "section": "Selecting columns",
    "text": "Selecting columns\nSometimes, there are a lot of columns in a data frame and we might not want all of them. The select() function gives us an easy way to choose which columns/variables we’d like to work with.\nThe select() function requires by default two arguments: the data frame and the variable names to choose from that data frame.\nThe following code works…\n\nselect(datascience, Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n…but it’s preferable to take advantage of piping in order to make code more readable:\n\ndatascience |>\n  select(Age)\n\n# A tibble: 2,288 × 1\n     Age\n   <dbl>\n 1    56\n 2    33\n 3    26\n 4    25\n 5    33\n 6    22\n 7    29\n 8    35\n 9    37\n10    31\n# ℹ 2,278 more rows\n\n\n\n\nWhat’s going on here?\n\nStart with the data frame datascience\nPipe (|>) the data frame to the select() function and specify that we want the variable Age\nThe result is a data frame with 2288 rows and 1 column with the Age variable\n\n\n\n\n\n\n\nCheck\n\n\n\nWhy do we type Age and not age?\n\n\n\nMultiple variables and excluding\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\ndatascience |>\n  select(Age, Major)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1    56 Mathematics or statistics                                   \n 2    33 Other                                                       \n 3    26 Computer Science                                            \n 4    25 Physics                                                     \n 5    33 Electrical Engineering                                      \n 6    22 Information technology, networking, or system administration\n 7    29 Computer Science                                            \n 8    35 Physics                                                     \n 9    37 Electrical Engineering                                      \n10    31 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if we swap the order of the variable names?\n\n\n\nA range of variables\n\ndatascience |>\n  select(Gender:EmploymentStatus)\n\n# A tibble: 2,288 × 3\n   Gender   Age EmploymentStatus                                    \n   <chr>  <dbl> <chr>                                               \n 1 Male      56 Independent contractor, freelancer, or self-employed\n 2 Male      33 Employed full-time                                  \n 3 Male      26 Employed full-time                                  \n 4 Male      25 Employed part-time                                  \n 5 Male      33 Employed full-time                                  \n 6 Male      22 Employed full-time                                  \n 7 Male      29 Employed full-time                                  \n 8 Male      35 Employed full-time                                  \n 9 Male      37 Employed full-time                                  \n10 Male      31 Employed part-time                                  \n# ℹ 2,278 more rows\n\n\n\n\nExcluding variables\n\ndatascience |>\n  select(-Country)\n\n# A tibble: 2,288 × 16\n   Gender   Age EmploymentStatus          EmployerIndustry FormalEducation Major\n   <chr>  <dbl> <chr>                     <chr>            <chr>           <chr>\n 1 Male      56 Independent contractor, … Mix of fields    Master's degree Math…\n 2 Male      33 Employed full-time        Internet-based   Bachelor's deg… Other\n 3 Male      26 Employed full-time        Financial        Master's degree Comp…\n 4 Male      25 Employed part-time        Academic         Bachelor's deg… Phys…\n 5 Male      33 Employed full-time        Telecommunicati… Doctoral degree Elec…\n 6 Male      22 Employed full-time        Mix of fields    Bachelor's deg… Info…\n 7 Male      29 Employed full-time        Pharmaceutical   Master's degree Comp…\n 8 Male      35 Employed full-time        Technology       Doctoral degree Phys…\n 9 Male      37 Employed full-time        Technology       Master's degree Elec…\n10 Male      31 Employed part-time        Technology       Doctoral degree Comp…\n# ℹ 2,278 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#arranging-rows",
    "href": "live_code/data_wrangling_pt2.html#arranging-rows",
    "title": "Data wrangling with dplyr",
    "section": "Arranging rows",
    "text": "Arranging rows\nWe might want to re-arrange rows in ascending or descending order according to a certain variable. The arrange() function does this, and requires specifying at least one variable to arrange by:\n\ndatascience |>\n  select(Age, Major) |>\n  arrange(Age)\n\n# A tibble: 2,288 × 2\n     Age Major                                                       \n   <dbl> <chr>                                                       \n 1     0 Mathematics or statistics                                   \n 2     1 Other                                                       \n 3    19 Computer Science                                            \n 4    19 Biology                                                     \n 5    20 Information technology, networking, or system administration\n 6    20 Mathematics or statistics                                   \n 7    20 Computer Science                                            \n 8    20 Mathematics or statistics                                   \n 9    21 Other                                                       \n10    21 Computer Science                                            \n# ℹ 2,278 more rows\n\n\n\n\nBy default, arrange() will reorder in ascending order. If we’d like to go in descending order, we can code arrange(desc(Age))."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#slicing-for-certain-row-numbers",
    "href": "live_code/data_wrangling_pt2.html#slicing-for-certain-row-numbers",
    "title": "Data wrangling with dplyr",
    "section": "Slicing for certain row numbers",
    "text": "Slicing for certain row numbers\nRemember, data frames are in tabular format. So each row has a certain index, as does each column. The first row is index 1, the second row index 2, etc.\nThe slice() function expects a vector of row indices to retain:\n\ndatascience |>\n  slice(1:5)\n\n# A tibble: 5 × 17\n  Country   Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n  <chr>     <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n1 United S… Male      56 Independent con… Mix of fields    Master's degree Math…\n2 Russia    Male      33 Employed full-t… Internet-based   Bachelor's deg… Other\n3 Taiwan    Male      26 Employed full-t… Financial        Master's degree Comp…\n4 United S… Male      25 Employed part-t… Academic         Bachelor's deg… Phys…\n5 United S… Male      33 Employed full-t… Telecommunicati… Doctoral degree Elec…\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat is the difference between select() and slice()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#filtering-to-select-a-subset-of-rows",
    "href": "live_code/data_wrangling_pt2.html#filtering-to-select-a-subset-of-rows",
    "title": "Data wrangling with dplyr",
    "section": "Filtering to select a subset of rows",
    "text": "Filtering to select a subset of rows\nThe slice() function is nice, but unless the rows of your data frame are ordered meaningfully, its actual utility is limited. We might want to look at a set of the cases in which a certain condition is met.\nIn the following code, we use the filter() function to only retain the observations where the person’s Major was Computer Science. This function requires specifying a logical condition, and keeps observations in which the condition is met (i.e. TRUE).\n\ndatascience |>\n  filter(Major == \"Computer Science\")\n\n# A tibble: 681 × 17\n   Country  Gender   Age EmploymentStatus EmployerIndustry FormalEducation Major\n   <chr>    <chr>  <dbl> <chr>            <chr>            <chr>           <chr>\n 1 Taiwan   Male      26 Employed full-t… Financial        Master's degree Comp…\n 2 Poland   Male      29 Employed full-t… Pharmaceutical   Master's degree Comp…\n 3 Iran     Male      31 Employed part-t… Technology       Doctoral degree Comp…\n 4 Brazil   Male      25 Employed full-t… Academic         Master's degree Comp…\n 5 Brazil   Male      32 Employed full-t… Academic         Master's degree Comp…\n 6 Russia   Male      31 Independent con… CRM/Marketing    Some college/u… Comp…\n 7 India    Male      23 Employed full-t… Technology       Master's degree Comp…\n 8 Canada   Male      52 Employed full-t… Academic         Bachelor's deg… Comp…\n 9 Russia   Male      26 Independent con… Military/Securi… Bachelor's deg… Comp…\n10 Czech R… Male      25 Independent con… Internet-based   Master's degree Comp…\n# ℹ 671 more rows\n# ℹ 10 more variables: CompensationAmount <dbl>, CompensationCurrency <chr>,\n#   CurrentJobTitle <chr>, TitleFit <chr>, LanguageRecommendation <chr>,\n#   DataScienceIdentity <chr>, WorkDataVisualizations <chr>,\n#   JobSatisfaction <chr>, JobSatisfaction2 <dbl>, ConversionUSD <dbl>\n\n\n\nMultiple conditions\n\n\n\n\n\n\nExpand\n\n\n\n\n\nWe can also filter for more than one condition at once. Within filter(), the comma , specifies that all conditions must be true. It can be read as “and”. In the following code, we retain cases where someone’s major was Computer Science and they were 30 years old at the time of filling out the survey.\n\ndatascience |>\n  filter(Major == \"Computer Science\", \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 36 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Computer Science    30\n10 Computer Science    30\n# ℹ 26 more rows\n\n\nIf we just need at least one of multiple conditions to be true, we can use the | operator which stands for “or”:\n\ndatascience |>\n  filter(Major == \"Computer Science\" | \n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 765 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    26\n 2 Computer Science    29\n 3 Computer Science    31\n 4 Computer Science    25\n 5 Computer Science    32\n 6 Computer Science    31\n 7 A social science    30\n 8 Computer Science    23\n 9 Biology             30\n10 Computer Science    52\n# ℹ 755 more rows\n\n\n\ndatascience |>\n  filter(Major == \"Computer Science\" | Major == \"Other\",\n         Age == 30) |>\n  select(Major, Age)\n\n# A tibble: 44 × 2\n   Major              Age\n   <chr>            <dbl>\n 1 Computer Science    30\n 2 Computer Science    30\n 3 Computer Science    30\n 4 Computer Science    30\n 5 Computer Science    30\n 6 Computer Science    30\n 7 Computer Science    30\n 8 Computer Science    30\n 9 Other               30\n10 Computer Science    30\n# ℹ 34 more rows"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#distinct-to-filter-for-unique-rows",
    "href": "live_code/data_wrangling_pt2.html#distinct-to-filter-for-unique-rows",
    "title": "Data wrangling with dplyr",
    "section": "Distinct to filter for unique rows",
    "text": "Distinct to filter for unique rows\nThe distinct() function requires specifying variables in the data frame, and the function will keep only unique/distinct instances of the variable(s). Unless otherwise specified, it will drop all the other variables.\n\ndatascience |>\n  distinct(FormalEducation)\n\n# A tibble: 5 × 1\n  FormalEducation                                                  \n  <chr>                                                            \n1 Master's degree                                                  \n2 Bachelor's degree                                                \n3 Doctoral degree                                                  \n4 Some college/university study without earning a bachelor's degree\n5 I prefer not to answer                                           \n\ndatascience |>\n  distinct(FormalEducation, Major) |>\n  arrange(FormalEducation)\n\n# A tibble: 58 × 2\n   FormalEducation   Major                                                      \n   <chr>             <chr>                                                      \n 1 Bachelor's degree Other                                                      \n 2 Bachelor's degree Physics                                                    \n 3 Bachelor's degree Information technology, networking, or system administrati…\n 4 Bachelor's degree A social science                                           \n 5 Bachelor's degree Electrical Engineering                                     \n 6 Bachelor's degree Mathematics or statistics                                  \n 7 Bachelor's degree Computer Science                                           \n 8 Bachelor's degree Engineering (non-computer focused)                         \n 9 Bachelor's degree A humanities discipline                                    \n10 Bachelor's degree Management information systems                             \n# ℹ 48 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat variables are by default included in the output from distinct()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#mutate-to-add-a-new-variable",
    "href": "live_code/data_wrangling_pt2.html#mutate-to-add-a-new-variable",
    "title": "Data wrangling with dplyr",
    "section": "Mutate to add a new variable",
    "text": "Mutate to add a new variable\nIt is typical for us to want to add variables to a given data frame. We do this with the mutate() function. We must specify:\n\nThe name of the new variable and\nHow to calculate the value of that new variable for each observation. This will typically involve operations involving variables already present in the data frame.\n\nWe link the two with an equals sign.\n\ndatascience %>%\n  mutate(compensation_1k = CompensationAmount/1000) |>\n  select(CompensationAmount, compensation_1k)\n\n# A tibble: 2,288 × 2\n   CompensationAmount compensation_1k\n                <dbl>           <dbl>\n 1             250000             250\n 2            1200000            1200\n 3            1100000            1100\n 4              20000              20\n 5             100000             100\n 6             624000             624\n 7             126000             126\n 8             133000             133\n 9              80000              80\n10              15000              15\n# ℹ 2,278 more rows\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat exactly is going on in the second line of code?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#counting-to-create-frequency-tables",
    "href": "live_code/data_wrangling_pt2.html#counting-to-create-frequency-tables",
    "title": "Data wrangling with dplyr",
    "section": "Counting to create frequency tables",
    "text": "Counting to create frequency tables\nWe can count the number of instances we observed each level of a given categorical variable:\n\ndatascience |>\n  count(EmployerIndustry)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 CRM/Marketing                       70\n 3 Financial                          211\n 4 Government                         137\n 5 Hospitality/Entertainment/Sports    27\n 6 Insurance                           68\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 Military/Security                   35\n10 Mix of fields                      195\n11 Non-profit                          35\n12 Other                              198\n13 Pharmaceutical                      54\n14 Retail                              61\n15 Technology                         445\n16 Telecommunications                  65\n\n\n\n\n\n\n\n\nCheck\n\n\n\nHow does the resulting data frame from count() compare to the original data frame we passed in?\n\n\n\nMaking frequency tables useful\nWe typically want to present the counts in ascending or descending order.\n\n\n\n\n\n\nExpand\n\n\n\n\n\nNote that the following chunks of code do the same thing. One of them takes advantage of an additional argument in count(), whereas the other block of the uses an additional function:\n\ndatascience |>\n  count(EmployerIndustry, sort = T)\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\ndatascience |>\n  count(EmployerIndustry) |>\n  arrange(desc(n))\n\n# A tibble: 16 × 2\n   EmployerIndustry                     n\n   <chr>                            <int>\n 1 Academic                           478\n 2 Technology                         445\n 3 Financial                          211\n 4 Other                              198\n 5 Mix of fields                      195\n 6 Government                         137\n 7 Internet-based                     134\n 8 Manufacturing                       75\n 9 CRM/Marketing                       70\n10 Insurance                           68\n11 Telecommunications                  65\n12 Retail                              61\n13 Pharmaceutical                      54\n14 Military/Security                   35\n15 Non-profit                          35\n16 Hospitality/Entertainment/Sports    27\n\n\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you pass in more than one variable into count()?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#practice",
    "href": "live_code/data_wrangling_pt2.html#practice",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Practice",
    "text": "Practice\nWrite code to create a summary table reporting the average age of survey respondents for each category of formal education, in descending order.\n\n\nCode\ndatascience |>\n  group_by(FormalEducation) |>\n  summarise(avg_age = mean(Age)) |>\n  arrange(desc(avg_age))"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#summarising-for-summary-statistics",
    "href": "live_code/data_wrangling_pt2.html#summarising-for-summary-statistics",
    "title": "Data wrangling with dplyr",
    "section": "Summarising for summary statistics",
    "text": "Summarising for summary statistics\nThe summarise() function gives us an easy way to calculate summary statistics of variables in the data frame! We just need to know the name of the function that will calculate the summary statistic for us.\n\ndatascience |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     34.4\n\n\n\n\nYou can obtain multiple summary statistics at once by separating the desired summary statistics with commas.\nThe summarise() function changes the data frame entirely. It collapses rows down to a summary statistic, and removes all columns that are irrelevant to the calculation.\n\n\n\n\n\n\nCheck\n\n\n\nWhat happens if you type summarise(mean(Age)) instead? You’ll note that the calculation becomes the column title."
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#remember-to-save-over-data-frames-for-future-use",
    "href": "live_code/data_wrangling_pt2.html#remember-to-save-over-data-frames-for-future-use",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Remember to save over data frames for future use!",
    "text": "Remember to save over data frames for future use!\nOften, we wrangle a data frame because we want certain variables to exist for future analyses. When we have modify a data frame for several future analyses, we should save over/store back into the same data frame with our new operations. As an example, in the following code, I am creating a new variable called age_months that represents the age in months.\n\ndatascience |>\n  mutate(age_months = Age * 12)\n\nNow suppose I want to work with this variable:\n\ndatascience |>\n  summarise(mean_age_months = mean(age_months))\n\nError in `summarise()`:\nℹ In argument: `mean_age_months = mean(age_months)`.\nCaused by error:\n! object 'age_months' not found\n\n\nIt’s complaining because the data frame datascience does not have a variable called age_months! We need to store over the previous version to make sure we “save our work”:\n\ndatascience <- datascience |>\n  mutate(age_months = Age * 12)"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#grouping-by-grouped-operations",
    "href": "live_code/data_wrangling_pt2.html#grouping-by-grouped-operations",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Grouping by grouped operations",
    "text": "Grouping by grouped operations\nSometimes, we want to look at a given statistic or create a new variable focusing on each level of a specific categorical variable. The group_by() function tells R to treat each unique level as a separate data set.\n\ndatascience |>\n  group_by(FormalEducation) |>\n  summarise(mean_age = mean(Age))\n\n# A tibble: 4 × 2\n  FormalEducation                                                   mean_age\n  <chr>                                                                <dbl>\n1 Bachelor's degree                                                     31.9\n2 Doctoral degree                                                       35.9\n3 Master's degree                                                       33.0\n4 Some college/university study without earning a bachelor's degree     25.8\n\n\nIt’s always important to ungroup() after using group_by()! Otherwise, the grouping with carry on and could lead to potential errors in your future wrangling! Notice the differences in the outputs in the following examples:\n\ndatascience |>\n  group_by(Major) |>\n  mutate(mean_age = mean(Age))|>\n  mutate(mean_comp = mean(CompensationAmount)) |>\n  ungroup() |>\n  select(Major, mean_age, mean_comp) |>\n  arrange(Major)\n\n# A tibble: 102 × 3\n   Major                   mean_age mean_comp\n   <chr>                      <dbl>     <dbl>\n 1 A humanities discipline     60      55000 \n 2 A social science            34      50000 \n 3 Biology                     28.3    18550 \n 4 Biology                     28.3    18550 \n 5 Biology                     28.3    18550 \n 6 Computer Science            28.4  1130131.\n 7 Computer Science            28.4  1130131.\n 8 Computer Science            28.4  1130131.\n 9 Computer Science            28.4  1130131.\n10 Computer Science            28.4  1130131.\n# ℹ 92 more rows\n\ndatascience |>\n  group_by(Major) |>\n  mutate(mean_age = mean(Age)) |>\n  ungroup() |>\n  mutate(mean_comp = mean(CompensationAmount)) |>\n  select(Major, mean_age, mean_comp) |>\n  arrange(Major)\n\n# A tibble: 102 × 3\n   Major                   mean_age mean_comp\n   <chr>                      <dbl>     <dbl>\n 1 A humanities discipline     60     604512.\n 2 A social science            34     604512.\n 3 Biology                     28.3   604512.\n 4 Biology                     28.3   604512.\n 5 Biology                     28.3   604512.\n 6 Computer Science            28.4   604512.\n 7 Computer Science            28.4   604512.\n 8 Computer Science            28.4   604512.\n 9 Computer Science            28.4   604512.\n10 Computer Science            28.4   604512.\n# ℹ 92 more rows"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#piping-to-ggplot",
    "href": "live_code/data_wrangling_pt2.html#piping-to-ggplot",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Piping to ggplot()",
    "text": "Piping to ggplot()\nRemember that when creating plots, ggplot() expects a data frame as its first argument.\nWe may sometimes need to wrangle data prior to visualizing it. We have two options (both have pros and cons):\n\nWrangle the original data, store the resulting data frame as a new object or overwrite the previous one, and then refer to that data frame with ggplot()\n\n\ndatascience_india <- datascience |>\n  filter(Country == \"India\")\n\nggplot(data = datascience_india, mapping = aes(x = Age)) +\n  geom_histogram(bins = 20)\n\n\n\n\n\nWrangle the original data, and then directly pipe the result into ggplot(), which knows to expect a data frame as its first argument:\n\n\n# Notice that we don't specify the data parameter in ggplot()!\ndatascience |>\n  filter(Country == \"India\") |>\n  ggplot(mapping = aes(x = Age)) + \n  geom_histogram(bins = 20)\n\n\n\n\n\n\n\n\nWhen do we use |> and when do we use + to connect lines of code?"
  },
  {
    "objectID": "live_code/data_wrangling_pt2.html#warm-uprecap",
    "href": "live_code/data_wrangling_pt2.html#warm-uprecap",
    "title": "Data wrangling with dplyr (cont.)",
    "section": "Warm-up/Recap:",
    "text": "Warm-up/Recap:\nWrite code to determine many different programming languages were recommended in the data:\n\n\nCode\ndatascience |>\n  distinct(LanguageRecommendation) |>\n  nrow()\n\n\nDisplay a data frame of the respondents who were living in the United States and were at most 35 years old at the time of taking the survey.\n\n\nCode\ndatascience |>\n  filter(Country == \"United States\", Age <= 35)"
  },
  {
    "objectID": "live_code/kaggle_survey_analysis.html",
    "href": "live_code/kaggle_survey_analysis.html",
    "title": "Kaggle survey: group data wrangling",
    "section": "",
    "text": "We will now work a larger subset of the Kaggle data science survey data!"
  },
  {
    "objectID": "live_code/kaggle_survey_analysis.html#group-analysis",
    "href": "live_code/kaggle_survey_analysis.html#group-analysis",
    "title": "Kaggle survey: group data wrangling",
    "section": "Group analysis",
    "text": "Group analysis\nI want your group to generate your own investigation. Using your data-wrangling and plotting skills to do some EDA. After about a half hour, your group will share your process and results with the rest of the class!\nYour final results must include:\n\nA meaningful use of group_by()\nSummary statistics or frequency table\nVisualization with meaningful labels/titles\n\nYou can create more than one visualization and/or more than one table. Whatever speaks to you! The individual components (i.e. table/summary stats vs plot) do not need to use the same set of variables. Feel free to create as many code chunks as you’d like! There is a data dictionary at the bottom of this page that defines all the variables in the data set for you."
  },
  {
    "objectID": "live_code/kaggle_survey_analysis.html#data-dictionary",
    "href": "live_code/kaggle_survey_analysis.html#data-dictionary",
    "title": "Kaggle survey: group data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the data dictionary for the subset of the Kaggle data data.\n\nCountry: home country of employee (character)\nGender: specified gender (character)\nAge: age at time of survey (numeric)\nEmploymentStatus: reported employed status (character)\nEmployerIndustry: employer’s industry (character)\nMajor: college major (character)\nCompensationAmount: annual compensation (numeric)\nCompensationCurrency: three-letter currency code (character)\nCurrentJobTitle: job title (character)\nTitleFit: assessment of how well the job title fits (“Fine”, “Perfectly”, “Poorly”)\nLanguageRecommendation: recommended programming language (character)\nDataScienceIdentity: does the respondent identify as a data scientist (character)\nWorkDataVisualizations: proportion of job dedicated to creating data visualizations, broken into pre-determined categories (character)\nJobSatisfaction: rating of job satisfaction on scale of 1-10, where 1 is not satisfied and 10 is highly satisfied (character)\nJobSatisfaction2: numeric version of JobSatisfaction (numeric)\nConversionUSD: conversion factor from CompensationCurrency to USD (numeric)"
  },
  {
    "objectID": "slides/slides-08-probability.html#random-variable",
    "href": "slides/slides-08-probability.html#random-variable",
    "title": "Probability basics",
    "section": "Random variable",
    "text": "Random variable\n\nA random variable is a variable whose value is unknown and depends on random events\n\nOften denoted with a capital letter like \\(X\\) or \\(Y\\)\n\nThere are two types: discrete and continuous (just like in numeric variables)\n\nDiscrete: represents random process where sample space is countable (i.e. finite, or distinct counts)\nContinuous: sample space is uncountable (i.e. can take on any value within a specified interval with infinite number of possible values)\n\nNOTE: we will focus on discrete random variables for now"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#misc.-live-code",
    "href": "slides/slides-10-simpsons.html#misc.-live-code",
    "title": "Simpson’s paradox",
    "section": "Misc. live code",
    "text": "Misc. live code\n\nlibrary(readr)\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/main/live_code/data/insurance.csv\"\ninsurance <- read_csv(url_file)\n\nWe will return to insurance data to learn about:\n\nUsing wrangling to obtain probabilities\ncase_when() to create more complex categorical variables"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#wrangling-for-probabilities",
    "href": "slides/slides-10-simpsons.html#wrangling-for-probabilities",
    "title": "Simpson’s paradox",
    "section": "Wrangling for probabilities",
    "text": "Wrangling for probabilities\n\n\nWhat is probability that someone is a smoker?\n\ninsurance |>\n  count(smoker) |>\n  mutate(prob = n/sum(n)) |>\n  select(-n)\n\n# A tibble: 2 × 2\n  smoker  prob\n  <chr>  <dbl>\n1 no     0.775\n2 yes    0.225\n\n\n\n\nWhat is the probability that someone is a smoker, conditioned on sex?\n\ninsurance |>\n  count(smoker, sex) |>\n  group_by(sex) |>\n  mutate(cond_prob = n/sum(n)) |>\n  select(-n)\n\n# A tibble: 4 × 3\n# Groups:   sex [2]\n  smoker sex    cond_prob\n  <chr>  <chr>      <dbl>\n1 no     female     0.837\n2 no     male       0.708\n3 yes    female     0.163\n4 yes    male       0.292"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#case_when",
    "href": "slides/slides-10-simpsons.html#case_when",
    "title": "Simpson’s paradox",
    "section": "case_when()",
    "text": "case_when()\nWe will use the case_when() function which generalizes if_else(). We use the following notation: <logical condition> ~ <value of variable>. Different “ifs” are separated by commas, and the logical conditions are checked sequentially.\n\n\n\ninsurance |>\n  mutate(bmi_cat = case_when(\n    bmi < 18.5 ~ \"under\",\n    bmi >= 18.5 & bmi < 25 ~ \"healthy\",\n    bmi >= 25 & bmi < 30 ~ \"over\",\n    bmi >= 30 ~ \"obese\"\n  )) |>\n  select(bmi, bmi_cat) |>\n  slice(1:5)\n\n# A tibble: 5 × 2\n    bmi bmi_cat\n  <dbl> <chr>  \n1  27.9 over   \n2  33.8 obese  \n3  33   obese  \n4  22.7 healthy\n5  28.9 over   \n\n\n\n\n# The following is also acceptable, but \n# relies on sequential ordering:\ninsurance |>\n  mutate(bmi_cat = case_when(\n    bmi < 18.5 ~ \"under\",\n    bmi >= 18.5 & bmi < 25 ~ \"healthy\",\n    bmi >= 25 & bmi < 30 ~ \"over\",\n    T ~ \"obese\" \n  )) |>\n  select(bmi, bmi_cat) |>\n  slice(1:5)\n\n# A tibble: 5 × 2\n    bmi bmi_cat\n  <dbl> <chr>  \n1  27.9 over   \n2  33.8 obese  \n3  33   obese  \n4  22.7 healthy\n5  28.9 over"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#more-complex-categorical-variables",
    "href": "slides/slides-10-simpsons.html#more-complex-categorical-variables",
    "title": "Simpson’s paradox",
    "section": "More complex categorical variables",
    "text": "More complex categorical variables\nSuppose I want to create a new variable representing the categories of BMI, constructed as follows:\n\nunderweight if someone’s BMI is less than 18.5\nhealthy if BMI is 18.5 to less than 25\noverweight if BMI is 25 to less than 30\nobese if BMI is 30 or greater\n\n\n\n# option 1 (awful): nested if_else()\ninsurance |>\n  mutate(bmi_cat = if_else(bmi < 18.5, \"under\",\n                           if_else(bmi >= 18.5 & bmi < 25, \"healthy\",\n                                   if_else(...))))"
  },
  {
    "objectID": "coding-practice-10-simpsons.html",
    "href": "coding-practice-10-simpsons.html",
    "title": "Conditional probabilities coding practice",
    "section": "",
    "text": "Today’s data comes from a study of conducted in Whickham, England. In this study, the researchers recorded each participant’s age, smoking status at the start of the study, and their health outcome 20 years later.\nThe data is in the mosaicData package. You will have to install the package first! Then run the following code:\n\nlibrary(tidyverse)\nlibrary(mosaicData)\n\nWe will work with the Whickham data. You should open its Help file and take a view of the data before proceeding. Note that “factor” can be though of as a categorical variable. Make sure you understand the data before proceeding!\nDiscuss with your group: What would you expect the relationship between smoking status and health outcome to be?\n\nCreate an appropriate visualization depicting the relationship between smoking status and health outcome.\n\n\n\n\n\nUsing wrangling code, calculate the conditional probabilities of death of each smoking status. Please report only the probabilities for when outcome is Dead.\n\n\n\n\nWith your group, briefly describe the relationship and whether or not it is what you expected. You may want to discuss the visualization from the previous exercise as well.\n\nCreate a new variable for future use called age_cat that takes the values as follows:\n\n\n“18-44”: if someone is less than or equal to 44 years old\n“45-64”: if someone is between 45 and 64 years old, inclusive\n“65+”: if someone is older than 64\n\n\n\n\n\nRe-create your first visualization, this time faceting by age_cat. You are welcome to copy-paste code if that is helpful.\n\n\n\n\n\nExtend your table from above by breaking it down by age category. You are welcome to copy-paste code if that is helpful.\n\n\n\n\nWith your group, compare the two visualizations and the two summary tables. What changed, and what might explain the change?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#general-multiplication-rule",
    "href": "slides/slides-09-conditional-probability.html#general-multiplication-rule",
    "title": "Conditional probability",
    "section": "General multiplication rule",
    "text": "General multiplication rule\nConditional, joint, and marginal probabilities are related via the general multiplication rule:\n\n\\[\n\\text{P}(A \\cap B) =\n\\]\n\n\nLet’s see this in the coffee example!\nVery useful for finding probability that two events will happen in sequence.\n\nExample: A box has three tickets, colored red, orange, yellow. We will draw two tickets randomly one-at-a-time without replacement. What is the probability of drawing the red ticket first and then the orange ticket?"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#tree-diagram",
    "href": "slides/slides-09-conditional-probability.html#tree-diagram",
    "title": "Conditional probability",
    "section": "Tree diagram",
    "text": "Tree diagram\nTool to organize outcomes and probabilities around the structure of the data. Useful when outcomes occur sequentially, and outcomes are conditioned on predecessors. Let’s do an example:\n\nA class has a midterm and a final exam. 13% of students earned an A on the midterm. Of those students who earned an A on the midterm, 47% received an A on the final. Of those student who earned below an A on the midterm, 11% received an A on the final. You randomly pick up a final exam and notice the student received an A. What is the probability that they earned an A on the midterm?\n\nUsing \\(\\text{P}()\\) notation, what probability are we interested in? What probabilities do we need to calculate along the way?\n\nLet’s construct our tree!\n\nIn the tree diagram, where are the three types of probabilities appearing?"
  },
  {
    "objectID": "midterms.html",
    "href": "midterms.html",
    "title": "Midterms",
    "section": "",
    "text": "When and where: Thursday, October 10 during class (75 minutes)\nWhat: content through end of Week 4 (i.e. through Simpson’s Paradox)\n\nYou will not be asked to write code, but you may be asked to read or critique it\n\nImportant: Prof. Tang will be proctoring the exam\nYou will not have a problem set assigned this week!\nProf. Tang will move Friday’s office hours to Wednesday 10/09 3-4pm instead.\n\nYou should bring a calculator to the midterm. If you do not have one, the department can provide very basic calculators."
  },
  {
    "objectID": "midterms.html#preparation",
    "href": "midterms.html#preparation",
    "title": "Midterms",
    "section": "Preparation",
    "text": "Preparation\n\nThe best preparation you can do for the midterm is to go back through your notes and homework and be honest with yourself about what you do/don’t understand. This means going through the painful process of looking at feedback on Canvas. For the concepts that you need to practice more, try more problems (see below)!\nAnother way to prepare is to create your own study guide with summaries and examples of important concepts. As you study, it would be a good diea to compile a list of questions that you might have.\nWork on the practice problems that were distributed at the end of classes but not assigned.\nFor extra practice, additional review problems will soon be made available below. These questions are not necessarily representative of the typical scope and difficulty of individual exam questions. This review is not comprehensive, nor does it represent the expected amount of time for it will take for you to complete the midterm.\n\nExtra problems here and here\nVideo recap of probability"
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "Advanced Introduction to Statistics and Data Science",
    "section": "Announcements",
    "text": "Announcements\n\nWeek 6 modified office hours:\n\nMonday 10/14: 2-3pm, 4:00-5:00pmish\nFriday 10/18: 10:30am-12:00pm"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#recap",
    "href": "slides/slides-09-conditional-probability.html#recap",
    "title": "Conditional probability",
    "section": "Recap",
    "text": "Recap\n\nTwo events are disjoint/mutually exclusive if they do not have any overlapping outcomes\nAddition rule: \\(\\text{Pr}(A \\cup B) =\\)\nComplement rule: \\(\\text{Pr}(A^c) =\\)"
  },
  {
    "objectID": "slides/slides-09-conditional-probability.html#law-of-total-probability",
    "href": "slides/slides-09-conditional-probability.html#law-of-total-probability",
    "title": "Conditional probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nLet \\(A\\) be an event, then let \\(\\{B_{1},B_{2},\\ldots, B_{k}\\}\\) be a set of mutually exclusive events whose union comprises their entire sample space \\(S\\)\nThen Law of Total Probability (LoTP) says:\n\n\n\\[\n\\text{Pr}(A) = \\text{Pr}(A \\cap B_{1} ) + \\text{Pr}(A \\cap B_{2}) + \\ldots + \\text{Pr}(A \\cap B_{k})\n\\]\n\n\nBlob picture"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#uc-berkeley-admissions",
    "href": "slides/slides-10-simpsons.html#uc-berkeley-admissions",
    "title": "Simpson’s paradox",
    "section": "UC Berkeley admissions",
    "text": "UC Berkeley admissions\nObservational study on sex bias based on Fall 1973 admissions data to the graduate program at the University of California, Berkeley\n\n\n\n\nAdmit\nDeny\nTotal\n\n\n\n\nMen\n3738\n4704\n8442\n\n\nWomen\n1494\n2827\n4321\n\n\nTotal\n5232\n7531\n12763\n\n\n\n\n\nWhat is the probability of admission for a randomly selected applicant?\nWhat is the probability of admission among men? Among women?\nAre the probabilities you found marginal, joint, or conditional probabilities?\n\n\n\n\nSuppose we want to understand the relationship between gender and admission decision. What sort of visualization might be appropriate for representing this data?"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#section",
    "href": "slides/slides-10-simpsons.html#section",
    "title": "Simpson’s paradox",
    "section": "",
    "text": "Dept\nFemale: Admit\nMale: Admit\nFemale: Reject\nMale: Reject\n\n\n\n\nA\n89\n512\n19\n313\n\n\nB\n17\n353\n8\n207\n\n\nC\n202\n120\n391\n205\n\n\nD\n131\n138\n244\n279\n\n\nE\n94\n53\n299\n138\n\n\nF\n24\n22\n317\n351"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#frequency-tables",
    "href": "slides/slides-10-simpsons.html#frequency-tables",
    "title": "Simpson’s paradox",
    "section": "Frequency tables",
    "text": "Frequency tables\nNumber of applicants by department:\n\n\nFemale applicants:\n\n\n\n\n\nDept\nn\n\n\n\n\nA\n108\n\n\nB\n25\n\n\nC\n593\n\n\nD\n375\n\n\nE\n393\n\n\nF\n341\n\n\n\n\n\n\nMale applicants:\n\n\n\n\n\nDept\nn\n\n\n\n\nA\n825\n\n\nB\n560\n\n\nC\n325\n\n\nD\n417\n\n\nE\n191\n\n\nF\n373"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#more-detailed-frequency-tables",
    "href": "slides/slides-10-simpsons.html#more-detailed-frequency-tables",
    "title": "Simpson’s paradox",
    "section": "More-detailed frequency tables",
    "text": "More-detailed frequency tables\nNumber of applicants by department and admission status:\n\n\nFemale applicants:\n\n\n\n\n \n  \n    Dept \n    Decision \n    n \n  \n \n\n  \n    A \n    Admit \n    89 \n  \n  \n    A \n    Reject \n    19 \n  \n  \n    B \n    Admit \n    17 \n  \n  \n    B \n    Reject \n    8 \n  \n  \n    C \n    Admit \n    202 \n  \n  \n    C \n    Reject \n    391 \n  \n  \n    D \n    Admit \n    131 \n  \n  \n    D \n    Reject \n    244 \n  \n  \n    E \n    Admit \n    94 \n  \n  \n    E \n    Reject \n    299 \n  \n  \n    F \n    Admit \n    24 \n  \n  \n    F \n    Reject \n    317 \n  \n\n\n\n\n\n\nMale applicants:\n\n\n\n\n \n  \n    Dept \n    Decision \n    n \n  \n \n\n  \n    A \n    Admit \n    512 \n  \n  \n    A \n    Reject \n    313 \n  \n  \n    B \n    Admit \n    353 \n  \n  \n    B \n    Reject \n    207 \n  \n  \n    C \n    Admit \n    120 \n  \n  \n    C \n    Reject \n    205 \n  \n  \n    D \n    Admit \n    138 \n  \n  \n    D \n    Reject \n    279 \n  \n  \n    E \n    Admit \n    53 \n  \n  \n    E \n    Reject \n    138 \n  \n  \n    F \n    Admit \n    22 \n  \n  \n    F \n    Reject \n    351"
  },
  {
    "objectID": "coding_practice/coding-practice-10-simpsons.html",
    "href": "coding_practice/coding-practice-10-simpsons.html",
    "title": "Conditional probabilities coding practice",
    "section": "",
    "text": "Today’s data comes from a study of conducted in Whickham, England. In this study, the researchers recorded each participant’s age, smoking status at the start of the study, and their health outcome 20 years later.\nThe data is in the mosaicData package. You may have to install the package first! Then run the following code:\n\nlibrary(tidyverse)\nlibrary(mosaicData)\n\nWe will work with the Whickham data. You should open its Help file and take a view of the data before proceeding. Note that “factor” can be though of as a categorical variable. Make sure you understand the data before proceeding!\nDiscuss with your group: What would you expect the relationship between smoking status and health outcome to be?\n\nCreate an appropriate visualization depicting the relationship between smoking status and health outcome. Make sure you have informative labels and titles.\n\n\n\n\n\nUsing wrangling code, calculate the conditional probabilities of death of each smoking status. Your resulting table/data frame should only retain the variables for smoke status, outcome, and the conditional probabilities in a meaningful order. Also, please report only the probabilities for when outcome is Dead.\n\n\n\n\nWith your group, briefly describe the relationship and whether or not it is what you expected. You may want to discuss the visualization from the previous exercise as well.\n\nUsing case_when(), create a new variable for future use called age_cat that takes the values as follows:\n\n\n“18-44”: if someone is less than or equal to 44 years old\n“45-64”: if someone is between 45 and 64 years old, inclusive\n“65+”: if someone is older than 64\n\n\n\n\n\nRe-create your first visualization from Exercise 1, this time faceting by age_cat. Make sure you have informative labels and titles.\n\n\n\n\n\nElaborate on your table from Exercise 2 above by breaking it down by age category. Your resulting table/data frame should only retain the variables for smoke status, age category, outcome, and the conditional probabilities in a meaningful order. Once again, please report only the probabilities for when outcome is Dead.\n\n\n\n\nWith your group, compare the two visualizations and the two summary tables. What changed, and what might explain the change?\nAnswer:\nWhen finished, knit one more time and submit the HTML to Canvas!"
  },
  {
    "objectID": "slides/slides-10-simpsons.html#uc-berkeley-admissions-cont.",
    "href": "slides/slides-10-simpsons.html#uc-berkeley-admissions-cont.",
    "title": "Simpson’s paradox",
    "section": "UC Berkeley admissions (cont.)",
    "text": "UC Berkeley admissions (cont.)"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#where-we-are-going",
    "href": "slides/slides-11-bootstrap.html#where-we-are-going",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Where we are going",
    "text": "Where we are going\nWe are leaving the world of EDA and beginning to enter the world of inference and modeling!\n\nWant to answer questions about a population, but must rely on a sample\nCollect data from sample –> calculate statistics\nWhat can we say about the statistics?\nData are random! So how sure are we about our conclusions?\n\n\nStatistics starts here!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#inferential-questions",
    "href": "slides/slides-11-bootstrap.html#inferential-questions",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Inferential questions",
    "text": "Inferential questions\n\nI want to know the true average number of hours of sleep Middlebury students get a night. Based on a sample of students, what might be a “good estimate” of the true average?\nIs the true average number of of hours of Middlebury students get a night less than 7 hours?\n\nQuestions here are about population parameter (in this case, \\(\\mu\\))\nAll we have access to is the data \\(x_{1}, x_{2},\\ldots, x_{n}\\) from which we can calculate some statistics"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#activity",
    "href": "slides/slides-11-bootstrap.html#activity",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Activity",
    "text": "Activity\nWhile you’re coming into the room, please take:\n\n1 pink card\n1 white card\n\n\nOn the pink card, write down an estimate of the average number of hours of sleep you received this past week.\nOn white card, write a 1 if this number you wrote down on the pink card is greater than or equal to 7, and a 0 otherwise\nThen bring these to Prof. Tang"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#variability-of-statistic",
    "href": "slides/slides-11-bootstrap.html#variability-of-statistic",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Variability of statistic",
    "text": "Variability of statistic\n\nTwo datasets collected under identical procedures will differ. As a result, value of the point estimate we obtain are also different\n\nActivity cont.\n\nThus, there exists the notion of a sampling distribution of the statistic: how the statistic behaves under repeated random samples obtained via the same sampling procedure\n\nThe variability associated with the sampling distribution of the statistic is called the standard error\n\nNote: “error” \\(\\neq\\) bad\n\nThis is in contrast to the standard deviation, which describes variability in the individual data points and not the statistic\n\nPopulation distribution vs. sample distribution vs. sampling distribution"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#sampling-distribution",
    "href": "slides/slides-11-bootstrap.html#sampling-distribution",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Sampling distribution",
    "text": "Sampling distribution\n\nOf course, sampling distribution of the statistic depends on underlying distribution of the population\nSometimes, we assume that the population/data have a very specific behavior, and this allows us to exactly define/quantify the sampling distribution\n\nWe will see this in a couple of weeks\n\nIf we don’t want to make assumptions, what do we do?\n\nCould conduct a census! That way we can answer any questions we want about the population. But that’s impractical…\nHow to obtain more samples cheaply and quickly?"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#procedure",
    "href": "slides/slides-11-bootstrap.html#procedure",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Procedure",
    "text": "Procedure\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\vec{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\vec{x}\\). Call this set of resampled data \\(\\vec{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\vec{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#activity-1",
    "href": "slides/slides-11-bootstrap.html#activity-1",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Activity",
    "text": "Activity\n\nTarget population:\nSampling method:\nPopulation parameter:\nStatistics we can calculate:"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#why-resample-with-replacement",
    "href": "slides/slides-11-bootstrap.html#why-resample-with-replacement",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Why resample with replacement?",
    "text": "Why resample with replacement?\n\nWe want to understand the sampling error of the sampling distribution!\n\nWhat would the bootstrap samples \\(\\vec{x}^*_b\\) look like if we sampled without replacement?\n\n\nSampling without replacement -> zero variation in the resampled statistics\n\nResampling with replacement will give us “new” datasets that are similar to original sample distribution but not exactly the same!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#remarks",
    "href": "slides/slides-11-bootstrap.html#remarks",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Remarks",
    "text": "Remarks\n\n\nRelies on having a representative original sample!\n\n\nResampling from initial sample should be roughly equivalent to sampling directly from the population\n\nRequires computational tools!\n\nWe need \\(B\\) to be large enough to accurately capture variability. \\(B=5000\\) or \\(B=10000\\) sufficient in this class\nMore complex problems will require larger \\(B\\)\n\nBootstrapping can fail!\nBootstrapping is not a solution to small sample sizes!!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#point-estimate",
    "href": "slides/slides-11-bootstrap.html#point-estimate",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Point estimate",
    "text": "Point estimate\n\n\\(\\bar{x}\\) is often times a sensible estimate for \\(\\mu\\)\n\\(\\bar{x}\\) is an example of a point estimate: a single number used to estimate a true but unknown population parameter\n\ni.e. a point estimate is a statistic with a specific purpose\nOther examples include \\(s\\) for \\(\\sigma\\), observed proportion \\(\\hat{p}\\) for true proportion \\(p\\),\n\n\nWhat are desirable characteristics of a “good” point estimate?\n\n\nDo we believe that \\(\\bar{x} = \\mu\\) or \\(\\hat{p} = p\\)?"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#demonstration",
    "href": "slides/slides-11-bootstrap.html#demonstration",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Demonstration",
    "text": "Demonstration\n\nActivity cont.\nLive code demonstration"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#housekeeping",
    "href": "slides/slides-12-bootstrap_ci.html#housekeeping",
    "title": "Bootstrap Confidence Intervals",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours 3-4pm\nMidterm tomorrows! Bring a calculator."
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-recap",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap recap",
    "text": "Bootstrap recap\nTaking new samples each time is costly! Bootstrap distribution is an approximation of the sampling distribution of the statistic!\nProcedure:\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\vec{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\vec{x}\\). Call this set of resampled data \\(\\vec{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\vec{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#confidence-intervals",
    "href": "slides/slides-12-bootstrap_ci.html#confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nAnalogy: would you rather go fishing with a single pole or a large net?\n\nA range of plausible values gives us a better chance at capturing the parameter\n\nA confidence interval provides such a range of values (more rigorous definition coming soon)\n\n“Interval” = we specify a lower bound and an upper bound\nConfidence intervals are not unique! Depending on the method you use, you might get different intervals"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-confidence-intervals",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap confidence intervals",
    "text": "Bootstrap confidence intervals\n\n\n\nLet’s continue with the data collected from our activity. We have the following bootstrap distribution of sample means, obtained from \\(B=\\) 5000 iterations:"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap distribution",
    "text": "Bootstrap distribution\n\n\n\nLet’s continue with the data collected from our activity. We have the following bootstrap distribution of sample proportions, obtained from \\(B=\\) 5000 iterations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhere is the bootstrap distribution centered?"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-percentile-interval",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-percentile-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap percentile interval",
    "text": "Bootstrap percentile interval\n\nThe \\(\\gamma \\times 100\\)% bootstrap percentile interval is obtained by finding the bounds of the middle \\(\\gamma \\times 100\\)% of the bootstrap distribution\n\n\ne.g. If I want a 90% bootstrap percentile interval, where would the bounds be?\n\n\nCalled “percentile interval” because the bounds are the \\((1-\\gamma)/2\\) and \\((1+\\gamma)/2\\) percentiles of the bootstrap distribution\n\ne.g. if \\(\\gamma = 0.80\\), then the bounds would be \\((1-0.80)/2 = 0.10\\) and \\((1+0.80)/2 = 0.90\\) percentiles\n\nFor our purposes, “bootstrap confidence interval” will be equivalent to “bootstrap percentile interval”"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval",
    "href": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval",
    "text": "Interpreting a confidence interval\n\nOur 90% confidence interval is: (0.3, 0.8) or (0.5, 0.9). Does this mean there is a 90% chance/probability that the true proportion lies in the interval?\n\n\nAnswer: NO\n\n\nRemember: bootstrap distribution is based on our original sample\n\nIf we started with a different original sample \\(\\vec{x}\\), then our estimated 90% confidence interval would also be different\n\n\nWhat a confidence interval (CI) represents: if we take many independent repeated samples from this population using the same method and calculate a \\(\\gamma \\times 100\\) % CI for the parameter in the exact same way, then in theory, \\(\\gamma \\times 100\\) % of these intervals should capture/contain the parameter\n\n\n\\(\\gamma\\) represents the long-run proportion of CIs that theoretically contain the true parameter\nHowever, we never know if any particular interval(s) actually do!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval-cont.",
    "href": "slides/slides-12-bootstrap_ci.html#interpreting-a-confidence-interval-cont.",
    "title": "Bootstrap Confidence Intervals",
    "section": "Interpreting a confidence interval (cont.)",
    "text": "Interpreting a confidence interval (cont.)\n\nCorrect interpretation (generic): We are \\(\\gamma \\times 100\\) % confident that the population parameter is between the lower bound and upper bound.\n\n\nInterpret our bootstrap CI in context\n\nAgain: why is this interpretation incorrect? “There is a 90% chance/probability that the true parameter value lies in the interval.”"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#obtaining-bootstrap-confidence-interval",
    "href": "slides/slides-12-bootstrap_ci.html#obtaining-bootstrap-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "Obtaining bootstrap confidence interval",
    "text": "Obtaining bootstrap confidence interval\n\n\n\n\n\n\nSection A 90% confidence interval for \\(p_{A}\\): (0.3, 0.8)\nSection B 90% confidence interval for \\(p_{B}\\): (0.5, 0.9)"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html",
    "href": "slides/slides-11-bootstrap.html",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "",
    "text": "Midterm review problems released\nWednesday office hours 3-4pm\nMidterm this Thursday in class! Bring a calculator.\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 4526 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Decision, Gender, Dept\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nWe are leaving the world of EDA and beginning to enter the world of inference and modeling!\n\nWant to answer questions about a population, but must rely on a sample\nCollect data from sample –> calculate statistics\nWhat can we say about the statistics?\nData are random! So how sure are we about our conclusions?\n\n\nStatistics starts here!\n\n\n\n\nStatistical inference is the process of using sample data to make conclusions about the underlying population the sample came from\n\nEstimation: using the sample to estimate a plausible values for the unknown parameter\nTesting: evaluating whether our observed sample provides evidence for or against some claim about the population\n\n\n\n\n\nI want to know the true average number of hours of sleep Middlebury students get a night. Based on a sample of students, what might be a “good estimate” of the true average?\nIs the true average number of of hours of Middlebury students get a night less than 7 hours?\n\nQuestions here are about population parameter (in this case, \\(\\mu\\))\nAll we have access to is the data \\(x_{1}, x_{2},\\ldots, x_{n}\\) from which we can calculate some statistics\n\n\n\n\n\n\nTarget population:\nSampling method:\nPopulation parameter:\nStatistics we can calculate:\n\n\n\n\n\n\\(\\bar{x}\\) is often times a sensible estimate for \\(\\mu\\)\n\\(\\bar{x}\\) is an example of a point estimate: a single number used to estimate a true but unknown population parameter\n\ni.e. a point estimate is a statistic with a specific purpose\nOther examples include \\(s\\) for \\(\\sigma\\), observed proportion \\(\\hat{p}\\) for true proportion \\(p\\),\n\n\nWhat are desirable characteristics of a “good” point estimate?\n\n\nDo we believe that \\(\\bar{x} = \\mu\\)?\n\n\n\n\n\n\nTwo datasets collected under identical procedures will differ. As a result, value of the point estimate we obtain are also different\n\nActivity cont.\n\nThus, there exists the notion of a sampling distribution of the statistic: how the statistic behaves under repeated random samples obtained via the same sampling procedure\n\nThe variability associated with the sampling distribution of the statistic is called the standard error\n\nNote: “error” \\(\\neq\\) bad\n\nThis is in contrast to the standard deviation, which describes variability in the individual data points and not the statistic\n\nPopulation distribution vs. sample distribution vs. sampling distribution\n\n\n\n\n\nOf course, sampling distribution of the statistic depends on underlying distribution of the population\nSometimes, we assume that the population/data have a very specific behavior, and this allows us to exactly define/quantify the sampling distribution\n\nWe will see this in a couple of weeks\n\nIf we don’t want to make assumptions, what do we do?\n\nCould conduct a census! That way we can answer any questions we want about the population. But that’s impractical…\nHow to obtain more samples cheaply and quickly?"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html",
    "href": "slides/slides-12-bootstrap_ci.html",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "Office hours 3-4pm\nMidterm tomorrows! Bring a calculator."
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#remarks",
    "href": "slides/slides-12-bootstrap_ci.html#remarks",
    "title": "Bootstrap Confidence Intervals",
    "section": "Remarks",
    "text": "Remarks\n\n\nWhat is a virtue of a “good” confidence interval?\n\n\nHow do you expect the interval to change as the original sample size \\(n\\) changes?\nHow do you expect the interval to change as level of confidence \\(\\gamma\\) changes?\n\nOnce again, relies on a representative original sample!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#your-turn",
    "href": "slides/slides-12-bootstrap_ci.html#your-turn",
    "title": "Bootstrap Confidence Intervals",
    "section": "Your turn!",
    "text": "Your turn!"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#inference",
    "href": "slides/slides-11-bootstrap.html#inference",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Inference",
    "text": "Inference\nStatistical inference is the process of using sample data to make conclusions about the underlying population the sample came from\n\nEstimation: using the sample to estimate a plausible values for the unknown parameter\nTesting: evaluating whether our observed sample provides evidence for or against some claim about the population"
  },
  {
    "objectID": "slides/slides-11-bootstrap.html#estimation-questions",
    "href": "slides/slides-11-bootstrap.html#estimation-questions",
    "title": "Variability of statistic + Intro to Bootstrap",
    "section": "Estimation questions",
    "text": "Estimation questions\n\nI want to know the true average number of hours of sleep Middlebury students get a night.\n\nBased on a sample of students, what might be a “good estimate” of the true average?\n\nWhat proportion of Middlebury students get a night less than 7 hours?\n\nBased on a sample of students, what might be a “good estimate” of the true proportion?\n\nQuestions here are about population parameter\n\nAll we have access to is the data \\(x_{1}, x_{2},\\ldots, x_{n}\\) from which we can calculate some statistics"
  },
  {
    "objectID": "live_code/bootstrap_dist.html",
    "href": "live_code/bootstrap_dist.html",
    "title": "Bootstrap distribution",
    "section": "",
    "text": "library(tidyverse)\n# our original sample\nx_orig <- c(1, 1, 1, 0, 1)\n\n# sample size stored as variable for reproducibility\nn <- length(x_orig)\n\n# number of bootstrap samples to take\nB <- 1000\n\n# vector to store bootstrap statistics. Starts off as vector full of NAs of length B\nbootstrap_props <- rep(NA, B)\n\nfor(b in 1:B){\n  # resample\n  x_boot <- sample(x = x_orig, size = n, replace = TRUE)\n  \n  # calculate and store bootstrap statistic\n  bootstrap_props[b] <- mean(x_boot)\n}\n\n# visualize\ndata.frame(props = bootstrap_props) |>\n  ggplot(aes(x = props))+\n  geom_histogram(binwidth =  0.2 ) +\n  labs(title = \"Bootstrap distribution of sample proportions\")"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#why-bootstrap",
    "href": "slides/slides-12-bootstrap_ci.html#why-bootstrap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Why bootstrap?",
    "text": "Why bootstrap?\n\nSample distribution describes how statistic behaves under repeated sampling from population\nLet’s continue with the data collected from our activity.\n\nI repeatedly take SRS of \\(n=5\\) values from the population and calculate \\(\\hat{p}\\). Sampling distribution of \\(\\hat{p}\\) is as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaking new samples each time is costly! Bootstrap distribution is an approximation of the sampling distribution of the statistic"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-procedure-recap",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-procedure-recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap procedure recap",
    "text": "Bootstrap procedure recap\n\nAssume we have a sample \\(x_{1}, x_{2}, \\ldots, x_{n}\\) from the population. Call this sample \\(\\vec{x}\\). Note the sample size is \\(n\\)\nChoose a large number \\(B\\). For \\(b\\) in \\(1,2, \\ldots, B\\):\n\nResample: take a sample of size \\(n\\) with replacement from \\(\\vec{x}\\). Call this set of resampled data \\(\\vec{x}^*_{b}\\)\nCalculate: calculate and record the statistic of interest from \\(\\vec{x}^{*}_{b}\\)\n\n\n\nAt the end of this procedure, we will have a distribution of resample or bootstrap statistics"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution-from-activity",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-distribution-from-activity",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap distribution from activity",
    "text": "Bootstrap distribution from activity\n\n\n\nWe have the following bootstrap distribution of sample proportions, obtained from \\(B=\\) 5000 iterations:"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#bootstrap-dist.-continued",
    "href": "slides/slides-12-bootstrap_ci.html#bootstrap-dist.-continued",
    "title": "Bootstrap Confidence Intervals",
    "section": "Bootstrap dist. continued",
    "text": "Bootstrap dist. continued\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice where the bootstrap distribution is centered\nWhat do we do with the bootstrap distribution?"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#answering-estimation-question",
    "href": "slides/slides-12-bootstrap_ci.html#answering-estimation-question",
    "title": "Bootstrap Confidence Intervals",
    "section": "Answering estimation question",
    "text": "Answering estimation question\nRecall our research question: What proportion of STAT 201A/STAT 201B students get at least 7 hours of sleep a night?\n\nCould respond using our single point estimate: \\(\\hat{p}_{A} = 0.6\\) or \\(\\hat{p}_{B} = 0.7\\)\nBut due to variability, we recognize that the point estimate will rarely (if ever) equal population parameter\nRather than report a single number, why not report a range of values?\n\n\nThis is possible only if we have a distribution to work with!!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#recap",
    "href": "slides/slides-12-bootstrap_ci.html#recap",
    "title": "Bootstrap Confidence Intervals",
    "section": "Recap",
    "text": "Recap\n\nSampling distribution describes how statistic behaves under repeated sampling from population\nLet’s return to the data collected from our activity.\n\nI will repeatedly take SRS of \\(n=10\\) values from the population (call this \\(\\vec{x}\\)) and calculate \\(\\hat{p}\\). Sampling distribution of \\(\\hat{p}\\) is as follows:"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals",
    "href": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals",
    "text": "Comparing confidence intervals\nComparing changes in \\(\\gamma \\times 100\\) % CI for sample sizes: \\(n = 5\\), \\(n = 10\\), and \\(n = 17\\):\n\n\n`summarise()` has grouped output by 'n_lab'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n\nWhat do you notice?\n\n\n\n\n\nSection A\n\n\nn\ninterval\n\n\n\n\nn = 5\n(0.2, 1)\n\n\nn = 10\n(0.3, 0.8)\n\n\nn = 17\n(0.41, 0.76)\n\n\n\n\n\n\nSection B\n\n\nn\ninterval\n\n\n\n\nn = 5\n(0.4, 1)\n\n\nn = 10\n(0.5, 0.9)\n\n\nn = 17\n(0.53, 0.88)"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-1",
    "href": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-1",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals",
    "text": "Comparing confidence intervals\nWhat do you think happens as we increase \\(\\gamma\\) from \\(0\\) to \\(1\\)?\n\nYour turn to try!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-cont.",
    "href": "slides/slides-12-bootstrap_ci.html#comparing-confidence-intervals-cont.",
    "title": "Bootstrap Confidence Intervals",
    "section": "Comparing confidence intervals (cont.)",
    "text": "Comparing confidence intervals (cont.)\nYou will investigate what happens as we move \\(\\gamma\\) between \\(0\\) to \\(1\\)!"
  },
  {
    "objectID": "slides/slides-12-bootstrap_ci.html#live-code-your-turn",
    "href": "slides/slides-12-bootstrap_ci.html#live-code-your-turn",
    "title": "Bootstrap Confidence Intervals",
    "section": "Live code + your turn!",
    "text": "Live code + your turn!\n\nLive code:\n\nin-line code\n\nYou will investigate what happens as we move \\(\\gamma\\) between \\(0\\) to \\(1\\)!"
  },
  {
    "objectID": "coding_practice/coding-practice-12-bootstrap.html",
    "href": "coding_practice/coding-practice-12-bootstrap.html",
    "title": "Bootstrap confidence intervals",
    "section": "",
    "text": "We will work with the average hours of sleep each class reported. In the following code chunk, please delete the line of code that does not correspond to your section.\n\nlibrary(tidyverse)\nlibrary(readr)\n\n# SECTION A DATA\nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/sectionA_week4_sleep.csv\"\n\n# SECTION B DATA \nurl_file <- \"https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/sectionB_week4_sleep.csv\"\n\n\nsleep <- read_csv(url_file)\n\nWe will intialize a pseudo-random-number-generator using the set.seed() function. You can choose any whole number to input as the parameter to this function. If I have the same seed and code and you, then I can reproduce the same random results.\n\nset.seed(201)\n\n\nCreate a variable that represents and stores the target sample size: 10. Then, take a random sample of size 10 of sleep hours from our population. Store your sample into a variable called x.\n\n\n# create a variable for sample size\n\n# obtain and store our sample\n\n\nWe will take 5000 bootstrap iterations. Store this value as a variable for reproducibility.\n\n\n# store number of bootstrap iterations\n\n\nObtain a bootstrap distribution of sample means using your original sample. Remember to store the bootstrap statistics somewhere! Please use a meaningful variable name. It may be useful to look at and modify the live code from previous class (on website)\n\n\n\n\n\nThe quantile() function obtains percentiles for us. It requires two arguments: a numeric vector and a percentile level (between 0 and 1). For example, quantile(x, 0.5) finds the 50-th percentile of the vector x.\n\nUsing this function, obtain the bounds for a 80%, 90%, and 99% bootstrap confidence interval, respectively. Store these bounds as variables.\n\n# 80%\n\n# 90%\n\n# 99%\n\n\nReport the three confidence intervals here in the format of (lower, upper) using in-line code.\n\n80% CI:\n90%: CI:\n99% CI:\n\nHow do the confidence interval widths change as the level of confidence increases?\n\nAnswer:\n\nInterpret one of your confidence intervals in context. Use in-line code in your answer.\n\nAnswer:"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#housekeeping",
    "href": "slides/slides-13-intro-testing.html#housekeeping",
    "title": "Introduction to Hypothesis Testing",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours change this week\nMid-semester feedback survey results"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#testing",
    "href": "slides/slides-13-intro-testing.html#testing",
    "title": "Introduction to Hypothesis Testing",
    "section": "Testing",
    "text": "Testing\nWe are now entering into second branch of inference-related tasks: testing.\n\nWe have some “claim”/question about the target population, and we use sampled data to provide evidence for or against the claim/question.\nEspecially important in experiments where we want to learn the effect of some new drug\nWe will use the hypothesis testing framework to formalize the process of making decisions about research claims.\n\nBecause claim is about target population, we will almost always formulate claims in terms of population parameters\nThen we use sample statistics to provide the evidence for/against"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#running-example-sex-discrimination-study",
    "href": "slides/slides-13-intro-testing.html#running-example-sex-discrimination-study",
    "title": "Introduction to Hypothesis Testing",
    "section": "Running example: sex discrimination study",
    "text": "Running example: sex discrimination study\n\nNote: this study considered sex as binary “male” or “female”, and did not take into consideration gender identities\nParticipants in the study were 48 bank supervisors who identified as male and were attending a management institute at UNC in 1972\n\nEach supervisor was asked to assume the role of personnel director of a bank\nThey were each given a file to judge whether the person in the file should be promoted\nThe files were identical, except half of them indicated that the candidate was male, and the other half were indicated as female\nFiles were randomly assigned to bank managers\n\nExperiment or observational study?\n\n\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#data",
    "href": "slides/slides-13-intro-testing.html#data",
    "title": "Introduction to Hypothesis Testing",
    "section": "Data",
    "text": "Data\nFor each of the 48 supervisors, the following were recorded:\n\nThe sex of the candidate in the file (male/female)\nThe decision (promote/not promote)\n\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nAre we prepared to answer our research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\nWhat evidence do we have?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#evidence",
    "href": "slides/slides-13-intro-testing.html#evidence",
    "title": "Introduction to Hypothesis Testing",
    "section": "Evidence",
    "text": "Evidence\nConditional probability of getting promoted by sex:\n\n\n# A tibble: 2 × 3\n# Groups:   sex [2]\n  sex    decision cond_prob\n  <chr>  <chr>        <dbl>\n1 female promote      0.583\n2 male   promote      0.875\n\n\n\nThe key question: does the difference we found provide convincing evidence that individuals who identify as female are unfairly discriminated against?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-1-define-hypotheses",
    "href": "slides/slides-13-intro-testing.html#step-1-define-hypotheses",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 1: Define hypotheses",
    "text": "Step 1: Define hypotheses\nA hypothesis test is a statistical technique used to evaluate competing claims using data\n\nWe define hypotheses to translate our research question/claim into statistical notation\nWe always define two hypotheses in context: a null hypothesis and an alternative hypothesis\nNull hypothesis \\(H_{0}\\): the hypothesis that represents “business as usual”/status quo/nothing unusual or noteworthy\nAlternative hypothesis \\(H_{A}\\): claim the researchers want to demonstrate\n\n\nIt will not always be obvious what \\(H_{0}\\) should be, but you will develop intuition for this over time!"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#defining-hypotheses-in-context",
    "href": "slides/slides-13-intro-testing.html#defining-hypotheses-in-context",
    "title": "Introduction to Hypothesis Testing",
    "section": "Defining hypotheses in context",
    "text": "Defining hypotheses in context\nResearch question: do the majority of STAT 201A/STAT 201B students get at least 7 hours of sleep?\n\nDefine \\(p\\) as the true proportion of STAT 201A/STAT 201B who get at least 7 hours of sleep on average\n\n\n\n\\(H_{0}\\): \\(p \\leq 0.5\\)\n\\(H_{A}\\): \\(p > 0.5\\)"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-2-collect-data-and-calculate-sample-statistics",
    "href": "slides/slides-13-intro-testing.html#step-2-collect-data-and-calculate-sample-statistics",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 2: Collect data and calculate sample statistics",
    "text": "Step 2: Collect data and calculate sample statistics\nSuppose I collect a sample of \\(n= 10\\) students from each class:\n\n\n\n\n\nIn STAT 201A sample: 6 students received at least 7 hours of sleep, and 4 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.6\n\n\nIn STAT 201B sample: 7 students received at least 7 hours of sleep, and 3 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.7\n\n\n\n\n\nAre we prepared to answer our research question based on this evidence?\n\nDue to variability in data and \\(\\hat{p}\\) we should ask: do the data provide convincing evidence that the majority of students get at least 7 hours of sleep?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#running-example-2-sex-discrimination-study",
    "href": "slides/slides-13-intro-testing.html#running-example-2-sex-discrimination-study",
    "title": "Introduction to Hypothesis Testing",
    "section": "Running example 2: sex discrimination study",
    "text": "Running example 2: sex discrimination study\n\nNote: this study considered sex as binary “male” or “female”, and did not take into consideration gender identities\nParticipants in the study were 48 bank supervisors who identified as male and were attending a management institute at UNC in 1972\n\nEach supervisor was asked to assume the role of personnel director of a bank\nThey were each given a file to judge whether the person in the file should be promoted\nThe files were identical, except half of them indicated that the candidate was male, and the other half were indicated as female\nFiles were randomly assigned to bank managers\n\nExperiment or observational study?\n\n\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#defining-hypotheses-here",
    "href": "slides/slides-13-intro-testing.html#defining-hypotheses-here",
    "title": "Introduction to Hypothesis Testing",
    "section": "Defining hypotheses here",
    "text": "Defining hypotheses here\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-3-determine-if-we-have-convincing-evidence",
    "href": "slides/slides-13-intro-testing.html#step-3-determine-if-we-have-convincing-evidence",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 3: Determine if we have “convincing evidence”",
    "text": "Step 3: Determine if we have “convincing evidence”\n“Convincing evidence” for us means that it would be highly unlikely to observe the data we did (or data even more extreme) if \\(H_{0}\\) were true!\n\nWe will calculate a p-value: the probability of observing data as or more extreme than we did assuming \\(H_{0}\\) true\n\nNote: p is not the same as true proportion \\(p\\)!\n\nHighly unlikely is vague and needs to defined by the researcher, ideally before seeing data.\n\nIf we want to answer the research question with a binary yes/no, we need some threshold to compare the p-value to. This is called a significance level \\(\\alpha\\)\nCommon choices are \\(\\alpha = 0.05\\), \\(\\alpha = 0.01\\) (more on this later)!\n\nFor our example, we will choose \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#simulating-under-h_0",
    "href": "slides/slides-13-intro-testing.html#simulating-under-h_0",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\)",
    "text": "Simulating under \\(H_{0}\\)\n-"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.",
    "href": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\) (step 3 cont.)",
    "text": "Simulating under \\(H_{0}\\) (step 3 cont.)\n\nWe have to simulate our data under the assumption that \\(H_{0}\\) is true (recall \\(H_0\\): \\(p \\leq 0.5\\))\nImagine a big bag with pink and purple slips of paper\n\nPink = people who got at least 7 hours of sleep\nPurple = people who got less than 7 hours\n\nWhat proportion of the slips in the bowl should be pink vs purple?\n\nTo simulate under \\(H_{0}\\), no more than 50% of the slip should be pink\n\nWe want convincing evidence even in the most “borderline” case, so we will choose 50% of the slips to be pink."
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.-1",
    "href": "slides/slides-13-intro-testing.html#simulating-under-h_0-step-3-cont.-1",
    "title": "Introduction to Hypothesis Testing",
    "section": "Simulating under \\(H_{0}\\) (step 3 cont.)",
    "text": "Simulating under \\(H_{0}\\) (step 3 cont.)\n\nActivity: we now replicate our original sample, this time sampling from this bag of paper slips\n\nWe repeatedly take samples from the null distribution, using original sample size \\(n =\\) 10\nFor each sample, calculate the simulated proportion of pink slips, \\(\\hat{p}_{sim}\\)\n\nLive code?\n\n\n\nset.seed(2) # reproducibility\nB <- 5000 # number of simulations to do to gather enough evidence\nn <- 10 # size of our original sample\np_null_vec <- rep(NA, B) # vector to store the simulated proportions\nfor(b in 1:B){\n  # sample() takes a random sample\n  null_samp <- sample(x = c(\"pink\", \"purple\"), # pink and purple slips\n                      size = n, # sample of size n\n                      replace = T, # tell R that my bowl has infinitely many marbles \n                      prob = c(0.5, 0.5)) # 50% of slips are pink and 50% are purple\n  \n  # calculate and store the proportion of pink slips in this simulation\n  p_null_vec[b] <- sum(null_samp == \"pink\")/n\n}"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#null-distribution-of-statistic",
    "href": "slides/slides-13-intro-testing.html#null-distribution-of-statistic",
    "title": "Introduction to Hypothesis Testing",
    "section": "Null distribution of statistic",
    "text": "Null distribution of statistic\nWe can visualize the distribution of \\(\\hat{p}_{sim}\\) assuming \\(H_{0}\\) true:\n\n\nThis is called the null distribution of the sample statistic, which is the distribution of the statistic assuming \\(H_{0}\\) is true\n\nWhere is the null distribution of \\(\\hat{p}\\) centered? Why does that “make sense”?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#obtain-p-value-step-3-cont.",
    "href": "slides/slides-13-intro-testing.html#obtain-p-value-step-3-cont.",
    "title": "Introduction to Hypothesis Testing",
    "section": "Obtain p-value (step 3 cont.)",
    "text": "Obtain p-value (step 3 cont.)\nWe can directly obtain (technically estimate) the p-value using our null distribution and our observed \\(\\hat{p}\\)!\n\n\n\n\n\n\n\n\n\nOut of 5000 replications, we saw 1946 instances of \\(\\hat{p}_{sim} \\geq \\hat{p}\\)\np-value is \\(\\frac{ 1946}{5000} \\approx\\) 0.39\n\n\n\n\n\n\n\n\nOut of 5000 replications, we saw 853 instances of \\(\\hat{p}_{sim} \\geq \\hat{p}\\)\np-value is \\(\\frac{ 853}{5000} \\approx\\) 0.17"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#comparing-null-to-observed",
    "href": "slides/slides-13-intro-testing.html#comparing-null-to-observed",
    "title": "Introduction to Hypothesis Testing",
    "section": "Comparing null to observed",
    "text": "Comparing null to observed\nLet’s return to our original goal of Step 3! We need to find the p-value: the probability of observing data as or more extreme as ours, assuming \\(H_{0}\\) were true.\n\nOur observed data were \\(\\hat{p} =\\) 0.6 (STAT 201A) or \\(\\hat{p} =\\) 0.7 (STAT 201B)\n\\(H_{0}\\): \\(p \\leq 0.5\\) and \\(H_{A}\\): \\(p > 0.5\\)\n\nWhat does “as or more extreme” mean in this context?\nHow can we use the null distribution to obtain this probability?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#how-to-obtain-p-value",
    "href": "slides/slides-13-intro-testing.html#how-to-obtain-p-value",
    "title": "Introduction to Hypothesis Testing",
    "section": "How to obtain p-value?",
    "text": "How to obtain p-value?\n\nHow to obtain this probability? It depends!\n\nOption 1: if we have assumptions about how our data behave, we can obtain this probability using theory/math (next week)\nOption 2: if we don’t want to make assumptions, why not apply the bootstrap technique and simulate?\n\nWe will call this option “simulating under \\(H_{0}\\)”\n\n\n\nThis is the step that requires the most “work”, and what exactly you do will depend on the the type of data and the research question/claim you have\n\nRemark: hypothesis tests, like confidence intervals, are not unique!"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-4-interpret-p-value-and-make-decision",
    "href": "slides/slides-13-intro-testing.html#step-4-interpret-p-value-and-make-decision",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 4: Interpret p-value and make decision",
    "text": "Step 4: Interpret p-value and make decision\n\nInterpret the p-value in context\n\n\nAssuming \\(H_{0}\\) true, the probability of observing a sample proportion as or more extreme as ours (0.6 or 0.7) is 0.39 or 0.17\n\n\nMake a decision about research claim/question by comparing p-value to significance level \\(\\alpha\\)\n\nIf p-value \\(< \\alpha\\), we reject \\(H_{0}\\) (it was highly unlikely to observe our data given our selected threshold)\nIf p-value \\(\\geq \\alpha\\), we fail to reject \\(H_{0}\\) (we did not have enough evidence against the null)\n\n\nNote: we never “accept \\(H_{A}\\)”!\n\n\n\nSince our p value is greater than \\(\\alpha = 0.05\\), we fail to reject \\(H_{0}\\). The data do not provide sufficient evidence to suggest that the majority of STAT 201A/STAT 201B students get less than 7 hours of sleep."
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#summary",
    "href": "slides/slides-13-intro-testing.html#summary",
    "title": "Introduction to Hypothesis Testing",
    "section": "Summary",
    "text": "Summary\nFour steps for hypothesis test:\n\nDefine null and alternative hypotheses \\(H_{0}\\) and \\(H_{A}\\) in context\nCollect data and set significance level \\(\\alpha\\)\nObtain p-value\n\nWe did this using by simulating under the null distribution\n\nInterpret p-value and make a decision in context"
  },
  {
    "objectID": "slides/slides-14-randomization.html#housekeeping",
    "href": "slides/slides-14-randomization.html#housekeeping",
    "title": "Hypothesis Testing with Randomization",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nOffice hours change this week\nMid-semester feedback survey results"
  },
  {
    "objectID": "slides/slides-14-randomization.html#recap",
    "href": "slides/slides-14-randomization.html#recap",
    "title": "Hypothesis Testing with Randomization",
    "section": "Recap",
    "text": "Recap\nFour steps for hypothesis test:\n\nDefine null and alternative hypotheses \\(H_{0}\\) and \\(H_{A}\\) in context\nCollect data and set significance level \\(\\alpha\\)\nObtain p-value by modeling randomness that would occur if the \\(H_{0}\\) were true\n\nWe did this using by simulating under the null distribution\n\nInterpret p-value and make a decision in context"
  },
  {
    "objectID": "slides/slides-14-randomization.html#running-example-sex-discrimination-study",
    "href": "slides/slides-14-randomization.html#running-example-sex-discrimination-study",
    "title": "Hypothesis Testing with Randomization",
    "section": "Running example: sex discrimination study",
    "text": "Running example: sex discrimination study\n\nNote: this study considered sex as binary “male” or “female”, and did not take into consideration gender identities\nParticipants in the study were 48 bank supervisors who identified as male and were attending a management institute at UNC in 1972\n\nEach supervisor was asked to assume the role of personnel director of a bank\nThey were each given a file to judge whether the person in the file should be promoted\nThe files were identical, except half of them indicated that the candidate was male, and the other half were indicated as female\nFiles were randomly assigned to bank managers\n\nExperiment or observational study?\n\n\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#defining-hypotheses",
    "href": "slides/slides-14-randomization.html#defining-hypotheses",
    "title": "Hypothesis Testing with Randomization",
    "section": "Defining hypotheses",
    "text": "Defining hypotheses\n\nResearch question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\n\nWhat is/are the variables(s) here? What types of variables are they?\n\nWe need to construct hypotheses where \\(H_{0}\\) is “status quo” and \\(H_{A}\\) is the claim researchers have\n\\(H_{0}\\): the variables sex and decision are independent.\n\ni.e. any observed difference in promotion rates is due to variability\n\n\\(H_{A}\\): the variables sex and decision are not independent, and equally-qualified female personnel are less likely to be promoted than male personnel"
  },
  {
    "objectID": "slides/slides-14-randomization.html#data",
    "href": "slides/slides-14-randomization.html#data",
    "title": "Hypothesis Testing with Randomization",
    "section": "Data",
    "text": "Data\nFor each of the 48 supervisors, the following were recorded:\n\nThe sex of the candidate in the file (male/female)\nThe decision (promote/not promote)\n\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nAre we prepared to answer our research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\nWhat evidence do we have?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#data-cont.",
    "href": "slides/slides-14-randomization.html#data-cont.",
    "title": "Hypothesis Testing with Randomization",
    "section": "Data (cont.)",
    "text": "Data (cont.)\nConditional probability of getting promoted by sex:\n\ndiscrimination |>\n  count(sex, decision) |>\n  group_by(sex) |>\n  mutate(cond_prob = n/sum(n)) |>\n  filter(decision == \"promote\") |>\n  select(-n)\n\n\n\n# A tibble: 2 × 3\n# Groups:   sex [2]\n  sex    decision cond_prob\n  <chr>  <chr>        <dbl>\n1 female promote      0.583\n2 male   promote      0.875\n\n\n\nIs the observed difference -0.2916667 convincing evidence? We need to examine variability in the data, assuming \\(H_{0}\\) true.\nLet’s set \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#comprehension-questions",
    "href": "slides/slides-13-intro-testing.html#comprehension-questions",
    "title": "Introduction to Hypothesis Testing",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nWhat are the similarities/differences between the bootstrap distribution of a sample statistic and the simulated null distribution?\nDo you understand what a p-value represents, and how we obtain it from the null distribution?\nWhat role does \\(\\alpha\\) play? Why is it important to set \\(\\alpha\\) early on?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#step-2-collect-and-summarize-data",
    "href": "slides/slides-13-intro-testing.html#step-2-collect-and-summarize-data",
    "title": "Introduction to Hypothesis Testing",
    "section": "Step 2: Collect and summarize data",
    "text": "Step 2: Collect and summarize data\nSuppose I collect a sample of \\(n= 10\\) students from each class:\n\n\n\n\n\nIn STAT 201A sample: 6 students received at least 7 hours of sleep, and 4 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.6\n\n\nIn STAT 201B sample: 7 students received at least 7 hours of sleep, and 3 received less than 7 hours\n\nSample statistic: \\(\\hat{p}\\): 0.7\n\n\n\n\n\nAre we prepared to answer our research question based on this evidence?\n\nDue to variability in data and \\(\\hat{p}\\) we should ask: do the data provide convincing evidence that the majority of students get at least 7 hours of sleep?"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#summary-of-testing-framework",
    "href": "slides/slides-13-intro-testing.html#summary-of-testing-framework",
    "title": "Introduction to Hypothesis Testing",
    "section": "Summary of testing framework",
    "text": "Summary of testing framework\nFour steps for hypothesis test:\n\nDefine null and alternative hypotheses \\(H_{0}\\) and \\(H_{A}\\) in context\nCollect data and set significance level \\(\\alpha\\)\nObtain/estimate p-value by modeling randomness that would occur if the \\(H_{0}\\) were true\n\nWe did this using by simulating under the null distribution\n\nInterpret p-value and make a decision in context"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#errors-in-decision",
    "href": "slides/slides-13-intro-testing.html#errors-in-decision",
    "title": "Introduction to Hypothesis Testing",
    "section": "Errors in decision",
    "text": "Errors in decision\n\nIn Step 4, we make a decision but it could be wrong! (Unfortunately, we will never know)\nWe always fall into one of the following four scenarios:\n\n\n\n\n\n\n\n\n\n\nIdentify which cells are good scenarios, and which are bad"
  },
  {
    "objectID": "slides/slides-13-intro-testing.html#errors-in-decision-1",
    "href": "slides/slides-13-intro-testing.html#errors-in-decision-1",
    "title": "Introduction to Hypothesis Testing",
    "section": "Errors in decision",
    "text": "Errors in decision\n\n\n\nWhat kind of error could we have made in our example?\n\nIt is important to weight the consequences of making each type of error!\n\nWe have some control in this. How?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#running-example-cpr",
    "href": "slides/slides-14-randomization.html#running-example-cpr",
    "title": "Hypothesis Testing with Randomization",
    "section": "Running example: CPR",
    "text": "Running example: CPR\nAn experiment was conducted, consisting of two treatments on 90 patients who underwent CPR for a heart attack and subsequently went to the hospital. Each patient was randomly assigned to either:\n\ntreatment group: receive a blood thinner\ncontrol group: do not receive a blood thinner\n\nFor each patient, the outcome recorded was whether they survived for at least 24 hours.\n\n\n\n\n \n  \n    group \n    died \n    survived \n    total \n  \n \n\n  \n    control \n    39 \n    11 \n    50 \n  \n  \n    treatment \n    26 \n    14 \n    40 \n  \n  \n    total \n    65 \n    25 \n    90 \n  \n\n\n\n\n\n\n\nWhat is/are the variables(s) here? What types of variables are they?"
  },
  {
    "objectID": "slides/slides-14-randomization.html#collect-data",
    "href": "slides/slides-14-randomization.html#collect-data",
    "title": "Hypothesis Testing with Randomization",
    "section": "Collect data",
    "text": "Collect data\nUsing the data, obtain the observed difference in sample proportions.\n\n\n\n\n \n  \n    group \n    died \n    survived \n    total \n  \n \n\n  \n    control \n    39 \n    11 \n    50 \n  \n  \n    treatment \n    26 \n    14 \n    40 \n  \n  \n    total \n    65 \n    25 \n    90 \n  \n\n\n\n\n\n\n\n\n\np_hat_c <- cpr |>\n  filter(group == \"control\") |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull()\np_hat_t <- cpr |>\n  filter(group == \"treatment\") |>\n  summarise(p = mean(outcome == \"survived\")) |>\n  pull()\nobs_diff <- p_hat_t - p_hat_c\n\n\n\n\n\\(\\hat{p}_{C} = \\frac{11}{50} =\\) 0.22\n\\(\\hat{p}_{T} = \\frac{14}{40} =\\) 0.35\nObserved difference: \\(\\hat{p}_{T} - \\hat{p}_{C} = 0.13\\)\n\n\n\n\nIs this “convincing evidence” that blood thinner usage after CPR is effective?\nSet \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#defining-hypotheses-1",
    "href": "slides/slides-14-randomization.html#defining-hypotheses-1",
    "title": "Hypothesis Testing with Randomization",
    "section": "Defining hypotheses",
    "text": "Defining hypotheses\nThe researchers are interested in learning if the blood thinner treatment was effective.\n\nIn words, try to determine \\(H_{0}\\) and \\(H_{A}\\).\n\n\nLet \\(p_{T}\\) and \\(p_{C}\\) denote the proportion of patients who survive when receiving the thinner (Treatment) and when not receiving the treatment (Control), respectively\n\n\n\n\n\\(H_{0}\\): \\(p_{T} \\leq p_{C}\\)\n\\(H_{A}\\): \\(p_{T} > p_{C}\\)\n\n\n\n\\(H_{0}\\): \\(p_{T} - p_{C} \\leq 0\\)\n\\(H_{A}\\): \\(p_{T} - p_{C}> 0\\)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#simulate-under-null",
    "href": "slides/slides-14-randomization.html#simulate-under-null",
    "title": "Hypothesis Testing with Randomization",
    "section": "Simulate under null",
    "text": "Simulate under null\n\nSimulating under \\(H_{0}\\) means operating in a hypothetical word where sex and decision are independent.\n\nThis means that knowing the sex of the candidate should have no bearing on the decision to promote or not\n\nWe will perform a simulation called a randomization test where we randomly re-assign decision and sex outcome pairs to see what would have happened if the bankers’ decisions had been independent of sex"
  },
  {
    "objectID": "slides/slides-14-randomization.html#visualizing-null-distribution",
    "href": "slides/slides-14-randomization.html#visualizing-null-distribution",
    "title": "Hypothesis Testing with Randomization",
    "section": "Visualizing null distribution",
    "text": "Visualizing null distribution"
  },
  {
    "objectID": "slides/slides-14-randomization.html#calculate-p-value",
    "href": "slides/slides-14-randomization.html#calculate-p-value",
    "title": "Hypothesis Testing with Randomization",
    "section": "Calculate p-value",
    "text": "Calculate p-value\n\n\n\n\n\n\n\n\n\nWe observed 107 out of 1000 simulations where the difference in proportions under \\(H_{0}\\) was as or more extreme than our observed difference of 0.13\nSo p-value is 0.107"
  },
  {
    "objectID": "slides/slides-14-randomization.html#interpret-and-make-conclusion",
    "href": "slides/slides-14-randomization.html#interpret-and-make-conclusion",
    "title": "Hypothesis Testing with Randomization",
    "section": "Interpret and make conclusion",
    "text": "Interpret and make conclusion\nThe researchers are interested in learning if the blood thinner treatment was effective.\nOur p-value is 0.107 and our selected significance level was \\(\\alpha = 0.05\\).\n\n\nInterpret our p-value in text\nMake a conclusion about the research question in context."
  },
  {
    "objectID": "slides/slides-14-randomization.html#simulate-under-null-code",
    "href": "slides/slides-14-randomization.html#simulate-under-null-code",
    "title": "Hypothesis Testing with Randomization",
    "section": "Simulate under null (code)",
    "text": "Simulate under null (code)\n\nset.seed(310)\nn_t <- sum(cpr$group == \"treatment\")\nn_c <- sum(cpr$group == \"control\")\nn_died <- sum(cpr$outcome == \"died\")\nn_survived <- sum(cpr$outcome == \"survived\")\n\n# make my cards\ncards <- c(rep(\"died\", n_died), rep(\"survived\", n_survived))\n\nB <- 1000\ndiff_sims <- rep(NA , B)\nfor(b in 1:B){\n  # shuffle cards\n  shuffled <- sample(cards)\n  \n  # deal out n_t cards to treatment group\n  control_sim <- shuffled[1:n_t]\n  \n  # deal out remaining n_c cards to control group\n  treat_sim <- shuffled[-c(1:n_t)]\n  \n  # calculate proportion of survival in each group\n  p_t_sim <- mean(treat_sim == \"survived\")\n  p_c_sim <- mean(control_sim == \"survived\")\n  \n  # calculate difference and store\n  diff_sims[b] <- p_t_sim - p_c_sim\n}"
  },
  {
    "objectID": "slides/slides-14-randomization.html#where-were-going-today",
    "href": "slides/slides-14-randomization.html#where-were-going-today",
    "title": "Hypothesis Testing with Randomization",
    "section": "Where we’re going today",
    "text": "Where we’re going today\n\nWe will see another kind of hypothesis for different type of research question\nHypothesis testing framework is the same, but will change how we obtain null distribution\nTry to see the big picture"
  },
  {
    "objectID": "slides/slides-14-randomization.html#randomization-test",
    "href": "slides/slides-14-randomization.html#randomization-test",
    "title": "Hypothesis Testing with Randomization",
    "section": "Randomization test",
    "text": "Randomization test\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    10 \n    14 \n    24 \n  \n  \n    male \n    3 \n    21 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nWrite down “promote” on 35 cards and “not promote” on 13 cards\nThen repeat the following several times:\n\nThoroughly shuffle these 48 cards.\nDeal out a stack of 24 cards to represent males, and the remaining 24 cards to represent females\n\nThis is how we simulate independence under \\(H_{0}\\)\n\nCalculate the proportion of “promote” cards in each stack, \\(\\hat{p}_{m, sim}\\) and \\(\\hat{p}_{f, sim}\\)\nCalculate and record the difference \\(\\hat{p}_{f,sim} - \\hat{p}_{m,sim}\\) (order of difference doesn’t matter so long as you are consistent)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#randomization-test-code",
    "href": "slides/slides-14-randomization.html#randomization-test-code",
    "title": "Hypothesis Testing with Randomization",
    "section": "Randomization test (code)",
    "text": "Randomization test (code)\nLet’s perform one iteration of the simulation.\n\n# reproducibility\nset.seed(1)\nn_promote <- sum(discrimination$decision == \"promote\")\nn_not_promote <- sum(discrimination$decision == \"not promote\")\nn_female <- sum(discrimination$sex == \"female\")\nn_male <- sum(discrimination$sex == \"male\")\n\n# create cards\ncards <- c(rep(\"promote\", n_promote), rep(\"not promote\", n_not_promote))\n\n# shuffle cards\nshuffled <- sample(cards)\n\n\n\n\n\n \n  \n    sex \n    not promote \n    promote \n    total \n  \n \n\n  \n    female \n    7 \n    17 \n    24 \n  \n  \n    male \n    6 \n    18 \n    24 \n  \n  \n    total \n    13 \n    35 \n    48 \n  \n\n\n\n\n\n\nUnder this simulation, 0.7083333 of females were promoted, and 0.75 of males were promoted. Simulated difference: -0.0416667"
  },
  {
    "objectID": "slides/slides-14-randomization.html#null-distribution",
    "href": "slides/slides-14-randomization.html#null-distribution",
    "title": "Hypothesis Testing with Randomization",
    "section": "Null distribution",
    "text": "Null distribution\n\n\n\nRepeat the previous 1000 times:"
  },
  {
    "objectID": "slides/slides-14-randomization.html#obtain-p-value",
    "href": "slides/slides-14-randomization.html#obtain-p-value",
    "title": "Hypothesis Testing with Randomization",
    "section": "Obtain p-value",
    "text": "Obtain p-value\nRecall, the observed difference in our data was \\(\\hat{p}_{f} - \\hat{p}_{m} =\\) -0.2916667.\n\np-value is probability of observing data as or more extreme than our original data, given \\(H_{0}\\) true.\n\nWhere does “as or more extreme” correspond to on our plot?\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut of 1000 simulations under \\(H_{0}\\), 29 resulted in difference in promotion rates as or more extreme than our observed\nSo the p-value is 0.029"
  },
  {
    "objectID": "slides/slides-14-randomization.html#making-conclusion",
    "href": "slides/slides-14-randomization.html#making-conclusion",
    "title": "Hypothesis Testing with Randomization",
    "section": "Making conclusion",
    "text": "Making conclusion\nOur research question: Are individuals who identify their sex as female discriminated against in promotion decisions made by their managers who identify as male?\n\n\\(H_{0}\\): sex and decision are independent\n\\(H_{A}\\): sex and decision are not independent and equally-qualified female personnel are less likely to get promoted than male personnel by male supervisors\n\\(\\alpha = 0.05\\)\n\n\n\nInterpret our p-value in context.\nMake a decision in response to the research question."
  },
  {
    "objectID": "slides/slides-14-randomization.html#making-conclusion-answer",
    "href": "slides/slides-14-randomization.html#making-conclusion-answer",
    "title": "Hypothesis Testing with Randomization",
    "section": "Making conclusion (answer)",
    "text": "Making conclusion (answer)\n\nAssuming that sex and decision are independent, the probability of observing a difference in promotion rates as or more extreme as we did is 0.029.\nBecause the observed p-value of 0.029 is less than our significant level 0.5, we reject \\(H_{0}\\). The data provide strong evidence of sex discrimination against female candidates by the male supervisors."
  },
  {
    "objectID": "slides/slides-14-randomization.html#simulate-under-null-1",
    "href": "slides/slides-14-randomization.html#simulate-under-null-1",
    "title": "Hypothesis Testing with Randomization",
    "section": "Simulate under null",
    "text": "Simulate under null\n\nWe will once again perform a randomization text to try and simulate the difference in proportions under \\(H_{0}\\)\n\nUnder \\(H_{0}\\), treatment group is no better than control group, so let’s simulate assuming that outcome and treatment are independent\n\nWrite down died on 65 cards, and survived on 25 cards. Then repeat several times:\n\nShuffle cards well\nDeal out 50 to be Control group, and remaining 40 to be Treatment group\nCalculate proportions of survival \\(\\hat{p}_{C, sim}\\) and \\(\\hat{p}_{T, sim}\\)\nObtain and record the simulated difference \\(\\hat{p}_{T, sim} - \\hat{p}_{C, sim}\\)"
  },
  {
    "objectID": "slides/slides-14-randomization.html#randomization-test-activity",
    "href": "slides/slides-14-randomization.html#randomization-test-activity",
    "title": "Hypothesis Testing with Randomization",
    "section": "Randomization test (activity)",
    "text": "Randomization test (activity)\nTry it!"
  },
  {
    "objectID": "live_code/intro_testing.html",
    "href": "live_code/intro_testing.html",
    "title": "Null distribution of sample proportion",
    "section": "",
    "text": "library(tidyverse)\nDefine \\(p\\) as the true proportion of students who get at least 7 hours of sleep on average. Our hypotheses were:\n\\(H_{0}\\): \\(p \\leq 0.5\\)\n\\(H_{A}\\): \\(p > 0.5\\)"
  },
  {
    "objectID": "live_code/intro_testing.html#simulating-null-distribution",
    "href": "live_code/intro_testing.html#simulating-null-distribution",
    "title": "Null distribution of sample proportion",
    "section": "Simulating null distribution",
    "text": "Simulating null distribution\nThe example below demonstrates how to obtain a null distribution for \\(\\hat{p}\\) under \\(H_{0}\\). We said:\n\npink slips represent students who get at least 7 hours, and\npurple slips represent students who do not get at least 7 hours\n\n\nset.seed(2)\nB <- 5000\nn <- 10\np_null_vec <- rep(NA, B)\nfor(b in 1:B){\n  null_samp <- sample(x = c(\"pink\", \"purple\"),\n                      size = n, \n                      replace = T, \n                      prob = c(0.5, 0.5)) \n  \n  p_null_vec[b] <- sum(null_samp == \"pink\")/n\n}\n\nThe code above repeatedly for 5000 iterations draws a new sample of size 10 from the world assuming \\(H_{0}\\) is true (in this case, \\(p = 0.5\\)). At every iteration, we record the proportion of pink slips in the sample of size 10 to represent the proportion of people who got at least 7 hours of sleep."
  },
  {
    "objectID": "live_code/intro_testing.html#visualizing-null-distribution",
    "href": "live_code/intro_testing.html#visualizing-null-distribution",
    "title": "Null distribution of sample proportion",
    "section": "Visualizing null distribution",
    "text": "Visualizing null distribution\nWe can visualize the null distribution by:\n\nCreating a data frame of our vector of simulated null statistics p_null_vec\nPiping into ggplot()\n\n\n\ndata.frame(<variable name> = <vector>)creates a data frame from vectors, and we can set the column/variable names.\nIn the code here, data.frame(p_sim = p_null_vec) creates a data frame with a variable called p_sim. The values that comprise that variable come from p_null_vec.\n\nnull_df <- data.frame(p_sim = p_null_vec)\nggplot(null_df, aes(x = p_sim))+\n  geom_histogram(binwidth = 0.1,col = \"white\")+\n  labs(x = \"Null dist. of proportion of students getting at least 7 hours\") +\n  theme_minimal()\n\n\n\n\nWe can add a vertical line to our plot to show where the observed \\(\\hat{p}\\) falls in the null distribution."
  },
  {
    "objectID": "practice_probs/practice-13-intro_testing.html",
    "href": "practice_probs/practice-13-intro_testing.html",
    "title": "Hypothesis testing",
    "section": "",
    "text": "For each of the research statements below, determine whether it represents a null hypothesis claim or an alternative hypothesis claim.\n\nThe number of hours that grade-school children spend doing homework predicts their future success on standardized tests.\nKing cheetahs on average run the same speed as standard spotted cheetahs.\nFor a particular student, the probability of correctly answer a 5-option multiple choice test is larger than 0.2 (i.e. better than guessing)\nThe probability of getting in a car accident is the same if using a cell phone then if not using a cell phone.\n\nWrite out the null and alternative hypotheses in words and also in statistical notation for each of the following situations. When writing in statistical notation, be sure to define quantities in context.\n\nNew York is known as “the city that never sleeps”. A random sample of 25 New Yorkers were asked how much they sleep they get per night. Does these data providing convincing evidence that New Yorkers on average sleep less than 8 hours per night?\nA study suggests that 25% of 25 year-olds have gotten married. You believe that this is incorrect and decide to collect your own data to conduct a hypothesis test.\n\nA Survey USA poll conducted in Seattle, WA in May 2021 reports that of the 650 respondents (adults living in this area), 159 support proposals to defund police departments.\n\nA journals writing a news story on the poll results wants to use the headline: “More than 1 in 5 adults living in Seattle support proposals to defund police departments”. You caution the journalist that they should first conduct a hypothesis test to see if the poll data provide convincing evidence for this claim. Write the hypotheses for this test using proper notation, defining any necessary quantities.\nDescribe in words a simulation scheme that would be appropriate for this situation. Also describe how the p-value can be calculated using the simulation results.\nThe histogram below shows the distribution of 1000 simulated proportions under \\(H_{0}\\). Estimate the p-value using the plot and use it to evaluate your hypotheses (i.e. make a conclusion). Assume a significance level of 0.05.\n\n\n\\((^*)\\) In a large university where 60% of the full-time students are employed at least 5 hours per week, the members of the Statistics Department faculty wonder if the same proportion of their students work at least 5 hours per week. They randomly sample 25 of their majors and find that 12 of the students work 5 or more hours per week.\nTwo sampling distributions were created to describe the variability in the proportion of statistics majors who work at least 5 hours per week: a null distribution and a bootstrap distribution. In both cases, \\(B=1000\\) simulations were generated.\n\n\nWhich distribution(s) was/were obtained by sampling with replacement, and which distribution(s) was/were obtained by sampling without replacement?\nEstimate the standard error of the simulated proportions based on each distribution. Are the two standard errors you estimated roughly equal?\nUsing the appropriate histogram, test the claim that 70% of statistics majors, like their peers, work at least 5 hours per week. State the hypotheses, find the p-value, and conclude in the context of the problem. Use a significance level of 0.10.\nUsing the appropriate histogram, find a 90% bootstrap confidence interval for the true proportions of statistics majors who work at least 5 hours per week. Interpret the confidence interval in the context of the problem.\nBriefly comment on how your conclusions in (c) and (d) compare.\n\nA study conducted in 2020 found that the U.S. adjusted divorce rate was 14 per 1000 married women. Joe is suspicious and disagrees with the stated divorce rate. Joe somehow collected data from 323 married or previously-married women, and asked them if they had a divorce in 2020. 55 of the women responded that they indeed had a divorce in 2020.\n\nWrite out the hypotheses corresponding to this scenario.\nDescribe in words a simulation scheme that would be appropriate for this situation. Also describe how the p-value can be calculated using the simulation results.\nThe histogram below shows the distribution of 1000 simulated proportions under \\(H_{0}\\). Estimate the p-value using the plot and use it to evaluate Joe’s hypotheses (i.e. make a conclusion). Assume a significance level of 0.05.\n\nJoe is some free time and also created a 90% bootstrap confidence interval for the divorce rate.\n\n\n\nHe obtained the following interval: (0.136, 0.204). Interpret this interval in context.\nBased on this interval, would it be appropriate for Joe to conclude that the study’s reported rate was wrong? Explain your reasoning.\nHow do your conclusions from (c) and (e) compare?"
  }
]