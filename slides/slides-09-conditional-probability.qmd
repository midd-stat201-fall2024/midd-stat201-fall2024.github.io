---
title: "Conditional probability"
date: "October 2, 2024"
title-slide-attributes:
    data-background-image: "figs/bikeshare-plots.png"
    data-background-size: contain
    data-background-opacity: "0.2"
format: 
  revealjs:
    theme: custom.scss
    transition: none
    incremental: true
    scrollable: true
editor: visual
editor_options: 
  chunk_output_type: console
draft: false
---

# Housekeeping

# Three types of probability

## Probabilities with contingency tables

-   As we saw in the previous class, sometimes the probabilities of events are quite clear to calculate (e.g. dice rolls or drawing cards)

-   But oftentimes we have to use data to try and estimate probabilities (e.g. the Pew Research survey)

-   When we have two (or more) variables, we often want to understand the relationships between them

## Practice

![](figs/08-coffee.png){fig-align="center"}

Source: <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5788283/>

::: fragment
|                                | Did not die | Died | **Total** |
|--------------------------------|-------------|------|-----------|
| **Does not drink coffee**      | 5438        | 1039 | 6477      |
| **Drinks coffee occasionally** | 29712       | 4440 | 34152     |
| **Drinks coffee regularly**    | 24934       | 3601 | 28535     |
| **Total**                      | 60084       | 9080 | 69164     |
:::

::: fragment
::: discuss
Define events $A$ = died and $B$ = non-coffee drinker. Calculate the following for a randomly selected person in the cohort:

-   $\text{P}(A)$

-   $\text{P}(A \cap B)$

-   $\text{P}(A \cup B^c)$
:::
:::

## Marginal and joint probabilities

1.  $\text{P}(A)$ is an example of a **marginal probability**, which is a probability involving a single random process

    -   From the contingency table, we use row totals or column totals and the overall total to obtain marginal probabilities

2.  $\text{P}(A \cap B)$ and $\text{P}(A \cup B^c)$ are examples of a **joint probability**, which is a probability of events for two or more random variables or processes

    -   From the contingency table, we use specific cells and the overall total to obtain marginal probabilities

## Marginal from joint

In simple cases, we can obtain the marginal distribution from joint distributions. You already did this!

|                                | Did not die | Died | **Total** |
|--------------------------------|-------------|------|-----------|
| **Does not drink coffee**      | 5438        | 1039 | 6477      |
| **Drinks coffee occasionally** | 29712       | 4440 | 34152     |
| **Drinks coffee regularly**    | 24934       | 3601 | 28535     |
| **Total**                      | 60084       | 9080 | 69164     |

::: fragment
$$\begin{align*}
\text{P}(B) =\text{P}(\text{does not drink coffee}) &= P(\text{does not drink coffee} \ \cap \text{ did not die}) + \\
&\quad \text{P}(\text{does not drink coffee} \ \cap \text{ died}) \\
&= \text{P}(B \cap A) + \text{P}(B \cap A^c) \\
&= \frac{5438}{69164 } + \frac{1039}{69164} \\
&= 0.0936
\end{align*}
$$
:::

## Conditional probability

3.  The probability that an event will occur *given* that another event has already occurred is a **conditional probability**.
    -   E.g. Given that it rained yesterday, what is the probability that it will rain today?
    -   It is called "conditional" because we calculate a probability under a specific condition
        -   Nnot to be confused with the coding `|` which is "or"

-   We can easily obtain conditional probabilities from contingency tables!

## Conditional probability with contingency tables

|                                | Did not die | Died | **Total** |
|--------------------------------|-------------|------|-----------|
| **Does not drink coffee**      | 5438        | 1039 | 6477      |
| **Drinks coffee occasionally** | 29712       | 4440 | 34152     |
| **Drinks coffee regularly**    | 24934       | 3601 | 28535     |
| **Total**                      | 60084       | 9080 | 69164     |

::: fragment
::: discuss
Recall events $A$ = died and $B$ = non-coffee drinker. Write $\text{P}()$ notation for conditional probability of dying given that someone does not drink coffee, and then obtain this probability.
:::
:::

## General multiplication rule

Conditional, joint, and marginal probabilities are related via the **general multiplication rule**\*:

::: fragment
$$
\text{P}(A \cap B) =
$$
:::

-   Very useful for finding probability that two events will happen.

    -   Example: A box has three tickets, colored red, orange, yellow. We will draw two tickets randomly without replacement. What is the probability of drawing the red ticket first and then the orange ticket?

## Independence and conditional probabilities

-   Recall, events $A$ and $B$ are independent when what is true about their joint probability?

-   Using the general multiplication rule, what is another way to determine if events $A$ and $B$ are independent?

    -   Why does this make sense "intuitively"?

-   ::: discuss
    Using this new test of independence, are dying and abstaining from coffee independent events?
    :::

## Conditional probability formula

We can re-arrange the general multiplication formula to obtain the following general formula for conditional probability. For any events $A$ and $B$:

::: fragment
$$
\text{P}(A| B) = \frac{\text{P}(A \cap B)}{\text{P}(B)}
$$
:::

-   ::: discuss
    Recall $A$ is the event that someone died, and $B$ the event that someone does not drink coffee.

    -   Use the above formula to obtain $\text{P}(A|B)$
    -   Come up with a formula for $\text{P}(B|A)$ and calculate this conditional probability for the problem at hand.
    :::

-   ::: {style="color: maroon"}
    Note: complement rule holds for conditional probabilities if we condition on the *same* information: $\text{P}(A|B) = 1 - \text{P}(A^c | B)$
    :::

## Tree diagram

Tool to organize outcomes and probabilities around the structure of the data. Useful when outcomes occur sequentially, and outcomes are conditioned on predecessors. Let's do an example:

-   A class has a midterm and a final exams. 13% of students earned an A on the midterm. Of those students who earned an A on the midterm, 47% received and A on the final. Of those student who earned below an A on the midterm, 11% received an A on the final. You randomly pick up a final exam and notice the student received an A. What is the probability that they earned an A on the midterm?

-   ::: discuss
    Using $\text{P}()$ notation, what probability are we interested in? What probabilities do we need to calculate the desired probability?
    :::

-   Let's construct our tree!

-   ::: discuss
    In the diagram tree, where are the three types of probabilities appearing?
    :::

# Bayes' Rule

## Bayes' Rule

-   As we saw before, the two conditional probabilities $P(A|B)$ and $P(B|A)$ are not the same. But are they related in some way?

-   **Bayes' rule**:

::: fragment
$$
P(A|B) =
$$
:::

-   Can we go even further?

::: fragment
$$
P(A|B) =
$$
:::

-   Why is this seemingly more complicated formula useful?

## Bayes' Theorem (more general)

-   Suppose we have a random process and have a defined event $B$

-   Further suppose we can break up the sample space into $k$ disjoint/mutually exclusive outcomes or events $A_{1}, A_{2}, \ldots, A_{k}$

    -   The $A_{i}$ may or may not intersect with $B$

-   Without loss of generality, suppose we want $\text{P}(A_{1} | B)$

-   **Bayes' Theorem** states:

    $$\begin{align*}
    \text{P}(A_{1} |  B ) &= \frac{\text{P}(A_{1} \cap B)}{\text{P}(B)}\\
    &= \frac{\text{P}(B|A_{1})\text{P}(A_{1})}{\text{P}(B\cap A_{1}) + \text{P}(B \cap A_{2}) + \ldots + \text{P}(B \cap A_{k})} \\
    &=\frac{\text{P}(B|A_{1}) \text{P}(A_{1})}{\text{P}(B|A_{1}) \text{P}(A_{1}) + \text{P}(B | A_{2}) \text{P}(A_{2}) + \ldots + \text{P}(B | A_{k} ) \text{P}(A_{k})}
    \end{align*}$$

::: notes
Blob picture. How would this change if we wanted $P(A_{2} | B)$ instead?
:::

## Example

-   In Canada, about 0.35% of women over 40 will develop breast cancer in any given year. A common screening test for cancer is the mammogram, but this test is not perfect.

-   In about 11% of patients with breast cancer, the test gives a *false negative*: it indicates a woman does not have breast cancer when she does have breast cancer.

-   In about 7% of patients who do not have breast cancer, the test gives a *false positive*: it indicates these patients have breast cancer when they actually do not.

-   If we tested a random Canadian woman over 40 for breast cancer using a mammogram and the test came back positive, what is the probability that the patient actually has breast cancer?
