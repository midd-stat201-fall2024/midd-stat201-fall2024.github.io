---
title: "Confidence Intervals for Means"
date: "October 24, 2024"
title-slide-attributes:
    data-background-image: "figs/bikeshare-plots.png"
    data-background-size: contain
    data-background-opacity: "0.2"
format: 
  revealjs:
    theme: custom.scss
    transition: none
    incremental: true
    scrollable: true
editor: visual
editor_options: 
  chunk_output_type: console
draft: false
---

## Recap

```{r echo = F, message= F}
knitr::opts_chunk$set(echo = F, warning = F, messabundance = F)
library(tidyverse)
library(openintro)
library(readr)
library(kableExtra)
plot_theme <- theme(text = element_text(size = 24))
source("../stat201_fns.R")
```

-   Central Limit Theorem: if we have a sufficiently large sample of $n$ independent observations from a population with mean $\mu$ and standard deviation $\sigma$, then $\bar{X} \overset{\cdot}{\sim} N\left(\mu, \frac{\sigma}{\sqrt{n}}\right)$

-   When considering the special case of sample proportions, if success-failure condition is met, we have $\hat{p} \overset{\cdot}{\sim} N\left(p, \sqrt{\frac{p(1-p)}{n}}\right)$

-   To obtain a $\gamma\times 100\%$ CI for a mean, we use

    ::: fragment
    $$
    \text{point estimate} \pm \text{critical value} \times \text{SE} 
    $$
    :::

    -   We needed to replace the standard error with an estimate

## Checking normality

-   Remember, CLT requires a sufficiently large sample size $n$ or assumption of Normality of the underlying data.

-   No perfect way to check Normality, but rule of thumb:

    -   If $n < 30$ small: check that there are no clear outliers

    -   If $n \geq 30$ large: check that there are no particularly extreme outliers

# CI for a single mean

## CI for a single mean (known variance)

Suppose we want a $\gamma\times 100\%$ CI for population mean $\mu$.

::: discuss
What would your "best guess" point estimate for $\mu$ be?
:::

-   If CLT holds, then we know

    $$
    \bar{X} \overset{\cdot}{\sim} N\left(\mu, \frac{\sigma}{\sqrt{n}}\right)
    $$

-   So our $\gamma \times 100\%$ CI for $\mu$ is:

    $$
    \text{point estimate} \pm \underbrace{\text{critical value} \times \text{SE}}_{\text{Margin of Error}} = \bar{x} \pm z_{(1+\gamma)/2}^* \times \frac{\sigma}{\sqrt{n}}
    $$

## Example: age at marriage

```{r}
set.seed(2)
n <- 25
sd_age <- round(sd(age_at_mar$age), 2)
x <- sample(age_at_mar$age, n)
xbar <- mean(x)
s_age <- round(sd(x),2)
se <- sd_age / sqrt(n)
```

In 2006-2010, the CDC conducted a thorough survey asking US women their age at first marriage. The standard deviation of the responses is `r sd_age` years. Suppose we randomly sample 25 US women and ask them their age at first marriage (plotted below). Their average age at marriage was `r xbar`.

:::::::: columns
:::: {.column width="50%"}
```{r}
ggplot(data.frame(x), aes(x=x)) +
  geom_histogram(binwidth = 2, col = "white") +
  labs(x = "Age at first marriage") +
  theme_minimal() +
  theme(text =element_text(size = 28))
```

::: discuss
What is/are the population parameter(s)? What is the statistic?
:::
::::

::::: {.column width="50%"}
::: {.fragment style="color: maroon"}
We will obtain an 80% confidence interval for the mean age of US women at first marriage.
:::

::: discuss
-   Are conditions of CLT met?

-   If so, what does CLT tell us?
:::
:::::
::::::::

## Example: age at marriage (cont.)

::: {style="color: maroon"}
Obtain an 80% confidence interval for the mean age of US women at first marriage.
:::

```{r}
zstar90 <- round(qnorm(0.9), 2)
ci <- round(xbar +  zstar90*se*c(-1,1), 2)
```

By CLT: $$\bar{X} \overset{\cdot}{\sim}N\left(\mu, \frac{`r sd_age`}{\sqrt{`r n`}}\right) = N(\mu, `r se`)$$

::: fragment
Collect necessary components:
:::

1.  Point estimate: $\bar{x} = `r xbar`$
2.  Standard error: $`r se`$
3.  Critical value: $z_{0.9}^{*} =$ `qnorm(0.9, 0, 1)` $= `r zstar90`$

::: fragment
So our 80% confidence interval is $`r xbar` \pm `r round(qnorm(0.9),2)` \times `r se` = (`r ci[1]`, `r ci[2]`)$
:::

:::: fragment
::: discuss
Interpret this interval!
:::
::::

## Utility of this model

-   The previous formula for the confidence interval for $\mu$ relies on knowing $\sigma$

-   But wait...

    -   Want to construct a CI for $\mu$ because we don't know its value

    -   If we don't know $\mu$, it seems highly unlikely that we would know $\sigma$!

-   So in practice, we will have to estimate standard error for $\bar{X}$:

::: fragment
$$
    \text{SE}\approx \frac{s}{\sqrt{n}}
$$

where $s$ is the observed sample standard deviation
:::

-   Recall we did something similar for CI for $p$

## Variance issue

-   Replacing $s$ for $\sigma$ works well enough when $n$ is extremely large so we can estimate $\sigma$ accurately

-   However, estimating variance is extremely difficult when $n$ is small, and still not great for large $n$

-   So if $\sigma$ is unknown, we ***cannot*** use the Normal approximation to model $\bar{X}$ for inferential tasks

-   Instead, we will use a new distribution for inference calculations, called the $t$-distribution

## $t$-distribution

-   The $t$**-distribution** is symmetric and bell-curved (like the Normal distribution)

-   Has "thicker tails" than the Normal distribution (the tails decay more slowly)

:::::: columns
:::: {.column width="60%"}
::: fragment
```{r}
ggplot() +
  stat_function(fun = dnorm, aes(col = "N(0,1)"), linetype = "dashed", linewidth = 2) +
  stat_function(fun = dt, args = list(df = 1), aes(col = "t (df = 1)"), linewidth = 2) +
    stat_function(fun = dt, args = list(df = 2), aes(col = "t (df = 2)"), linewidth = 2) +
    stat_function(fun = dt, args = list(df = 10), aes(col = "t (df = 20)"), linewidth = 2) +
  scale_x_continuous(limits = c(-4,4), breaks = -4:4) +
  theme_minimal() +
  labs(color = "Distribution", y = "density", x = "x") +
  theme(text = element_text(size = 28))
```
:::
::::

::: {.column width="40%"}
-   $t$-distribution is always centered at 0
-   One parameter: **degrees of freedom (df)** defines exact shape of the $t$
    -   Denoted $t_{df}$ (e.g. $t_{1}$ or $t_{20}$)
:::
::::::

-   As $df$ increase, $t$ resembles the $N(0,1)$. When $df \geq 30$, the $t_{df}$ is nearly identical to $N(0,1)$

## Working with $t$ distribution

```{r}
ub <- -1.5
p <- 0.7
df <- 2
```

Let's draw pictures for the following:

-   What proportion of the $t_{`r df`}$-distribution falls below `r ub`?

-   What value of the $t_{`r df`}$-distribution has $`r p*100`\%$ area lying below it?

## $t$ distribution in `R`

-   `pnorm(x, mean, sd)` and `qnorm(%, mean, sd)` used to find probabilities and percentiles for the Normal distribution

-   Analogous functions for $t$-distribution: `pt(x, df)` and `qt(%, df)`

::::::::: columns
::::: {.column width="50%"}
::: fragment
```{r}
funcShaded_t <- function(x, lower_bound = -Inf, upper_bound = Inf) {
    y = dt(x, df = df)
    y[x < lower_bound] <- NA
    y[x > upper_bound] <- NA
    return(y)
}


ggplot() +
  stat_function(fun = dt, args = list(df = 2)) +
  scale_x_continuous(limits = c(-4,4), breaks = -4:4) +
  theme_minimal() +
  labs(title = (expression(t[2])), y = "density", x = "x") +
  theme(text = element_text(size = 28)) +
  stat_function(fun = funcShaded_t, args = list( upper_bound = ub),  geom = "area", fill = "#84CA72", alpha = .8)  +
  annotate("text", label = "?", x = ub - 0.75, y = 0.02, size = 15 )

prob <- pt(ub, df)
```
:::

::: fragment
`pt(`r ub`,df =`r df`)` = `r prob`
:::
:::::

::::: {.column width="50%"}
::: fragment
```{r}
ub <- qt(p, df)
ggplot() +
  stat_function(fun = dt, args = list(df = 2)) +
  scale_x_continuous(limits = c(-4,4), breaks = -4:4) +
  theme_minimal() +
  labs(title = (expression(t[2])), y = "density", x = "x") +
  theme(text = element_text(size = 28)) +
  stat_function(fun = funcShaded_t, args = list( upper_bound = ub),  geom = "area", fill = "#84CA72", alpha = .8) +
   annotate("text", label = as.character(p), x = ub - 0.75, y = 0.15, size = 15)
```
:::

::: fragment
`qt(`r p`, df =`r df`)` = `r ub`
:::
:::::
:::::::::

## CI for a single mean (unknown variance)

-   Still require independent observations and the Normality condition for CLT

-   General formula for $\gamma \times 100\%$ CI is the same, but we simply change what goes into the margin of error.

::: fragment
$$
\begin{align*}
\text{point estimate} &\pm t^*_{df, (1+\gamma)/2} \times \widehat{\text{SE}} \\
\bar{x} &\pm t_{df, (1+\gamma)/2}^* \times \frac{s}{\sqrt{n}}
\end{align*}
$$
:::

-   $df = n-1$

-   critical value $t^*_{df, (1+\gamma)/2}$ = $(1+\gamma)/2$ percentile of the $t_{df}$ distribution

## Example: age at marriage (cont.)

Let's return to the age at marriage example. Once again let's obtain an 80% confidence interval for the average age of first marriage for US women, but now suppose we **don't know $\sigma$**.

::: fragment
In our sample of $n = 25$ women, we observed a sample mean of $`r xbar`$ years and a sample standard deviation of $s = `r s_age`$ years.
:::

```{r}
se_hat <- s_age/ sqrt(n)
df <- n-1
tstar90 <- round(qt(0.9, df), 2)
ci_t <- round(xbar + tstar90*se_hat*c(-1,1), 2)
```

1.  Point estimate: $\bar{x} = `r xbar`$
2.  Standard error: $\widehat{\text{SE}} = \frac{s}{\sqrt{n}}= \frac{`r s_age`}{\sqrt{`r n`}} = `r se_hat`$
3.  Critical value:
    -   $df = n-1 = `r df`$
    -   $t_{`r df`}^*$ = `qt(0.9, df =`r df`)` = `r tstar90`

::: fragment
So our 80% confidence interval for $\mu$ is:

$$
`r xbar` \pm `r tstar90` \times `r se_hat` = (`r ci_t[1]`, `r ci_t[2]`)
$$
:::

## Comparing CIs

::::: columns
::: {.column width="50%"}
**Known variance:**

80% CI: (`r ci`)
:::

::: {.column width="50%"}
**Unknown variance:**

80% CI: (`r ci_t`)
:::
:::::

-   ::: discuss
    How do the two intervals compare?
    :::

-   Interpretation of CI does not change even if we use a different model!

## Examples

Assume that all conditions necessary for inference are satisfied.

::::::::: columns
:::: {.column width="33%"}
::: {style="font-size:75%"}
`qnorm(0.90)` = `r round(qnorm(0.90, mean = 0, sd = 1),2)`

`qnorm(0.95)` = `r round(qnorm(0.95, mean = 0, sd = 1),2)`

`qnorm(0.975)` = `r round(qnorm(0.975, mean = 0, sd = 1),2)`
:::
::::

:::: {.column width="33%"}
::: {style="font-size:75%"}
`qt(0.90, df = 35)` = `r round(qt(0.90, df = 35), 2)`

`qt(0.95, df = 35)` = `r round(qt(0.95, df = 35), 2)`

`qt(0.975, df = 35)` = `r round(qt(0.975, df = 35), 2)`
:::
::::

:::: {.column width="33%"}
::: {style="font-size:75%"}
`qt(0.90, df = 36)` = `r round(qt(0.90, df = 36), 2)`

`qt(0.95, df = 36)` = `r round(qt(0.95, df = 36), 2)`

`qt(0.975, df = 36)` = `r round(qt(0.975, df = 36), 2)`
:::
::::
:::::::::

::: {style="font-size:85%"}
1.  A 90% confidence interval for a population mean $\mu$ is given as $(18.985, 21.015)$. The interval was obtained based on a SRS for 36 observations. Calculate the sample mean and sample standard deviation.

2.  The standard deviation for students at particular Ivy League college is 250 points. Two students, Raina and Luke, want to estimate the average SAT score of students at this college. They want their margin of error to be no more than 25 points.

    a.  Raina wants to use a 90% confidence level. How large a sample does Raina need to collect?

    b.  Luke wants to use a 95% confidence level. Without calculations, determine whether Luke's sample should be larger or smaller than Raina's. Explain your reasoning.

    c.  Calculate the minimum sample size for Luke.
:::

# CI for paired mean

## Paired data

Suppose we have two sets of observations/data $\boldsymbol{x} = (x_{1}, x_{2}, \ldots x_{n})$ and $\boldsymbol{y} = (y_{1}, y_{2}, \ldots, y_{n})$

-   The data are considered **paired data** if each $x_{i}$ corresponds to exactly one $y_{i}$

-   Example: your score on the midterm and your score on the final

-   When analyzing paired data, we are typically interested in the difference in outcomes of each pair of observations

## Paired differences

-   Let $d_{i} = y_{i} - x_{i}$ for each $i = 1,\ldots, n$ be the observed differences

-   The $d_{i}$ come from larger population with true mean difference $\mu_{d}$ and standard deviation of differences $\sigma_{d}$

-   The sample mean difference and sample standard deviation of the differences are

::: fragment
$$\bar{d} = \frac{1}{n}\sum_{i=1}^{n} d_{i} \qquad \qquad s_{d} = \frac{1}{n-1}\sum_{i=1}^{n} (d_{i} - \bar{d})^2 $$
:::

## CLT for mean difference in pairs

-   Suppose the $n$ observational units are independent and the distribution of the differences is approximately normal. Then CLT says:

    $$
    \bar{d} \overset{\cdot}{\sim} N\left(\mu_{d}, \frac{\sigma_{d}}{\sqrt{n}} \right)
    $$


-   We are usually interested in performing inference for $\mu_{d}$ when both $\mu_{d}$ and $\sigma_{d}$ unknown

-   Our formula for $\gamma\times 100\%$ CI for $\mu_{d}$ is analogous to the formula for one mean when $\sigma$ unknown:

::: fragment
$$
\begin{align*}
\text{point estimate} &\pm t^*_{df, (1+\gamma)/2} \times \widehat{\text{SE}} \\
\bar{d} &\pm t_{df, (1+\gamma)/2}^* \times \frac{s_{d}}{\sqrt{n}}
\end{align*}
$$

where $df = n-1$
:::

## Example: zinc

```{r}
zinc <- data.frame(bottom = c(0.430, 0.266, 0.567, 0.531, 0.707, 0.716, .651,	.589,	.469,	.723),
                   surface = c(.415,	.238,	.390,	.410,	.605,	.609,	.632,	.523,	.411,	.612))
```

Data consist of measured zinc concentrations in bottom water and surface water at 10 randomly sampled wells:

::: {style="color: maroon"}
Do the data suggest that the true average concentration in the bottom water is different than that of surface water? Let's answer this using a 95% confidence interval.
:::

::::::: columns
::: {.column width="50%"}
```{r}
zinc |>
  mutate(d = bottom - surface) |>
  ggplot(aes(x = d)) +
  geom_histogram(bins = 10) +
  labs(x = "Observed difference (bottom - surface)") +
  theme_minimal() +
  theme(text= element_text(size =28))
```
:::

::::: {.column width="50%"}
:::: fragment
```{r}
head(zinc)
```

::: discuss
Are the data paired? Does CLT apply?
:::
::::
:::::
:::::::

## Example: zinc (cont.)

::::: columns
::: {.column width="40%"}
```{r echo = T}
zinc <- zinc |>
  mutate(d = bottom - surface)
d_bar <- mean(zinc$d)
d_bar
s_d <- sd(zinc$d)
s_d
```

```{r}
n <- nrow(zinc)
d_bar <- round(d_bar, 4)
s_d <- round(s_d, 3)
se <- round(s_d/sqrt(n), 3)
df <- n-1
tstar <- round(qt(0.975, df), 2)
zinc_ci <- round(d_bar + tstar*se*c(-1,1), 3)
```
:::

::: {.column width="60%"}
1.  point estimate: $\bar{d} = `r d_bar`$

2.  SE $\approx$ $\frac{s_{d}}{\sqrt{n}} = \frac{`r s_d`}{\sqrt{`r n`}} = `r se`$

3.  ::: discuss
    critical value: what code would you write?
    :::

    -   $df = n-1 = `r n-1`$

    -   $t_{`r df`, 0.975}^{*} =$ `qt(0.975,`r df`)` $= `r tstar`$
:::
:::::

::: fragment
So our 95% confidence interval is:

$$`r d_bar` \pm `r tstar`(`r se`) = (`r zinc_ci`)$$
:::

:::: fragment
::: {style="color: maroon"}
Do the data suggest that the true average concentration in the bottom water is different than that of surface water? Explain.
:::
::::

# CIs for difference in two means

## Difference of two means

Now consider two populations under the condition that the data/populations are not paired.

We might be interested in learning about whether or not the means of each population are equal (think about the voice jitter homework problem)!

-   Let $\mu_{1}$ and $\mu_{2}$ represent the population means for the two populations 1 and 2

-   Samples of size $n_{1}$ and $n_{2}$ from each population, respectively

-   We might think it reasonable to use $\bar{x}_{1} - \bar{x}_{2}$ as a point estimate for $\mu_{1} - \mu_{2}$

## Conditions for inference

Now that we have two populations, conditions for CLT and use of the $t$-distribution for inference will look slightly different:

1.  **Independence** (extended): need data within *and* between the two groups

    -   e.g.the two data sets come from independent random samples or from a randomized experiment

2.  **Normality**: we need to check for approximate normality for *both* groups separately

## CI for difference in two means

If the conditions hold, then our usual formula for $\gamma \times 100\%$ CI still holds:

$$
\text{point estimate} \pm \text{critical value} \times \text{SE}
$$

1.  Point estimate

```{r}

```

::::::: columns
:::: {.column width="50%"}
::: {.fragment style="color: maroon"}
If $\sigma_{1}$ and $\sigma_{2}$ known:
:::

2.  $\text{SE} = \sqrt{\frac{\sigma_{1}^2}{n_{1}} + \frac{\sigma_{2}^2}{n_{2}}}$

3.  critical value: $z_{(1+\gamma)/2}^*$

    -   $(1+\gamma)/2$ percentile of $N(0,1)$
::::

:::: {.column width="50%"}
::: {.fragment style="color: maroon"}
If $\sigma_{1}$ and $\sigma_{2}$ unknown:
:::

2.  $\text{SE} \approx \sqrt{\frac{s_{1}^2}{n_{1}} + \frac{s_{2}^2}{n_{2}}}$

3.  critical value: $t_{df, (1+\gamma)/2}^*$

    -   $(1+\gamma)/2$ percentile of $t_{df}$

    -   $df = \min\{n_{1} -1, n_{2} - 1\}$
::::
:::::::

## Example: voice shimmer

Let's consider the voice shimmer of PD vs non-PD patients from last week's homework.

```{r}
url_file <- "https://raw.githubusercontent.com/midd-stat201-fall2024/midd-stat201-fall2024.github.io/refs/heads/main/data/parkinsons.csv"
parkinsons <- read_csv(url_file)
x_pd <- parkinsons |>
  filter(status == "PD") |>
  pull(shimmer)
x_healthy <- parkinsons |>
  filter(status == "Healthy") |>
  pull(shimmer)
n1 <- length(x_pd); n2 <- length(x_healthy)
xbar1 <- mean(x_pd); xbar2 <- mean(x_healthy)
s1 <- sd(x_pd); s2 <- sd(x_healthy)
```

::: {style="color: maroon"}
Convince yourself that this data isn't paired!
:::

-   Population 1: people with Parkinson's Disease

-   Population 2: people without Parkinson's Disease

::: {.fragment style="color: maroon"}
Research question: are average voice shimmers different between people with and without Parkinson's? Create a 95% confidence interval to answer this question.
:::

-   We care about the difference in means $\mu_{\text{PD}} - \mu_{\text{H}}$

## Example: voice shimmer (cont.)

::: {style="color: maroon"}
Are average voice shimmers different between people with and without Parkinson's? Create a 95% confidence interval to answer this question.
:::

:::::::: columns
::: {.column width="50%"}
```{r}
shimmer_sum <- parkinsons |>
  group_by(status) |>
  summarise(n = n(), xbar = mean(shimmer), s = sd(shimmer))
kableExtra::kable(shimmer_sum, digits = 3)
parkinsons |> 
  ggplot(aes(x = shimmer))+
    geom_histogram(bins = 20) +
    facet_wrap(~ status, scales = "free") +
  labs(x = "Voice shimmer") +
    theme_minimal()+
    theme(text = element_text(size = 28))
```
:::

:::::: {.column width="50%"}
::: discuss
Do assumptions for CLT hold?
:::

-   Independence: random sample!
-   Normality condition: $n \geq 30$ in both groups with no particularly extreme outliers

:::: fragment
::: discuss
Set-up/find the following:
:::

1.  Point estimate
2.  Standard error
3.  Code for critical value
::::
::::::
::::::::

## Example: voice shimmer (cont.)

```{r}
#kableExtra::kable(birth_sum, digits = 3)
point_est <- round(xbar1 - xbar2,3)
se <- round(sqrt(s1^2/n1  + s2^2 / n2), 3)
df <- min(c(n1-1, n2-1))
t975 <- round(qt(0.975, df), 2)

ci <- round(point_est + se * t975 * c(-1,1), 3)
```

1.  Point estimate: $\bar{x}_{\text{PD}} - \bar{x}_{\text{H}} = `r round(xbar1, 2)` - `r round(xbar2,2)` = `r point_est`$

2.  SE $\approx \sqrt{\frac{s_{\text{PD}}^2}{n_{\text{PD}}} + \frac{s_{\text{H}}^2}{n_{\text{H}}}} = \sqrt{\frac{`r round(s1,2)`^2}{`r n1`} + \frac{`r round(s2,2)`^2}{`r n2`}} = `r se`$

3.  Critical value:

    -   $df = \min\{n_{\text{PD}} -1, n_{\text{H}} -1 \} = \min\{`r n1` - 1, `r n2`- 1\} = `r df`$

    -   Want $0.975$-th percentile of $t_{`r df`}$ distribution: `qt(0.975, df =`r df`)` = `r t975`

:::: fragment
::: discuss
Putting everything together, our 95% CI for $\mu_{\text{PD}} - \mu_{\text{H}}$ is: 
$$
`r point_est` \pm `r t975` \times `r se` = (`r ci`)
$$

- Interpret this CI in context. Note: direction of difference matters! 

- Are average voice shimmers different between people with and without Parkinson's? Briefly explain why or why not.
:::
::::
